{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "## Model : marketdirection\n### Description :\nThis model uses a Tensorflow neural network to predict the direction of a market in the next Y periods, based on the values of the previous X periods. \n\n### Model Attributes :\n- FFNN\n- Boosting\n- Re-training of entire network for each additional period\n\n### USP :\n- Normalised market data (between 0 and 1) to highlight common patterns at any time scale.\n- Utilises similar markets to increase size of training set\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "MODEL_ID = \"fdbe5895-0327-49d9-83e9-2246dbe1858b\"\n\nDATASET_ID1 = \"4234f0f1b6fcc17f6458696a6cdf5101\" # DOW\nDATASET_ID2 = \"3231bbe5eb2ab84eb54c9b64a8dcea55\" # SPY\n\nTRAINING_RUN = {\n        \"model_id\": MODEL_ID,\n        \"datasets\": [\n            DATASET_ID1,\n            DATASET_ID2\n        ]\n    }\n", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "#\n# Get dataset from MI API #\n#\n\nimport pandas\nimport sys\nimport gc\nimport uuid\nimport numpy as np\n\n#!pip install --upgrade git+https://github.com/cwilko/quantutils.git\n\nimport quantutils.dataset.pipeline as ppl\nfrom quantutils.api.auth import CredentialsStore\nfrom quantutils.api.bluemix import CloudObjectStore, ObjectStore, Metrics, Logger\nfrom quantutils.api.marketinsights import MarketInsights\nfrom quantutils.api.assembly import MIAssembly\nfrom quantutils.api.functions import Functions\nimport quantutils.model.utils as mlutils\nfrom quantutils.model.ml import Model\n\ncred = CredentialsStore()\nmetrics = Metrics(cred)\nmi = MarketInsights(cred)\nobjStore = ObjectStore(cred)\ncos = CloudObjectStore(cred)\nlog = Logger('MarketInsights-ML', cred)\nfun = Functions(cred)\nmiassembly = MIAssembly(mi, fun)\n\n# Logging helper function\ntag = lambda x,y : \"\".join([\"(\", x, \":\", str(y+1), \") \"])\n\nCONFIG = mi.get_model(MODEL_ID)\nTRN_CNF = CONFIG['training']\nTRAINING_RUN[\"id\"] = cos.generateKey([str(TRAINING_RUN[\"datasets\"]), str(TRAINING_RUN[\"model_id\"])])\nCOS_BUCKET = \"marketinsights-weights\"\nmi.put_training_run(TRAINING_RUN)\n\nmkt1, mkt1_desc = mi.get_dataset_by_id(DATASET_ID1)\nmkt2, mkt2_desc = mi.get_dataset_by_id(DATASET_ID2)\n\n# Crop training dates\nif \"training_end_date\" in TRN_CNF:\n    print(\"Cropping datasets...\")\n    #mkt1 = mkt1[TRN_CNF[\"training_start_date\"]:TRN_CNF[\"training_end_date\"]]\n    #mkt2 = mkt2[TRN_CNF[\"training_start_date\"]:TRN_CNF[\"training_end_date\"]]\n\n# Interleave (part of the \"added insight\" for this model)\nMK1, MK2, isect = ppl.intersect(mkt1,mkt2)\ndataset = ppl.interleave(MK1,MK2)\n\nTRAINING_SET_SIZE = TRN_CNF[\"training_window_size\"]\nTEST_SET_SIZE = len(dataset) - TRAINING_SET_SIZE\nWINDOW_SIZE = TRAINING_SET_SIZE\n\n_, test_y = ppl.splitCol(dataset[TRAINING_SET_SIZE:], mkt1_desc[\"features\"])\n\n# Create ML model\nffnn = Model(mkt1_desc[\"features\"], mkt1_desc[\"labels\"], CONFIG)\n\nprint(\"Done - Training ID: \" + TRAINING_RUN[\"id\"])", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Cropping datasets...\nDone - Training ID: 078df5a1afbaa2290ee93b4a562e3898\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "##\n## BOOTSTRAP/BOOSTING TRAINING WITH LOO\n##\n\n# Train thread id\ntrain_id = str(uuid.uuid1())[:8]\n#train_id = \"0b4045ec\"\n\nlog.info(\"\".join([\"(\", train_id, \")\", \" Training model: \", CONFIG['model_desc'], \"(\",MODEL_ID,\") , Training Run: \", TRAINING_RUN[\"id\"]]))\n                  \ntry:\n    \n    testSetIndex = isect[-(TEST_SET_SIZE//2):]\n    predictions = np.array([]).reshape(0,mkt1_desc[\"labels\"])\n\n    if (cos.keyExists(COS_BUCKET, TRAINING_RUN[\"id\"])):\n        weights = cos.get_csv(COS_BUCKET, TRAINING_RUN[\"id\"])\n        existing_predictions = pandas.DatetimeIndex(np.unique(weights[\"timestamp\"]) * 10**9).tz_localize(\"UTC\")\n        resultIndex = testSetIndex.difference(existing_predictions)\n    else:\n        weights = pandas.DataFrame()\n        resultIndex = testSetIndex\n        \n    prediction_idx = np.array([testSetIndex.get_loc(idx) for idx in resultIndex])     \n\n    labels_idx = ppl.interleave(pandas.DataFrame(prediction_idx*2), pandas.DataFrame(prediction_idx*2+1)).values.flatten()\n\n    for i in prediction_idx:\n        print(\"Training\", end='')\n        dataIdx = i * 2 + TRAINING_SET_SIZE\n        training_set = dataset[dataIdx-WINDOW_SIZE:dataIdx]\n        test_set = dataset[dataIdx:dataIdx+2]\n        success = False\n        prediction = [-1, -1]\n        retry = 0\n        while ((not success) & (retry<TRN_CNF['training_retries'])):\n            try:\n                ## CHOOSE BOOTSTRAP OR BOOST\n                # TODO : Separate the train from the evaluation of the test set,i.e. go back into the model to evaluate the test set on the current weights. This is to be certain\n                # that the test set is not affecting the training process.\n                #results = mlutils.boostingTrain(ffnn, training_set, test_set, TRN_CNF['lamda'], TRN_CNF['iterations'], CONFIG['debug'])\n                results = mlutils.bootstrapTrain(ffnn, training_set, test_set, TRN_CNF['lamda'], TRN_CNF['iterations'], TRN_CNF['threshold'], CONFIG['debug'])\n                prediction = np.nanmean(results[\"test_predictions\"], axis=0) # TODO Plug in other aggregation method, e.g. voting\n                predictions =  np.concatenate([predictions, prediction])    \n                success = True\n            except ValueError: \n                print(\"Value error\")\n                log.error(\"\".join([tag(train_id, i), \"ValueError - Retrying...\"]))\n                retry = retry + 1\n        \n        if (not success):\n            log.error(\"Failed to train after several retries\")\n            break\n            \n        print(\".\")\n\n        # Extract predictions and store them (deprecated)\n        p1, p2 = [pandas.DataFrame([mkt], index=testSetIndex[i:i+1]) for mkt in prediction]        \n        #mi.put_predictions(p1, DATASET_ID1, TRAINING_RUN[\"id\"], update=True)\n        #mi.put_predictions(p2, DATASET_ID1, TRAINING_RUN[\"id\"], update=True)\n        \n        # Extract weights and store them        \n        newWeights = pandas.DataFrame(results[\"weights\"])\n        newWeights.insert(0,'timestamp', [testSetIndex[i].value // 10**9] * len(newWeights))\n        if (len(weights.columns)>0):\n            weights.columns = newWeights.columns\n        weights = weights.append(newWeights)\n        print(\"Storing Weights...\")\n        cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], weights) # Re-Write entire csv (TODO : to parquet)\n        \n        if (True):\n            log.debug(\"\".join([tag(train_id, i), testSetIndex[i].isoformat(), \" \", DATASET_ID1, \": \", str(p1.values[0])]))\n            log.debug(\"\".join([tag(train_id, i), testSetIndex[i].isoformat(), \" \", DATASET_ID2, \": \", str(p2.values[0])]))\n            \n        # Progress statistics\n        res = mlutils.evaluate(ppl.onehot(predictions), ppl.onehot(test_y[labels_idx][:len(predictions)]), TRN_CNF['threshold'])\n        log.info(\"\".join([tag(train_id, i), str(\"Results after %d iterations, %.2f precision, %.2f recall at %.2f threshold\" % (i+1, res[0], res[1], TRN_CNF['threshold']))]))   \n        metrics.send([{'name':'MI.precision', 'value':res[0].tolist()},{'name':'MI.recall', 'value':res[1].tolist()}])\n\n        # Backup predictions to filestore (deprecated)\n        x = 1\n        for mkt in ppl.deinterleave(pandas.DataFrame(predictions)):\n            mkt.index = resultIndex[:len(mkt)]\n            mkt.to_csv(\"results.csv\", header=False)\n            objStore.put_file('Experiment2', \"results.csv\", \"\".join([TRAINING_RUN[\"id\"], \"_\", str(x), \".csv\"]) )\n            x = x + 1\n\n        # Try to free memory\n        gc.collect()\nexcept:\n    log.error(\"\".join([tag(train_id, i), str(\"Unexpected error: %s\" % sys.exc_info()[0])]))\n    raise\n    ", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "##\n## BOOSTING TRAINING\n##\nprint(\"Training\")\nresults = mlutils.boostingTrain(ffnn, dataset[:TRAINING_SET_SIZE], dataset[TRAINING_SET_SIZE:], TRN_CNF['lamda'], TRN_CNF['iterations'], CONFIG['debug'])\npredictions =  np.nanmean(results[\"test_predictions\"], axis=0)\nprint(mlutils.evaluate(ppl.onehot(predictions), ppl.onehot(test_y), .0))\n\n# Save weights to Cloud Object Store\nnewWeights = pandas.DataFrame(results[\"weights\"])\nnewWeights.insert(0,'timestamp', [isect[TRAINING_SET_SIZE//2].value // 10**9] * len(newWeights))\ncos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], newWeights)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "##\n## BOOTSTRAP TRAINING\n##\n\nprint(\"Training\")\nresults = mlutils.bootstrapTrain(ffnn, dataset[:TRAINING_SET_SIZE], dataset[TRAINING_SET_SIZE:], TRN_CNF['lamda'], TRN_CNF['iterations'], TRN_CNF['threshold'], CONFIG['debug'])\npredictions =  np.nanmean(results[\"test_predictions\"], axis=0)\nprint(mlutils.evaluate(ppl.onehot(predictions), ppl.onehot(test_y), .0))\n\n# Save weights to Cloud Object Store\nnewWeights = pandas.DataFrame(results[\"weights\"])\nnewWeights.insert(0,'timestamp', [isect[TRAINING_SET_SIZE//2].value // 10**9] * len(newWeights))\n#cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], newWeights)", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Training\n............................................................(0.52083331, 1.0, 0.68493148966921835)\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Assess the individual market performance\nscores1 = miassembly.get_predictions_with_dataset_id(DATASET_ID1, TRAINING_RUN[\"id\"], start=\"2016-07-06\")\nscores1 = ppl.intersect(scores1, MK1)[0]\n\nscores2 = miassembly.get_predictions_with_dataset_id(DATASET_ID2, TRAINING_RUN[\"id\"], start=\"2016-07-06\")\nscores2 = ppl.intersect(scores2, MK2)[0]", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "a = mlutils.aggregatePredictions([scores1], method='mean_all')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\na = mlutils.aggregatePredictions([scores2], method='mean_all')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))\n\n#display(evaluate(ppl.onehot(predictions), ppl.onehot(test_y)))", 
            "cell_type": "code", 
            "execution_count": 15, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 265.0\nLost : 250.0\nTotal : 515.0\nDiff : 15.0\nEdge : 2.91262135922%\nIR : 0.660979\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.51456308"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 273.0\nLost : 242.0\nTotal : 515.0\nDiff : 31.0\nEdge : 6.01941747573%\nIR : 1.36602\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.53009707"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "a = mlutils.aggregatePredictions([scores1,scores2], method='mean_all')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))", 
            "cell_type": "code", 
            "execution_count": 17, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 267.0\nLost : 248.0\nTotal : 515.0\nDiff : 19.0\nEdge : 3.68932038835%\nIR : 0.83724\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.51844662"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 260.0\nLost : 255.0\nTotal : 515.0\nDiff : 5.0\nEdge : 0.970873786408%\nIR : 0.220326\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.50485438"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_majority')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))", 
            "cell_type": "code", 
            "execution_count": 18, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 269.0\nLost : 246.0\nTotal : 515.0\nDiff : 23.0\nEdge : 4.46601941748%\nIR : 1.0135\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.52233011"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 264.0\nLost : 251.0\nTotal : 515.0\nDiff : 13.0\nEdge : 2.52427184466%\nIR : 0.572848\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.51262134"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_unanimous_markets')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))", 
            "cell_type": "code", 
            "execution_count": 19, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 261.0\nLost : 237.0\nTotal : 498.0\nDiff : 24.0\nEdge : 4.81927710843%\nIR : 1.07547\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.52409637"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 255.0\nLost : 243.0\nTotal : 498.0\nDiff : 12.0\nEdge : 2.40963855422%\nIR : 0.537733\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.51204818"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_unanimous_pred')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))", 
            "cell_type": "code", 
            "execution_count": 20, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 276.0\nLost : 239.0\nTotal : 515.0\nDiff : 37.0\nEdge : 7.18446601942%\nIR : 1.63041\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.53592235"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 273.0\nLost : 242.0\nTotal : 515.0\nDiff : 31.0\nEdge : 6.01941747573%\nIR : 1.36602\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.53009707"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_unanimous_all')\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\ndisplay(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))", 
            "cell_type": "code", 
            "execution_count": 21, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 206.0\nLost : 173.0\nTotal : 379.0\nDiff : 33.0\nEdge : 8.70712401055%\nIR : 1.6951\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.54353565"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Won : 202.0\nLost : 177.0\nTotal : 379.0\nDiff : 25.0\nEdge : 6.5963060686%\nIR : 1.28416\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "0.53298151"
                    }, 
                    "metadata": {}
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "cos.delete(COS_BUCKET, TRAINING_RUN[\"id\"])", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], newWeights)", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "cos.get_csv(COS_BUCKET, TRAINING_RUN[\"id\"])", 
            "cell_type": "code", 
            "execution_count": null, 
            "outputs": [], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}