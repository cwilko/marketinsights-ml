{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : marketdirection\n",
    "### Description :\n",
    "This model uses a Tensorflow neural network to predict the direction of a market in the next Y periods, based on the values of the previous X periods. \n",
    "\n",
    "### Model Attributes :\n",
    "- FFNN\n",
    "- Boosting\n",
    "- Re-training of entire network for each additional period\n",
    "\n",
    "### USP :\n",
    "- Normalised market data (between 0 and 1) to highlight common patterns at any time scale.\n",
    "- Utilises similar markets to increase size of training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"fdbe5895-0327-49d9-83e9-2246dbe1858b\"\n",
    "\n",
    "DATASET_ID1 = \"4234f0f1b6fcc17f6458696a6cdf5101\" # DOW\n",
    "DATASET_ID2 = \"3231bbe5eb2ab84eb54c9b64a8dcea55\" # SPY\n",
    "\n",
    "TRAINING_RUN = {\n",
    "        \"model_id\": MODEL_ID,\n",
    "        \"datasets\": [\n",
    "            DATASET_ID1,\n",
    "            DATASET_ID2\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping datasets...\n",
      "Done - Training ID: 078df5a1afbaa2290ee93b4a562e3898\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get dataset from MI API #\n",
    "#\n",
    "\n",
    "import pandas\n",
    "import sys\n",
    "import gc\n",
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "#!pip install --upgrade git+https://github.com/cwilko/quantutils.git\n",
    "\n",
    "import quantutils.dataset.pipeline as ppl\n",
    "from quantutils.api.auth import CredentialsStore\n",
    "from quantutils.api.bluemix import CloudObjectStore, ObjectStore, Metrics, Logger\n",
    "from quantutils.api.marketinsights import MarketInsights\n",
    "from quantutils.api.assembly import MIAssembly\n",
    "from quantutils.api.functions import Functions\n",
    "import quantutils.model.utils as mlutils\n",
    "from quantutils.model.ml import Model\n",
    "\n",
    "cred = CredentialsStore()\n",
    "metrics = Metrics(cred)\n",
    "mi = MarketInsights(cred)\n",
    "objStore = ObjectStore(cred)\n",
    "cos = CloudObjectStore(cred)\n",
    "log = Logger('MarketInsights-ML', cred)\n",
    "fun = Functions(cred)\n",
    "miassembly = MIAssembly(mi, fun)\n",
    "\n",
    "# Logging helper function\n",
    "tag = lambda x,y : \"\".join([\"(\", x, \":\", str(y+1), \") \"])\n",
    "\n",
    "CONFIG = mi.get_model(MODEL_ID)\n",
    "TRN_CNF = CONFIG['training']\n",
    "TRAINING_RUN[\"id\"] = cos.generateKey([str(TRAINING_RUN[\"datasets\"]), str(TRAINING_RUN[\"model_id\"])])\n",
    "COS_BUCKET = \"marketinsights-weights\"\n",
    "mi.put_training_run(TRAINING_RUN)\n",
    "\n",
    "mkt1, mkt1_desc = mi.get_dataset_by_id(DATASET_ID1)\n",
    "mkt2, mkt2_desc = mi.get_dataset_by_id(DATASET_ID2)\n",
    "\n",
    "# Crop training dates\n",
    "if \"training_end_date\" in TRN_CNF:\n",
    "    print(\"Cropping datasets...\")\n",
    "    #mkt1 = mkt1[TRN_CNF[\"training_start_date\"]:TRN_CNF[\"training_end_date\"]]\n",
    "    #mkt2 = mkt2[TRN_CNF[\"training_start_date\"]:TRN_CNF[\"training_end_date\"]]\n",
    "\n",
    "# Interleave (part of the \"added insight\" for this model)\n",
    "MK1, MK2, isect = ppl.intersect(mkt1,mkt2)\n",
    "dataset = ppl.interleave(MK1,MK2)\n",
    "\n",
    "TRAINING_SET_SIZE = TRN_CNF[\"training_window_size\"]\n",
    "TEST_SET_SIZE = len(dataset) - TRAINING_SET_SIZE\n",
    "WINDOW_SIZE = TRAINING_SET_SIZE\n",
    "\n",
    "_, test_y = ppl.splitCol(dataset[TRAINING_SET_SIZE:], mkt1_desc[\"features\"])\n",
    "\n",
    "# Create ML model\n",
    "ffnn = Model(mkt1_desc[\"features\"], mkt1_desc[\"labels\"], CONFIG)\n",
    "\n",
    "print(\"Done - Training ID: \" + TRAINING_RUN[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##\n",
    "## BOOTSTRAP/BOOSTING TRAINING WITH LOO\n",
    "##\n",
    "\n",
    "# Train thread id\n",
    "train_id = str(uuid.uuid1())[:8]\n",
    "#train_id = \"0b4045ec\"\n",
    "\n",
    "log.info(\"\".join([\"(\", train_id, \")\", \" Training model: \", CONFIG['model_desc'], \"(\",MODEL_ID,\") , Training Run: \", TRAINING_RUN[\"id\"]]))\n",
    "                  \n",
    "try:\n",
    "    \n",
    "    testSetIndex = isect[-(TEST_SET_SIZE//2):]\n",
    "    predictions = np.array([]).reshape(0,mkt1_desc[\"labels\"])\n",
    "\n",
    "    if (cos.keyExists(COS_BUCKET, TRAINING_RUN[\"id\"])):\n",
    "        weights = cos.get_csv(COS_BUCKET, TRAINING_RUN[\"id\"])\n",
    "        existing_predictions = pandas.DatetimeIndex(np.unique(weights[\"timestamp\"]) * 10**9).tz_localize(\"UTC\")\n",
    "        resultIndex = testSetIndex.difference(existing_predictions)\n",
    "    else:\n",
    "        weights = pandas.DataFrame()\n",
    "        resultIndex = testSetIndex\n",
    "        \n",
    "    prediction_idx = np.array([testSetIndex.get_loc(idx) for idx in resultIndex])     \n",
    "\n",
    "    labels_idx = ppl.interleave(pandas.DataFrame(prediction_idx*2), pandas.DataFrame(prediction_idx*2+1)).values.flatten()\n",
    "\n",
    "    for i in prediction_idx:\n",
    "        print(\"Training\", end='')\n",
    "        dataIdx = i * 2 + TRAINING_SET_SIZE\n",
    "        training_set = dataset[dataIdx-WINDOW_SIZE:dataIdx]\n",
    "        test_set = dataset[dataIdx:dataIdx+2]\n",
    "        success = False\n",
    "        prediction = [-1, -1]\n",
    "        retry = 0\n",
    "        while ((not success) & (retry<TRN_CNF['training_retries'])):\n",
    "            try:\n",
    "                ## CHOOSE BOOTSTRAP OR BOOST\n",
    "                # TODO : Separate the train from the evaluation of the test set,i.e. go back into the model to evaluate the test set on the current weights. This is to be certain\n",
    "                # that the test set is not affecting the training process.\n",
    "                #results = mlutils.boostingTrain(ffnn, training_set, test_set, TRN_CNF['lamda'], TRN_CNF['iterations'], CONFIG['debug'])\n",
    "                results = mlutils.bootstrapTrain(ffnn, training_set, test_set, TRN_CNF['lamda'], TRN_CNF['iterations'], TRN_CNF['threshold'], CONFIG['debug'])\n",
    "                prediction = np.nanmean(results[\"test_predictions\"], axis=0) # TODO Plug in other aggregation method, e.g. voting\n",
    "                predictions =  np.concatenate([predictions, prediction])    \n",
    "                success = True\n",
    "            except ValueError: \n",
    "                print(\"Value error\")\n",
    "                log.error(\"\".join([tag(train_id, i), \"ValueError - Retrying...\"]))\n",
    "                retry = retry + 1\n",
    "        \n",
    "        if (not success):\n",
    "            log.error(\"Failed to train after several retries\")\n",
    "            break\n",
    "            \n",
    "        print(\".\")\n",
    "\n",
    "        # Extract predictions and store them (deprecated)\n",
    "        p1, p2 = [pandas.DataFrame([mkt], index=testSetIndex[i:i+1]) for mkt in prediction]        \n",
    "        #mi.put_predictions(p1, DATASET_ID1, TRAINING_RUN[\"id\"], update=True)\n",
    "        #mi.put_predictions(p2, DATASET_ID1, TRAINING_RUN[\"id\"], update=True)\n",
    "        \n",
    "        # Extract weights and store them        \n",
    "        newWeights = pandas.DataFrame(results[\"weights\"])\n",
    "        newWeights.insert(0,'timestamp', [testSetIndex[i].value // 10**9] * len(newWeights))\n",
    "        if (len(weights.columns)>0):\n",
    "            weights.columns = newWeights.columns\n",
    "        weights = weights.append(newWeights)\n",
    "        print(\"Storing Weights...\")\n",
    "        cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], weights) # Re-Write entire csv (TODO : to parquet)\n",
    "        \n",
    "        if (True):\n",
    "            log.debug(\"\".join([tag(train_id, i), testSetIndex[i].isoformat(), \" \", DATASET_ID1, \": \", str(p1.values[0])]))\n",
    "            log.debug(\"\".join([tag(train_id, i), testSetIndex[i].isoformat(), \" \", DATASET_ID2, \": \", str(p2.values[0])]))\n",
    "            \n",
    "        # Progress statistics\n",
    "        res = mlutils.evaluate(ppl.onehot(predictions), ppl.onehot(test_y[labels_idx][:len(predictions)]), TRN_CNF['threshold'])\n",
    "        log.info(\"\".join([tag(train_id, i), str(\"Results after %d iterations, %.2f precision, %.2f recall at %.2f threshold\" % (i+1, res[0], res[1], TRN_CNF['threshold']))]))   \n",
    "        metrics.send([{'name':'MI.precision', 'value':res[0].tolist()},{'name':'MI.recall', 'value':res[1].tolist()}])\n",
    "\n",
    "        # Backup predictions to filestore (deprecated)\n",
    "        x = 1\n",
    "        for mkt in ppl.deinterleave(pandas.DataFrame(predictions)):\n",
    "            mkt.index = resultIndex[:len(mkt)]\n",
    "            mkt.to_csv(\"results.csv\", header=False)\n",
    "            objStore.put_file('Experiment2', \"results.csv\", \"\".join([TRAINING_RUN[\"id\"], \"_\", str(x), \".csv\"]) )\n",
    "            x = x + 1\n",
    "\n",
    "        # Try to free memory\n",
    "        gc.collect()\n",
    "except:\n",
    "    log.error(\"\".join([tag(train_id, i), str(\"Unexpected error: %s\" % sys.exc_info()[0])]))\n",
    "    raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## BOOSTING TRAINING\n",
    "##\n",
    "print(\"Training\")\n",
    "results = mlutils.boostingTrain(ffnn, dataset[:TRAINING_SET_SIZE], dataset[TRAINING_SET_SIZE:], TRN_CNF['lamda'], TRN_CNF['iterations'], CONFIG['debug'])\n",
    "predictions =  np.nanmean(results[\"test_predictions\"], axis=0)\n",
    "print(mlutils.evaluate(ppl.onehot(predictions), ppl.onehot(test_y), .0))\n",
    "\n",
    "# Save weights to Cloud Object Store\n",
    "newWeights = pandas.DataFrame(results[\"weights\"])\n",
    "newWeights.insert(0,'timestamp', [isect[TRAINING_SET_SIZE//2].value // 10**9] * len(newWeights))\n",
    "cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], newWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "............................................................(0.52083331, 1.0, 0.68493148966921835)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## BOOTSTRAP TRAINING\n",
    "##\n",
    "\n",
    "print(\"Training\")\n",
    "results = mlutils.bootstrapTrain(ffnn, dataset[:TRAINING_SET_SIZE], dataset[TRAINING_SET_SIZE:], TRN_CNF['lamda'], TRN_CNF['iterations'], TRN_CNF['threshold'], CONFIG['debug'])\n",
    "predictions =  np.nanmean(results[\"test_predictions\"], axis=0)\n",
    "print(mlutils.evaluate(ppl.onehot(predictions), ppl.onehot(test_y), .0))\n",
    "\n",
    "# Save weights to Cloud Object Store\n",
    "newWeights = pandas.DataFrame(results[\"weights\"])\n",
    "newWeights.insert(0,'timestamp', [isect[TRAINING_SET_SIZE//2].value // 10**9] * len(newWeights))\n",
    "#cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], newWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the individual market performance\n",
    "scores1 = miassembly.get_predictions_with_dataset_id(DATASET_ID1, TRAINING_RUN[\"id\"], start=\"2016-07-06\")\n",
    "scores1 = ppl.intersect(scores1, MK1)[0]\n",
    "\n",
    "scores2 = miassembly.get_predictions_with_dataset_id(DATASET_ID2, TRAINING_RUN[\"id\"], start=\"2016-07-06\")\n",
    "scores2 = ppl.intersect(scores2, MK2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 265.0\n",
      "Lost : 250.0\n",
      "Total : 515.0\n",
      "Diff : 15.0\n",
      "Edge : 2.91262135922%\n",
      "IR : 0.660979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51456308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 273.0\n",
      "Lost : 242.0\n",
      "Total : 515.0\n",
      "Diff : 31.0\n",
      "Edge : 6.01941747573%\n",
      "IR : 1.36602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53009707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mlutils.aggregatePredictions([scores1], method='mean_all')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "a = mlutils.aggregatePredictions([scores2], method='mean_all')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "\n",
    "#display(evaluate(ppl.onehot(predictions), ppl.onehot(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 267.0\n",
      "Lost : 248.0\n",
      "Total : 515.0\n",
      "Diff : 19.0\n",
      "Edge : 3.68932038835%\n",
      "IR : 0.83724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51844662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 260.0\n",
      "Lost : 255.0\n",
      "Total : 515.0\n",
      "Diff : 5.0\n",
      "Edge : 0.970873786408%\n",
      "IR : 0.220326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50485438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mlutils.aggregatePredictions([scores1,scores2], method='mean_all')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 269.0\n",
      "Lost : 246.0\n",
      "Total : 515.0\n",
      "Diff : 23.0\n",
      "Edge : 4.46601941748%\n",
      "IR : 1.0135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52233011"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 264.0\n",
      "Lost : 251.0\n",
      "Total : 515.0\n",
      "Diff : 13.0\n",
      "Edge : 2.52427184466%\n",
      "IR : 0.572848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51262134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_majority')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 261.0\n",
      "Lost : 237.0\n",
      "Total : 498.0\n",
      "Diff : 24.0\n",
      "Edge : 4.81927710843%\n",
      "IR : 1.07547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.52409637"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 255.0\n",
      "Lost : 243.0\n",
      "Total : 498.0\n",
      "Diff : 12.0\n",
      "Edge : 2.40963855422%\n",
      "IR : 0.537733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51204818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_unanimous_markets')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 276.0\n",
      "Lost : 239.0\n",
      "Total : 515.0\n",
      "Diff : 37.0\n",
      "Edge : 7.18446601942%\n",
      "IR : 1.63041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53592235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 273.0\n",
      "Lost : 242.0\n",
      "Total : 515.0\n",
      "Diff : 31.0\n",
      "Edge : 6.01941747573%\n",
      "IR : 1.36602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53009707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_unanimous_pred')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 206.0\n",
      "Lost : 173.0\n",
      "Total : 379.0\n",
      "Diff : 33.0\n",
      "Edge : 8.70712401055%\n",
      "IR : 1.6951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.54353565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 202.0\n",
      "Lost : 177.0\n",
      "Total : 379.0\n",
      "Diff : 25.0\n",
      "Edge : 6.5963060686%\n",
      "IR : 1.28416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53298151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mlutils.aggregatePredictions([scores1,scores2], method='vote_unanimous_all')\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK1.loc[a.index], mkt1_desc[\"features\"])[1])))\n",
    "display(mlutils.evaluate(ppl.onehot(a.values), ppl.onehot(ppl.splitCol(MK2.loc[a.index], mkt1_desc[\"features\"])[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.delete(COS_BUCKET, TRAINING_RUN[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.put_csv(COS_BUCKET, TRAINING_RUN[\"id\"], newWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.get_csv(COS_BUCKET, TRAINING_RUN[\"id\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
