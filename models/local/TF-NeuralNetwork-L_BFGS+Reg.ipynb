{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def featureNormalise(X):\n",
    "    mu = np.mean(X,0)\n",
    "    sigma = np.std(X,0, ddof=1)\n",
    "    return ((X - mu) / sigma), mu, sigma\n",
    "\n",
    "def mapFeatures(x1, x2):\n",
    "    degree = 6;\n",
    "    out = np.ones([x1.shape[0],1]);\n",
    "    for i in range(1, degree+1):\n",
    "        for j in range(0, i+1):\n",
    "            out = np.hstack((out,np.array((x1**(i-j)) * (x2**j)).reshape(x1.shape[0],1)))\n",
    "    return out\n",
    "\n",
    "\n",
    "## Load Training data\n",
    "dataset = pandas.read_csv(\"data/ex4data1_X.csv\", header=None)\n",
    "labels = pandas.read_csv(\"data/ex4data1_y.csv\", header=None)\n",
    "\n",
    "m,n = dataset.shape\n",
    "X = dataset.values.reshape(m,n).astype(np.float32)\n",
    "y_raw = labels.values.ravel() - 1\n",
    "\n",
    "\n",
    "## Load Validation and Test data\n",
    "\n",
    "## Normalise\n",
    "x_norm = X#, mu, sigma = featureNormalise(X)\n",
    "\n",
    "# Add bias\n",
    "x_with_bias = np.hstack((np.ones((x_norm.shape[0],1)),x_norm)).astype(np.float32)\n",
    "#x_with_bias = mapFeatures(x_norm[:,0], x_norm[:,1]).astype(np.float32)\n",
    "#m,n = x_with_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "##\n",
    "## Split (Train/Val/Test)\n",
    "##\n",
    "def split(data, train=.6, val=.2, test=.2):\n",
    "    idx = np.arange(0,len(data)) / float(len(data))\n",
    "    msk1 = data[idx<train]\n",
    "    msk2 = data[(idx>=train) & (idx<(train + val))]\n",
    "    msk3 = data[(idx>=(train+val))]\n",
    "    return [msk1.values, msk2.values, msk3.values]\n",
    "\n",
    "##\n",
    "## Shuffle data\n",
    "##\n",
    "def shuffle(data):\n",
    "    return data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def encode(data):\n",
    "    y = np.zeros([data.shape[0], 10]).astype(np.float32)\n",
    "    for i in range(0,data.shape[0]):\n",
    "        y[i,data[i]] = 1.\n",
    "    return y\n",
    "\n",
    "shuffled = shuffle(pd.DataFrame(np.hstack((x_with_bias,y_raw.reshape(m,1)))))\n",
    "train_X, val_X, test_X = split(shuffled)\n",
    "train_y = encode(train_X[:,-1].reshape(-1,1).astype(np.integer))\n",
    "val_y = encode(val_X[:,-1].reshape(-1,1).astype(np.integer))\n",
    "test_y = encode(test_X[:,-1].reshape(-1,1).astype(np.integer))\n",
    "\n",
    "m = train_X.shape[0]\n",
    "n = train_X.shape[1] - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll bundle groups of examples during training for efficiency.\n",
    "# This defines the size of the batch.\n",
    "BATCH_SIZE = m\n",
    "HIDDEN_UNITS = 25\n",
    "NUM_FEATURES = n \n",
    "NUM_LABELS = 10\n",
    "# The random seed that defines initialization.\n",
    "SEED = 42\n",
    "\n",
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step, which we'll write once we define the graph structure.\n",
    "train_data_node = tf.placeholder(tf.float32, shape=(None, NUM_FEATURES+1))\n",
    "train_labels_node = tf.placeholder(tf.float32, shape=(None, NUM_LABELS))\n",
    "\n",
    "length = tf.Variable(tf.constant(m, dtype=tf.float32))\n",
    "\n",
    "# The variables below hold all the trainable weights. For each, the\n",
    "# parameter defines how the variables will be initialized. \n",
    "# TODO : These should be pulled from a config file\n",
    "\n",
    "Theta1 = tf.Variable( tf.truncated_normal([HIDDEN_UNITS, (NUM_FEATURES+1)], stddev=0.1, seed=SEED))\n",
    "\n",
    "Theta2 = tf.Variable( tf.truncated_normal([NUM_LABELS, HIDDEN_UNITS],stddev=0.1, seed=SEED))\n",
    "bias2 = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def model(X, Theta1, Theta2, bias):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # Perceptron\n",
    "    \n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(X, tf.transpose(Theta1)))\n",
    "                        \n",
    "    output = tf.nn.bias_add(tf.matmul(layer1, tf.transpose(Theta2)),bias)\n",
    "\n",
    "    return output\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "yhat = model(train_data_node, Theta1, Theta2, bias2)\n",
    "\n",
    "lam = .06\n",
    "\n",
    "# Change the weights by subtracting derivative with respect to that weight\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=train_labels_node, logits=yhat))\n",
    "# Regularization using L2 Loss function \n",
    "regularizer = tf.nn.l2_loss(Theta1) + tf.nn.l2_loss(Theta2)\n",
    "loss_reg = loss + (lam / tf.to_float(tf.shape(train_data_node)[0])) * regularizer\n",
    "\n",
    "# Optimizer: \n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(loss_reg, options={'maxiter':500})\n",
    "#update_weights = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Predictions\n",
    "train_prediction = yhat\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the loss at each iteration so we can chart it later\n",
    "J = []\n",
    "\n",
    "def loss_callback(loss):\n",
    "    J.append(loss)\n",
    "        \n",
    "def train(feed_dict, train=True):\n",
    "\n",
    "    #optimizer.minimize(feed_dict=feed_dict, fetches=[loss_reg], loss_callback=loss_callback)\n",
    "    if (train):\n",
    "        optimizer.minimize(feed_dict=feed_dict, fetches=[loss_reg], loss_callback=loss_callback )\n",
    "\n",
    "    return loss.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  Objective function value: 0.026939\n",
      "  Number of iterations: 372\n",
      "  Number of functions evaluations: 388\n"
     ]
    }
   ],
   "source": [
    "## Train \n",
    "J = []\n",
    "\n",
    "# Create a new interactive session that we'll use in\n",
    "# subsequent code cells.\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "# Initialize all the variables we defined above.\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "final_loss = train({train_data_node: train_X[:,:NUM_FEATURES+1], train_labels_node: train_y[:,:]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996666666666667"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = train_prediction.eval({train_data_node: train_X[:,:NUM_FEATURES+1], train_labels_node: train_y[:,:]})\n",
    "a = np.argmax(predictions,axis=1) \n",
    "np.sum(a == train_X[:,-1]) / np.float32(train_X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAEKCAYAAAC8B0kLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn7bX5JMDF2sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f510415dd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the fit and the loss over time.\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "fig.set_size_inches(10, 4)\n",
    "\n",
    "x = np.array(range(0, len(J)))\n",
    "ax1.plot(x, np.array(J).ravel())\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Training Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0078394506"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
