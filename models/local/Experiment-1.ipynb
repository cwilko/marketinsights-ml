{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_FEATURES = (2 * 4) + 1\n",
    "NUM_LABELS = 2\n",
    "\n",
    "## Load Training data\n",
    "train = pandas.read_csv(\"../datasets/output/WallSt-FinalTradingHour/WallSt-FinalTradingHour_train.csv\", header=None)\n",
    "val = pandas.read_csv(\"../datasets/output/WallSt-FinalTradingHour/WallSt-FinalTradingHour_val.csv\", header=None)\n",
    "test = pandas.read_csv(\"../datasets/output/WallSt-FinalTradingHour/WallSt-FinalTradingHour_test.csv\", header=None)\n",
    "\n",
    "train = pandas.concat([train, val])\n",
    "train = pandas.concat([train, test[250:]])\n",
    "test = test[:250]\n",
    "          \n",
    "def split(data, num_features):    \n",
    "    return data.values[:,:num_features], data.values[:,num_features:]\n",
    "\n",
    "train_X, train_y = split(train, NUM_FEATURES)\n",
    "val_X, val_y = split(test, NUM_FEATURES)\n",
    "test_X, test_y = split(test, NUM_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "##### #Define the architecture\n",
    "HIDDEN_UNITS = 32\n",
    "\n",
    "# The random seed that defines initialization.\n",
    "SEED = 42\n",
    "\n",
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step, which we'll write once we define the graph structure.\n",
    "train_data_node = tf.placeholder(tf.float32, shape=(None, NUM_FEATURES))\n",
    "train_labels_node = tf.placeholder(tf.float32, shape=(None, NUM_LABELS))\n",
    "lam = tf.placeholder(tf.float32)\n",
    "\n",
    "# The variables below hold all the trainable weights. For each, the\n",
    "# parameter defines how the variables will be initialized. \n",
    "# TODO : These should be pulled from a config file\n",
    "\n",
    "Theta1 = tf.Variable( tf.truncated_normal([HIDDEN_UNITS, (NUM_FEATURES)], stddev=0.1))\n",
    "\n",
    "Theta2 = tf.Variable( tf.truncated_normal([NUM_LABELS, HIDDEN_UNITS],stddev=0.1))\n",
    "bias2 = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def model(X, Theta1, Theta2, bias):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # Perceptron\n",
    "    \n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(X, tf.transpose(Theta1)))\n",
    "                        \n",
    "    output = tf.nn.bias_add(tf.matmul(layer1, tf.transpose(Theta2)),bias)\n",
    "\n",
    "    return output\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "yhat = model(train_data_node, Theta1, Theta2, bias2)\n",
    "\n",
    "# Change the weights by subtracting derivative with respect to that weight\n",
    "loss =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=train_labels_node, logits=yhat))\n",
    "# Regularization using L2 Loss function \n",
    "regularizer = tf.nn.l2_loss(Theta1) + tf.nn.l2_loss(Theta2)\n",
    "reg = (lam / tf.to_float(tf.shape(train_labels_node)[0])) * regularizer\n",
    "loss_reg = loss + reg\n",
    "\n",
    "# Optimizer: \n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(loss_reg, options={'maxiter':4000})\n",
    "#update_weights = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Predictions\n",
    "train_prediction = tf.sigmoid(yhat)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of the loss at each iteration so we can chart it later\n",
    "J = []\n",
    "\n",
    "def loss_callback():\n",
    "    print \"Recalc...\"\n",
    "    \n",
    "def step_callback(params):\n",
    "    J.append(params)\n",
    "    \n",
    "def minimize(feed_dict, train=True):\n",
    "    \n",
    "    #optimizer.minimize(feed_dict=feed_dict, fetches=[loss_reg], loss_callback=loss_callback)\n",
    "    if (train):\n",
    "        optimizer.minimize(feed_dict=feed_dict)\n",
    "\n",
    "    return loss.eval(feed_dict), train_prediction.eval(feed_dict)\n",
    "\n",
    "def predict(data_X, data_y, lam1, threshold):    \n",
    "    loss, predictions = minimize({train_data_node: data_X, train_labels_node: data_y, lam: lam1}, train=False)\n",
    "    a = np.argmax(predictions,axis=1) \n",
    "    b = np.argmax(data_y,axis=1) \n",
    "    a = a[(predictions > threshold).any(axis=1)]\n",
    "    b = b[(predictions > threshold).any(axis=1)]\n",
    "    precision = np.float32(np.sum(a == b) / np.float32(b.shape[0]))\n",
    "    recall = np.float32(np.sum(a == b) / np.float32(data_y.shape[0])) # Correct Recall\n",
    "    recall = np.float32(b.shape[0]) / data_y.shape[0] # Number of Days traded\n",
    "    F_score = (2.0 * precision * recall) / (precision + recall)\n",
    "    return loss, precision, recall, F_score\n",
    "\n",
    "def train(train_dict, val_dict, threshold, iterations=50):\n",
    "    \n",
    "    metrics = {\n",
    "        \"train_loss\":[],\n",
    "        \"train_precision\":[],\n",
    "        \"train_recall\":[],\n",
    "        \"train_f\":[],\n",
    "        \"val_loss\":[],\n",
    "        \"val_precision\":[],\n",
    "        \"val_recall\":[],\n",
    "        \"val_f\":[]\n",
    "    }\n",
    "    \n",
    "    print \"Training\",\n",
    "    \n",
    "    for i in range(0,iterations):\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            # Create a new interactive session that we'll use in\n",
    "            # subsequent code cells.\n",
    "            s = tf.InteractiveSession()\n",
    "            s.as_default()\n",
    "\n",
    "            # Initialize all the variables we defined above.\n",
    "            tf.global_variables_initializer().run()\n",
    "\n",
    "            minimize(train_dict)\n",
    "            train_loss, train_precision, train_recall, train_f = predict(train_dict[train_data_node], train_dict[train_labels_node], train_dict[lam], threshold)\n",
    "\n",
    "            if (train_loss < .65):\n",
    "                print \".\",\n",
    "                metrics[\"train_loss\"].append(train_loss)\n",
    "                metrics[\"train_precision\"].append(train_precision)\n",
    "                metrics[\"train_recall\"].append(train_recall)\n",
    "                metrics[\"train_f\"].append(train_f)\n",
    "\n",
    "                val_loss, val_precision, val_recall, val_f = predict(val_dict[train_data_node], val_dict[train_labels_node], val_dict[lam], threshold)\n",
    "\n",
    "                metrics[\"val_loss\"].append(val_loss)\n",
    "                metrics[\"val_precision\"].append(val_precision)\n",
    "                metrics[\"val_recall\"].append(val_recall)\n",
    "                metrics[\"val_f\"].append(val_f)\n",
    "                break;\n",
    "    \n",
    "    results = {\n",
    "        \"train_loss\": {\"mean\":np.nanmean(metrics[\"train_loss\"]), \"std\":np.nanstd(metrics[\"train_loss\"]), \"values\":metrics[\"train_loss\"]},\n",
    "        \"train_precision\": {\"mean\":np.nanmean(metrics[\"train_precision\"]), \"std\":np.nanstd(metrics[\"train_precision\"]), \"values\":metrics[\"train_precision\"]},\n",
    "        \"train_recall\": {\"mean\":np.nanmean(metrics[\"train_recall\"]), \"std\":np.nanstd(metrics[\"train_recall\"]), \"values\":metrics[\"train_recall\"]},\n",
    "        \"train_f\": {\"mean\":np.nanmean(metrics[\"train_f\"]), \"std\":np.nanstd(metrics[\"train_f\"]), \"values\":metrics[\"train_f\"]},\n",
    "        \"val_loss\": {\"mean\":np.nanmean(metrics[\"val_loss\"]), \"std\":np.nanstd(metrics[\"val_loss\"]), \"values\":metrics[\"val_loss\"]},\n",
    "        \"val_precision\":{\"mean\":np.nanmean(metrics[\"val_precision\"]), \"std\":np.nanstd(metrics[\"val_precision\"]), \"values\":metrics[\"val_precision\"]},\n",
    "        \"val_recall\": {\"mean\":np.nanmean(metrics[\"val_recall\"]), \"std\":np.nanstd(metrics[\"val_recall\"]), \"values\":metrics[\"val_recall\"]},\n",
    "        \"val_f\": {\"mean\":np.nanmean(metrics[\"val_f\"]), \"std\":np.nanstd(metrics[\"val_f\"]), \"values\":metrics[\"val_f\"]},\n",
    "    }\n",
    "    \n",
    "    print \".\"\n",
    "    print(\"Iterations : %d Lambda : %.2f, Threshold : %.2f\" % (iterations, val_dict[lam], threshold))\n",
    "    print(\"Training loss : %.2f+/-%.2f, precision : %.2f+/-%.2f, recall : %.2f+/-%.2f, F : %.2f+/-%.2f\" % \n",
    "          (results[\"train_loss\"][\"mean\"], results[\"train_loss\"][\"std\"],\n",
    "           results[\"train_precision\"][\"mean\"], results[\"train_precision\"][\"std\"],\n",
    "           results[\"train_recall\"][\"mean\"], results[\"train_recall\"][\"std\"],\n",
    "           results[\"train_f\"][\"mean\"], results[\"train_f\"][\"std\"]))\n",
    "    print(\"Validation loss : %.2f+/-%.2f, precision : %.2f+/-%.2f, recall : %.2f+/-%.2f, F : %.2f+/-%.2f\" % \n",
    "          (results[\"val_loss\"][\"mean\"], results[\"val_loss\"][\"std\"],\n",
    "           results[\"val_precision\"][\"mean\"], results[\"val_precision\"][\"std\"],\n",
    "           results[\"val_recall\"][\"mean\"], results[\"val_recall\"][\"std\"],\n",
    "           results[\"val_f\"][\"mean\"], results[\"val_f\"][\"std\"]))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training . . . . . . . ."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "Iterations : 50 Lambda : 0.01, Threshold : 0.80\n",
      "Training loss : 0.48+/-0.01, precision : 0.92+/-0.01, recall : 0.37+/-0.02, F : 0.53+/-0.02\n",
      "Validation loss : 0.82+/-0.05, precision : 0.64+/-0.04, recall : 0.38+/-0.03, F : 0.47+/-0.03\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAEKCAYAAAB5ddOaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkNcwwJ0mS1LD/A7dIblF85qC6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f415d42c5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### \n",
    "### PREDICTIONS\n",
    "###\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "J = []\n",
    "lam_opt = 0.01\n",
    "THRESHOLD = 0.8\n",
    "\n",
    "\n",
    "train({train_data_node: train_X, train_labels_node: train_y, lam: lam_opt},\n",
    "      {train_data_node: val_X, train_labels_node: val_y, lam: lam_opt}, \n",
    "      THRESHOLD, \n",
    "      50)\n",
    "\n",
    "# Show the fit and the loss over time.\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "fig.set_size_inches(10, 4)\n",
    "\n",
    "x = np.array(range(0, len(J)))\n",
    "ax1.plot(x, np.array(J).ravel())\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 89.01+/-0.00, precision : 0.53+/-0.00, recall : 1.00+/-0.00, F : 0.69+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 45.88+/-0.00, precision : 0.54+/-0.00, recall : 1.00+/-0.00, F : 0.70+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 54.66+/-0.00, precision : 0.53+/-0.00, recall : 1.00+/-0.00, F : 0.69+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 81.07+/-0.00, precision : 0.58+/-0.00, recall : 1.00+/-0.00, F : 0.74+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 26.83+/-0.00, precision : 0.53+/-0.00, recall : 1.00+/-0.00, F : 0.69+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 56.92+/-0.00, precision : 0.49+/-0.00, recall : 1.00+/-0.00, F : 0.66+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 40.53+/-0.00, precision : 0.50+/-0.00, recall : 1.00+/-0.00, F : 0.67+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 24.54+/-0.00, precision : 0.51+/-0.00, recall : 1.00+/-0.00, F : 0.67+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 18.75+/-0.00, precision : 0.50+/-0.00, recall : 1.00+/-0.00, F : 0.66+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 158.39+/-0.00, precision : 0.51+/-0.00, recall : 1.00+/-0.00, F : 0.68+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 47.93+/-0.00, precision : 0.57+/-0.00, recall : 1.00+/-0.00, F : 0.72+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 70.41+/-0.00, precision : 0.48+/-0.00, recall : 1.00+/-0.00, F : 0.65+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 17.67+/-0.00, precision : 0.52+/-0.00, recall : 1.00+/-0.00, F : 0.68+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 54.08+/-0.00, precision : 0.51+/-0.00, recall : 1.00+/-0.00, F : 0.67+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.01+/-0.00, precision : 0.99+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 472.02+/-0.00, precision : 0.52+/-0.00, recall : 1.00+/-0.00, F : 0.69+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 20.19+/-0.00, precision : 0.52+/-0.00, recall : 1.00+/-0.00, F : 0.69+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 20.14+/-0.00, precision : 0.56+/-0.00, recall : 1.00+/-0.00, F : 0.72+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 25.63+/-0.00, precision : 0.54+/-0.00, recall : 1.00+/-0.00, F : 0.70+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 34.55+/-0.00, precision : 0.54+/-0.00, recall : 1.00+/-0.00, F : 0.70+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 14.94+/-0.00, precision : 0.48+/-0.00, recall : 1.00+/-0.00, F : 0.65+/-0.00\n",
      "Training . .\n",
      "Iterations : 1 Lambda : 0.00, Threshold : 0.00\n",
      "Training loss : 0.00+/-0.00, precision : 1.00+/-0.00, recall : 1.00+/-0.00, F : 1.00+/-0.00\n",
      "Validation loss : 23.76+/-0.00, precision : 0.58+/-0.00, recall : 1.00+/-0.00, F : 0.73+/-0.00\n",
      "Training"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ca3af26a60f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0mtrain_data_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmyLam\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m              \u001b[0mTHRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m               \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             )\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-e6209aea64d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dict, val_dict, threshold, iterations)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_labels_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-e6209aea64d4>\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(feed_dict, train)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#optimizer.minimize(feed_dict=feed_dict, fetches=[loss_reg], loss_callback=loss_callback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, session, feed_dict, fetches, step_callback, loss_callback)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0minequality_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minequality_funcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minequality_grad_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minequality_grad_funcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         step_callback=step_callback, optimizer_kwargs=self.optimizer_kwargs)\n\u001b[0m\u001b[1;32m    159\u001b[0m     var_vals = [packed_var_val[packing_slice]\n\u001b[1;32m    160\u001b[0m                 for packing_slice in self._packing_slices]\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, initial_val, loss_grad_func, equality_funcs, equality_grad_funcs, inequality_funcs, inequality_grad_funcs, step_callback, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mminimize_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mminimize_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     logging.info('Optimization terminated with:\\n'\n\u001b[1;32m    319\u001b[0m                  \u001b[0;34m'  Message: %s\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 450\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36mloss_grad_func_wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_grad_func_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;31m# SciPy's L-BFGS-B Fortran implementation requires gradients as doubles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36meval_func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m       augmented_fetch_vals = session.run(\n\u001b[0;32m--> 225\u001b[0;31m           augmented_fetches, feed_dict=augmented_feed_dict)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###\n",
    "### LEARNING CURVES FOR TRAINING SET AND CROSS-VALIDATION SET \n",
    "###\n",
    "train_losses = []\n",
    "val_losses = [0]\n",
    "perc_losses = [0]\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "metrics = {\n",
    "        \"train_loss\":[],\n",
    "        \"train_precision\":[],\n",
    "        \"train_recall\":[],\n",
    "        \"train_f\":[],\n",
    "        \"val_loss\":[],\n",
    "        \"val_precision\":[],\n",
    "        \"val_recall\":[],\n",
    "        \"val_f\":[]\n",
    "    }\n",
    "\n",
    "myLam = 0.0\n",
    "THRESHOLD = 0\n",
    "\n",
    "for i in range(10,train_X.shape[0]+1,10):\n",
    "    \n",
    "    results = train({train_data_node: train_X[:i,:], train_labels_node: train_y[:i,:], lam: myLam},\n",
    "            {train_data_node: val_X, train_labels_node: val_y, lam: myLam},\n",
    "             THRESHOLD,\n",
    "              1\n",
    "            )\n",
    "    \n",
    "    metrics[\"train_loss\"].append(results[\"train_loss\"][\"mean\"])\n",
    "    metrics[\"val_loss\"].append(results[\"val_loss\"][\"mean\"])\n",
    "    metrics[\"val_precision\"].append(results[\"val_precision\"][\"mean\"])\n",
    "    metrics[\"val_recall\"].append(results[\"val_recall\"][\"mean\"])\n",
    "    metrics[\"val_f\"].append(results[\"val_f\"][\"mean\"])\n",
    "        \n",
    "# Show the loss as the amount of data increases\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "fig.set_size_inches(10, 4)\n",
    "\n",
    "x = np.array(range(0, len(metrics[\"val_loss\"]))) * 10\n",
    "ax1.plot(x, np.array(metrics[\"train_loss\"]).ravel())\n",
    "ax1.plot(x, np.array(metrics[\"val_loss\"]).ravel(),'r')\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Training Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAEKCAYAAABXMPIIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncCYiIiLSivx/sXN+FToQwI8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb52f6672d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the loss as the amount of data increases\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "fig.set_size_inches(10, 4)\n",
    "\n",
    "x = np.array(range(0, len(metrics[\"val_loss\"]))) * 10\n",
    "#ax1.plot(x, np.array(train_losses).ravel())\n",
    "#ax1.plot(x, np.array(val_losses).ravel(),'r')\n",
    "ax1.plot(x[2:], (np.array(((np.array(metrics[\"val_loss\"])) ))[2:]).ravel(),'g')\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Training Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 10 Lambda : 0.00, Threshold : 0.90\n",
      "Mean Validation loss : 2.04, precision : 0.62, recall : 0.67, F : 0.64\n",
      "Sigma Validation loss : 0.38, precision : 0.03, recall : 0.08, F : 0.04\n",
      "Training...\n",
      "Iterations : 10 Lambda : 0.01, Threshold : 0.90\n",
      "Mean Validation loss : 0.90, precision : 0.65, recall : 0.27, F : 0.38\n",
      "Sigma Validation loss : 0.06, precision : 0.04, recall : 0.04, F : 0.03\n",
      "Optimal value for lambda is 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAEKCAYAAABNDBKGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n10gjVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb523476310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###\n",
    "### LAMBDA OPTIMIZATION\n",
    "###\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "#lams = [0.0, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1]#, 0.3, 1.0, 3.0, 10.0]\n",
    "#lams = np.arange(0.02,.04, .001)\n",
    "lams = [0.0, 0.01]\n",
    "\n",
    "metrics = {\n",
    "        \"train_loss\":[],\n",
    "        \"train_precision\":[],\n",
    "        \"train_recall\":[],\n",
    "        \"train_f\":[],\n",
    "        \"val_loss\":[],\n",
    "        \"val_precision\":[],\n",
    "        \"val_recall\":[],\n",
    "        \"val_f\":[]\n",
    "    }\n",
    "\n",
    "for i in lams:\n",
    "    \n",
    "    results = train({train_data_node: train_X, train_labels_node: train_y, lam: i},\n",
    "            {train_data_node: val_X, train_labels_node: val_y, lam: i},\n",
    "             THRESHOLD,\n",
    "              10\n",
    "            )\n",
    "    \n",
    "    metrics[\"train_loss\"].append(results[\"train_loss\"][\"mean\"])\n",
    "    metrics[\"val_loss\"].append(results[\"val_loss\"][\"mean\"])\n",
    "     \n",
    "\n",
    "lam_opt = lams[np.argmin(metrics[\"val_loss\"])]\n",
    "print(\"Optimal value for lambda is %s\" % lam_opt)\n",
    "    \n",
    "# Show the loss as the value of lambda changes\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "fig.set_size_inches(10, 4)\n",
    "\n",
    "ax1.plot(lams, np.array(metrics[\"train_loss\"]).ravel())\n",
    "ax1.plot(lams, np.array(metrics[\"val_loss\"]).ravel(),'r')\n",
    "ax1.plot(lams[np.argmin(metrics[\"val_loss\"])], metrics[\"val_loss\"][np.argmin(metrics[\"val_loss\"])], 'x', color='black')\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_xlabel(\"Lambda\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-80fba718532b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtrain_data_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_node\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmylam\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmylam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cbd3367dbdae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(feed_dict, train)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#optimizer.minimize(feed_dict=feed_dict, fetches=[loss_reg], loss_callback=loss_callback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, session, feed_dict, fetches, step_callback, loss_callback)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0minequality_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minequality_funcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0minequality_grad_funcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minequality_grad_funcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         step_callback=step_callback, optimizer_kwargs=self.optimizer_kwargs)\n\u001b[0m\u001b[1;32m    159\u001b[0m     var_vals = [packed_var_val[packing_slice]\n\u001b[1;32m    160\u001b[0m                 for packing_slice in self._packing_slices]\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, initial_val, loss_grad_func, equality_funcs, equality_grad_funcs, inequality_funcs, inequality_grad_funcs, step_callback, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mminimize_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mminimize_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     logging.info('Optimization terminated with:\\n'\n\u001b[1;32m    319\u001b[0m                  \u001b[0;34m'  Message: %s\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 450\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36mloss_grad_func_wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_grad_func_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;31m# SciPy's L-BFGS-B Fortran implementation requires gradients as doubles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/opt/python/training/external_optimizer.pyc\u001b[0m in \u001b[0;36meval_func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    217\u001b[0m       augmented_feed_dict = {\n\u001b[1;32m    218\u001b[0m           \u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpacking_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacking_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packing_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m       }\n\u001b[1;32m    221\u001b[0m       \u001b[0maugmented_feed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###\n",
    "### THRESHOLD OPTIMIZATION\n",
    "###\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "mylam = 0.0\n",
    "threshold = 0\n",
    "thresholds = [.5, .8, .9, .99, .999]\n",
    "lams = [0.0, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 1.0]\n",
    "\n",
    "for i in thresholds:\n",
    "    \n",
    "    results = train({train_data_node: train_X, train_labels_node: train_y, lam: mylam},\n",
    "            {train_data_node: val_X, train_labels_node: val_y, lam: mylam},\n",
    "             i\n",
    "            ) \n",
    "    \n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prediction.eval({train_data_node: val_X, train_labels_node: val_y, lam: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = train_prediction.eval({train_data_node: val_X, train_labels_node: val_y, lam: 0})\n",
    "np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = train_prediction.eval({train_data_node: test_X, train_labels_node: test_y, lam: 0})\n",
    "np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(val_y,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
