{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST OF UPDATES\n",
    "#\n",
    "# Added bias (constant) to each linear layer\n",
    "# Switched to using equivalent keras optimizer - SGD \n",
    "# Moved loss calculation to an independent function\n",
    "# Switched to defining the network as Keras layers(!)\n",
    "# Add tf.function to training loop - 10x speed increase(!)\n",
    "# Switch to calculating gradients with keras 'trainable_weight' vs tf 'variables' \n",
    "# Tried using Keras Model.fit but order of magnitude slower than custom loop!\n",
    "# Switch to train/val/test -> Showed that validation accuracy peaks at about 55% Training accuracy :(\n",
    "# Switch to MeanSquaredError as loss function (But this is not a good error for classification)\n",
    "# TODO : Early completion based on validation changes\n",
    "# TODO : Represent data using windowing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 23:22:01.315545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 23:22:01.445719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:01.445740: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-04 23:22:02.661069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:02.661191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:02.661215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import quantutils.dataset.pipeline as ppl\n",
    "import quantutils.dataset.ml as mlutils\n",
    "from marketinsights.api.model import MarketInsightsModel\n",
    "from marketinsights.remote.ml import MIAssembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 23:22:04.731450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-04 23:22:04.732445: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732517: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732643: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-05-04 23:22:04.732906: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-04 23:22:04.733205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "DATASET_ID1 = \"4234f0f1b6fcc17f6458696a6cdf5101\"  # DOW\n",
    "NUM_FEATURES = (2 * 4) + 1\n",
    "\n",
    "assembly = MIAssembly(secret=\"marketinsights-k8s-cred\")\n",
    "\n",
    "# Dataset\n",
    "dataset, descriptor = assembly.get_dataset_by_id(DATASET_ID1, debug=False)\n",
    "dataset = tf.cast(dataset, tf.float32)\n",
    "\n",
    "# Split into Train/Val/Test\n",
    "n = len(dataset)\n",
    "train_df = dataset[0:int(n*0.7)]\n",
    "val_df = dataset[int(n*0.7):int(n*0.9)]\n",
    "test_df = dataset[int(n*0.9):]\n",
    "\n",
    "# Split into features/labels\n",
    "train_x, train_y = train_df[:, :NUM_FEATURES], train_df[:,NUM_FEATURES:]\n",
    "val_x, val_y = val_df[:, :NUM_FEATURES], val_df[:,NUM_FEATURES:]\n",
    "test_x, test_y = test_df[:, :NUM_FEATURES], test_df[:,NUM_FEATURES:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 ms, sys: 0 ns, total: 22.3 ms\n",
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mlmodel = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(NUM_LABELS),\n",
    "    ]\n",
    ")\n",
    "mlmodel.compile(optimizer=\"SGD\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2495\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2495\n",
      "CPU times: user 95.8 ms, sys: 3.37 ms, total: 99.2 ms\n",
      "Wall time: 89 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f06428e8d60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlmodel.fit(train_x, train_y, batch_size=len(train_x), epochs=1000, verbose=1, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 1\n",
    "HIDDEN_UNITS = 32\n",
    "\n",
    "# Prepare our layer, loss, and optimizer.\n",
    "mlmodel = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(NUM_LABELS),\n",
    "    ]\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def loss_fn(model, y_pred, y, lam=tf.constant(0.001, tf.float32)):\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_pred))\n",
    "\n",
    "    # Regularization using L2 Loss function\n",
    "    regularizer = tf.nn.l2_loss(model.variables[0]) + tf.nn.l2_loss(model.variables[1])\n",
    "    reg = (lam / tf.cast(tf.shape(y)[0], tf.float32)) * regularizer\n",
    "    loss_reg = loss + reg\n",
    "\n",
    "    return loss_reg\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "@tf.function  # Make it fast.\n",
    "def train_on_batch(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = mlmodel(x)\n",
    "        #loss = loss_fn(mlmodel, logits, y)\n",
    "        loss = mse(y, tf.nn.sigmoid(logits))\n",
    "        gradients = tape.gradient(loss, mlmodel.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, mlmodel.trainable_weights))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Training Loss: 0.2483554482460022, Val Loss: 0.24932557344436646\n",
      "Step 1000 - Training Loss: 0.24834215641021729, Val Loss: 0.24927736818790436\n",
      "Step 2000 - Training Loss: 0.24833020567893982, Val Loss: 0.24923017621040344\n",
      "Step 3000 - Training Loss: 0.24831931293010712, Val Loss: 0.2491840124130249\n",
      "Step 4000 - Training Loss: 0.24830929934978485, Val Loss: 0.24913868308067322\n",
      "Step 5000 - Training Loss: 0.2483000010251999, Val Loss: 0.24909420311450958\n",
      "Step 6000 - Training Loss: 0.24829129874706268, Val Loss: 0.24905049800872803\n",
      "Step 7000 - Training Loss: 0.24828311800956726, Val Loss: 0.24900750815868378\n",
      "Step 8000 - Training Loss: 0.24827536940574646, Val Loss: 0.2489652782678604\n",
      "Step 9000 - Training Loss: 0.2482680231332779, Val Loss: 0.24892373383045197\n",
      "CPU times: user 12.1 s, sys: 589 ms, total: 12.7 s\n",
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set training parameters\n",
    "epochs = 10000\n",
    "learning_rate = .1\n",
    "losses = []\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "# Format training loop\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = train_on_batch(train_x, train_y)\n",
    "        \n",
    "    # Keep track of model loss per epoch\n",
    "    losses.append(epoch_loss)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Step {epoch} - Training Loss: {epoch_loss}, Val Loss: {mse(tf.nn.sigmoid(mlmodel(val_x)), val_y).numpy()}')\n",
    "        #print(f'{epoch} - Accuracy: {accuracy.result():.2%}, Loss: {epoch_loss.numpy():0.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 532.0\n",
      "Lost : 431.0\n",
      "Total : 963.0\n",
      "Diff : 101.0\n",
      "Edge : 10.488058151609554%\n",
      "Information Coefficient : 0.10488057136535645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5524403"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.evaluate(ppl.onehot(tf.nn.sigmoid(mlmodel(train_x)).numpy()), ppl.onehot(train_y.numpy()), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 138.0\n",
      "Lost : 138.0\n",
      "Total : 276.0\n",
      "Diff : 0.0\n",
      "Edge : 0.0%\n",
      "Information Coefficient : 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.evaluate(ppl.onehot(tf.nn.sigmoid(mlmodel(val_x)).numpy()), ppl.onehot(val_y.numpy()), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 73.0\n",
      "Lost : 65.0\n",
      "Total : 138.0\n",
      "Diff : 8.0\n",
      "Edge : 5.797101449275362%\n",
      "Information Coefficient : 0.05797100067138672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5289855"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.evaluate(ppl.onehot(tf.nn.sigmoid(mlmodel(test_x)).numpy()), ppl.onehot(test_y.numpy()), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev3.9",
   "language": "python",
   "name": "dev3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
