{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST OF UPDATES\n",
    "#\n",
    "# Added bias (constant) to each linear layer\n",
    "# Switched to using equivalent keras optimizer - SGD \n",
    "# Moved loss calculation to an independent function\n",
    "# Switched to defining the network as Keras layers(!)\n",
    "# Add tf.function to training loop - 10x speed increase(!)\n",
    "# Switch to calculating gradients with keras 'trainable_weight' vs tf 'variables' \n",
    "# Tried using Keras Model.fit but order of magnitude slower than custom loop!\n",
    "# Switch to train/val/test -> Showed that validation accuracy peaks at about 55% Training accuracy :(\n",
    "# Switch to MeanSquaredError as loss function (But this is not a good error for classification)\n",
    "# Add callback support to custom training loop\n",
    "# Early completion based on validation changes\n",
    "# Switch to correct method of regularisation with L2 Loss\n",
    "# Addition of Dropout for regularisation\n",
    "# Batch support (improves regularisation)\n",
    "# Tried various train/test/val combinations - results are very sensitive to this.\n",
    "# Tried various activation functions - \"elu\" seems best (not sure why yet)\n",
    "# Switched to BinaryCrossEntropy loss function from keras\n",
    "# Switched to Adam optimiser with scheduled learning\n",
    "# Utilised log x-scale to compare model plot results\n",
    "# Switch to \"relu\" activation function on hidden nodes - good for variables in 0 to 1 range.\n",
    "# Add Accuracy as a metric\n",
    "# Add multiple plots to compare metrics\n",
    "# Switch to Hinge loss function- better for penalising wrong sign!\n",
    "# Switch to tanh activation function and -1/1 labels (for Hinge)\n",
    "# Initialise variables with \"he-uniform\" - better for relu?\n",
    "# Regularisation after the activiation function, using Lamda to control how much impact.\n",
    "# TODO : Represent data using windowing method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import quantutils.dataset.pipeline as ppl\n",
    "import quantutils.dataset.ml as mlutils\n",
    "from marketinsights.api.model import MarketInsightsModel\n",
    "from marketinsights.remote.ml import MIAssembly\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from functools import partialmethod\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1387 entries, 2013-01-02 15:00:00-05:00 to 2018-08-01 15:00:00-04:00\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1387 non-null   float64\n",
      " 1   1       1387 non-null   float64\n",
      " 2   2       1387 non-null   float64\n",
      " 3   3       1387 non-null   float64\n",
      " 4   4       1387 non-null   float64\n",
      " 5   5       1387 non-null   float64\n",
      " 6   6       1387 non-null   float64\n",
      " 7   7       1387 non-null   float64\n",
      " 8   8       1387 non-null   float64\n",
      " 9   9       1387 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 119.2 KB\n"
     ]
    }
   ],
   "source": [
    "#DATASET_ID1 = \"dbaab93d94795145539e595fab79f2d4\"  # DOW\n",
    "#DATASET_ID1 = \"4234f0f1b6fcc17f6458696a6cdf5101\"  # DOW\n",
    "DATASET_ID1 = \"09dcbc101dd03d999a479baa924901b3\" # 2023 - Corrected \n",
    "#DATASET_ID1 = \"1f0ee1144486054fa56d65ce71b04110\" # 2023 - Corrected \n",
    "NUM_FEATURES = (2 * 4) + 1\n",
    "\n",
    "assembly = MIAssembly(secret=\"marketinsights-k8s-cred\")\n",
    "\n",
    "# Dataset\n",
    "dataset, descriptor = assembly.get_dataset_by_id(DATASET_ID1, debug=False)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02 15:00:00-05:00</th>\n",
       "      <td>0.390854</td>\n",
       "      <td>0.826284</td>\n",
       "      <td>0.199852</td>\n",
       "      <td>0.508756</td>\n",
       "      <td>0.504133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629408</td>\n",
       "      <td>0.051259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03 15:00:00-05:00</th>\n",
       "      <td>0.766445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586159</td>\n",
       "      <td>0.943148</td>\n",
       "      <td>0.943148</td>\n",
       "      <td>0.944016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487062</td>\n",
       "      <td>0.108321</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04 15:00:00-05:00</th>\n",
       "      <td>0.096991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631825</td>\n",
       "      <td>0.632902</td>\n",
       "      <td>0.905283</td>\n",
       "      <td>0.340489</td>\n",
       "      <td>0.847693</td>\n",
       "      <td>0.043706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07 15:00:00-05:00</th>\n",
       "      <td>0.078908</td>\n",
       "      <td>0.468290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337985</td>\n",
       "      <td>0.337655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>0.984516</td>\n",
       "      <td>0.071635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08 15:00:00-05:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.685708</td>\n",
       "      <td>0.685012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.344723</td>\n",
       "      <td>0.518904</td>\n",
       "      <td>0.068146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-26 15:00:00-04:00</th>\n",
       "      <td>0.117785</td>\n",
       "      <td>0.779641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500333</td>\n",
       "      <td>0.492980</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.345889</td>\n",
       "      <td>0.654713</td>\n",
       "      <td>0.078719</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-27 15:00:00-04:00</th>\n",
       "      <td>0.378094</td>\n",
       "      <td>0.888481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.861922</td>\n",
       "      <td>0.845986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287613</td>\n",
       "      <td>0.489824</td>\n",
       "      <td>0.109395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 15:00:00-04:00</th>\n",
       "      <td>0.307187</td>\n",
       "      <td>0.954621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892212</td>\n",
       "      <td>0.903560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369722</td>\n",
       "      <td>0.483388</td>\n",
       "      <td>0.102674</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 15:00:00-04:00</th>\n",
       "      <td>0.820354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359752</td>\n",
       "      <td>0.719278</td>\n",
       "      <td>0.730509</td>\n",
       "      <td>0.786664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157419</td>\n",
       "      <td>0.051675</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 15:00:00-04:00</th>\n",
       "      <td>0.778085</td>\n",
       "      <td>0.944538</td>\n",
       "      <td>0.216968</td>\n",
       "      <td>0.489333</td>\n",
       "      <td>0.500444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988908</td>\n",
       "      <td>0.105143</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1387 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0         1         2         3         4  \\\n",
       "Date_Time                                                                     \n",
       "2013-01-02 15:00:00-05:00  0.390854  0.826284  0.199852  0.508756  0.504133   \n",
       "2013-01-03 15:00:00-05:00  0.766445  1.000000  0.586159  0.943148  0.943148   \n",
       "2013-01-04 15:00:00-05:00  0.096991  1.000000  0.000000  0.631825  0.632902   \n",
       "2013-01-07 15:00:00-05:00  0.078908  0.468290  0.000000  0.337985  0.337655   \n",
       "2013-01-08 15:00:00-05:00  0.000000  0.748026  0.000000  0.685708  0.685012   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2018-07-26 15:00:00-04:00  0.117785  0.779641  0.000000  0.500333  0.492980   \n",
       "2018-07-27 15:00:00-04:00  0.378094  0.888481  0.000000  0.861922  0.845986   \n",
       "2018-07-30 15:00:00-04:00  0.307187  0.954621  0.000000  0.892212  0.903560   \n",
       "2018-07-31 15:00:00-04:00  0.820354  1.000000  0.359752  0.719278  0.730509   \n",
       "2018-08-01 15:00:00-04:00  0.778085  0.944538  0.216968  0.489333  0.500444   \n",
       "\n",
       "                                  5         6         7         8  9  \n",
       "Date_Time                                                             \n",
       "2013-01-02 15:00:00-05:00  1.000000  0.000000  0.629408  0.051259  1  \n",
       "2013-01-03 15:00:00-05:00  0.944016  0.000000  0.487062  0.108321 -1  \n",
       "2013-01-04 15:00:00-05:00  0.905283  0.340489  0.847693  0.043706  1  \n",
       "2013-01-07 15:00:00-05:00  1.000000  0.253843  0.984516  0.071635  1  \n",
       "2013-01-08 15:00:00-05:00  1.000000  0.344723  0.518904  0.068146  1  \n",
       "...                             ...       ...       ...       ... ..  \n",
       "2018-07-26 15:00:00-04:00  1.000000  0.345889  0.654713  0.078719 -1  \n",
       "2018-07-27 15:00:00-04:00  1.000000  0.287613  0.489824  0.109395  1  \n",
       "2018-07-30 15:00:00-04:00  1.000000  0.369722  0.483388  0.102674 -1  \n",
       "2018-07-31 15:00:00-04:00  0.786664  0.000000  0.157419  0.051675 -1  \n",
       "2018-08-01 15:00:00-04:00  1.000000  0.000000  0.988908  0.105143 -1  \n",
       "\n",
       "[1387 rows x 10 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flip labels for Hinge loss function\n",
    "labels = dataset[9]\n",
    "labels[labels == 0] = -1\n",
    "dataset[9] = labels\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.insert(4, \"3.5\", dataset[8].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (np.reshape(dataset.loc[:,:8].values, (len(dataset),2,5)) * 2.0) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(dataset[9].values, (len(dataset),1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x, all_y = dataset_to_tensor(ds.skip(1200).batch(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([187, 2, 5])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds.take(1200).batch(40)\n",
    "val_ds = ds.skip(1200).take(100).batch(100)\n",
    "test_ds = ds.skip(1300).take(100).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_x, train_df_y = dataset_to_tensor(train_ds)\n",
    "val_df_x, val_df_y = dataset_to_tensor(val_ds)\n",
    "test_df_x, test_df_y = dataset_to_tensor(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1200, 2, 5), dtype=float32, numpy=\n",
       "array([[[-0.21829142,  0.6525677 , -0.6002953 ,  0.01751144,\n",
       "         -0.89748204],\n",
       "        [ 0.00826512,  1.        , -1.        ,  0.2588159 ,\n",
       "         -0.89748204]],\n",
       "\n",
       "       [[ 0.5328901 ,  1.        ,  0.17231701,  0.8862958 ,\n",
       "         -0.7833588 ],\n",
       "        [ 0.8862958 ,  0.8880319 , -1.        , -0.02587597,\n",
       "         -0.7833588 ]],\n",
       "\n",
       "       [[-0.8060177 ,  1.        , -1.        ,  0.26365003,\n",
       "         -0.91258764],\n",
       "        [ 0.26580366,  0.8105657 , -0.31902137,  0.6953861 ,\n",
       "         -0.91258764]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.7239906 ,  1.        , -1.        ,  0.48299602,\n",
       "         -0.92615074],\n",
       "        [ 0.4485232 ,  0.6553491 , -0.44802845, -0.31006503,\n",
       "         -0.92615074]],\n",
       "\n",
       "       [[-0.06215989,  0.37529337, -1.        ,  0.06284009,\n",
       "         -0.9185584 ],\n",
       "        [ 0.12533608,  1.        , -0.24967986,  0.06284009,\n",
       "         -0.9185584 ]],\n",
       "\n",
       "       [[-0.27975342,  1.        , -1.        , -0.5198048 ,\n",
       "         -0.93616796],\n",
       "        [-0.47979409,  0.5201951 , -1.        , -0.27975342,\n",
       "         -0.93616796]]], dtype=float32)>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def roundTan(x):\n",
    "    x = tf.where(x < 0, -1., x)\n",
    "    x = tf.where(x > 0, 1., x)\n",
    "    return x\n",
    "\n",
    "def toSigmoid(x):\n",
    "    return tf.where(x<0, 0., 1.)\n",
    "\n",
    "def dataset_to_tensor(dataset):\n",
    "    # Create an empty list to store the numpy arrays\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    # Loop through the mapdataset\n",
    "    for element in dataset:\n",
    "        # Convert the element to a numpy array and append it to the list\n",
    "        x.append(element[0].numpy())\n",
    "        y.append(element[1].numpy())\n",
    "    \n",
    "    # Return the list of numpy arrays\n",
    "    return tf.cast(np.concatenate(x, axis=0), tf.float32), tf.cast(np.concatenate(y, axis=0), tf.float32)\n",
    "\n",
    "\n",
    "def train(mlmodel, epochs=100000, _callbacks=[]):\n",
    "    \n",
    "    callbacks = tf.keras.callbacks.CallbackList(_callbacks, add_history=True, model=mlmodel)\n",
    "    \n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "      0.001,\n",
    "      decay_steps=1000,\n",
    "      decay_rate=1,\n",
    "      staircase=False)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.SquaredHinge()\n",
    "    val_loss_fn = tf.keras.metrics.SquaredHinge()\n",
    "    metric = tf.keras.losses.MeanSquaredError()\n",
    "    accuracyMetric = tf.keras.metrics.Accuracy()\n",
    "    val_accuracyMetric = tf.keras.metrics.Accuracy()\n",
    "    lamda = tf.constant(0.1, tf.float32)\n",
    "    \n",
    "    \n",
    "    @tf.function  # Make it fast.\n",
    "    def train_on_batch(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "                        \n",
    "            loss = loss_fn(y_pred=tf.nn.tanh(mlmodel(x, training=True)), y_true=y) \n",
    "            regularization_loss=tf.add_n(mlmodel.losses)\n",
    "            loss = loss + regularization_loss * lamda\n",
    "            \n",
    "            #binary_cross_entropy = metric(y_pred=y_pred, y_true=y) \n",
    "            val_model = tf.nn.tanh(mlmodel(val_df_x))\n",
    "            \n",
    "            #val_binary_cross_entropy = metric(y_pred=val_y_pred, y_true=val_y)\n",
    "            val_loss = val_loss_fn(y_pred=val_model, y_true=val_df_y) \n",
    "            \n",
    "            accuracy = accuracyMetric(y_pred=roundTan(mlmodel(x)), y_true=y)\n",
    "            val_accuracy = val_accuracyMetric(y_pred=roundTan(val_model), y_true=val_df_y)\n",
    "            \n",
    "            gradients = tape.gradient(loss, mlmodel.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, mlmodel.trainable_weights))\n",
    "        return {\n",
    "            \"loss\":loss, \n",
    "            \"val_loss\": val_loss, \n",
    "            #\"metric\":binary_cross_entropy, \n",
    "            #\"val_metric\":val_binary_cross_entropy, \n",
    "            \"accuracy\": accuracy,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"regularization_loss\":regularization_loss}\n",
    "\n",
    "\n",
    "    logs = {}\n",
    "    mlmodel.stop_training = False\n",
    "\n",
    "    # Store the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    callbacks.on_train_begin(logs=logs)\n",
    "\n",
    "    # Format training loop\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        callbacks.on_epoch_begin(epoch, logs=logs)\n",
    "        #mlmodel.reset_states() # Not needed?\n",
    "\n",
    "        for batch, (batch_x, batch_y) in enumerate(train_ds):\n",
    "\n",
    "            callbacks.on_batch_begin(batch, logs=logs)\n",
    "            callbacks.on_train_batch_begin(batch, logs=logs)\n",
    "\n",
    "            logs = train_on_batch(batch_x, batch_y)\n",
    "\n",
    "            callbacks.on_train_batch_end(batch, logs=logs)\n",
    "            callbacks.on_batch_end(batch, logs=logs)\n",
    "\n",
    "        callbacks.on_epoch_end(epoch, logs=logs)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            \n",
    "            # Store the end time\n",
    "            end_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            print(f'Step {epoch} - Training Loss: {logs[\"loss\"]}, Val Loss: {logs[\"val_loss\"]}, Accuracy: {logs[\"accuracy\"]}, Val Accuracy: {logs[\"val_accuracy\"]}, Time: {end_time:.2f} sec')\n",
    "\n",
    "        if mlmodel.stop_training:\n",
    "            print(f'Step {epoch} - Training Loss: {logs[\"loss\"]}, Val Loss: {logs[\"val_loss\"]}')\n",
    "            break\n",
    "\n",
    "    callbacks.on_train_end(logs=logs)\n",
    "\n",
    "    # Fetch the history object we normally get from keras.fit\n",
    "    history_object = None\n",
    "    for cb in callbacks:\n",
    "        if isinstance(cb, tf.keras.callbacks.History):\n",
    "            history_object = cb\n",
    "    assert history_object is not None\n",
    "    \n",
    "    return history_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 200000\n",
    "\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, start_from_epoch=500, patience=10000, restore_best_weights=True)\n",
    "# Set up callbacks\n",
    "callbacks = [earlyStopping]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_LABELS = 1\n",
    "HIDDEN_UNITS = 64\n",
    "\n",
    "conv_layer = tf.keras.layers.Conv1D(\n",
    "            filters=HIDDEN_UNITS,\n",
    "            kernel_size=(2,),\n",
    "            kernel_initializer='he_uniform',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "            activation='relu')\n",
    "\n",
    "# Prepare our layer, loss, and optimizer.\n",
    "mlmodel = tf.keras.Sequential(\n",
    "    [\n",
    "        # Shape: (time, features) => (time*features)\n",
    "        conv_layer,\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(NUM_LABELS),\n",
    "    ]\n",
    ")\n",
    "\n",
    "histories[\"64x4\"] = train(mlmodel, TOTAL_EPOCHS, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - Training Loss: 1.4128813743591309, Val Loss: 1.7471652030944824, Accuracy: 0.5016666650772095, Val Accuracy: 0.49266666173934937, Time: 2.91 sec\n",
      "Step 100 - Training Loss: 1.569186806678772, Val Loss: 2.0907607078552246, Accuracy: 0.5271204710006714, Val Accuracy: 0.4748019874095917, Time: 26.14 sec\n",
      "Step 200 - Training Loss: 1.4446502923965454, Val Loss: 2.044947624206543, Accuracy: 0.5248051285743713, Val Accuracy: 0.4874991774559021, Time: 25.90 sec\n",
      "Step 300 - Training Loss: 1.3144476413726807, Val Loss: 2.030014753341675, Accuracy: 0.5240393280982971, Val Accuracy: 0.4916522800922394, Time: 27.64 sec\n",
      "Step 400 - Training Loss: 1.231623649597168, Val Loss: 2.0225298404693604, Accuracy: 0.5236554741859436, Val Accuracy: 0.4937340021133423, Time: 26.93 sec\n",
      "Step 500 - Training Loss: 1.2533795833587646, Val Loss: 2.017914056777954, Accuracy: 0.5149734020233154, Val Accuracy: 0.4949920177459717, Time: 27.67 sec\n",
      "Step 600 - Training Loss: 2.7837541103363037, Val Loss: 2.003514289855957, Accuracy: 0.5122531652450562, Val Accuracy: 0.4986572265625, Time: 29.37 sec\n",
      "Step 700 - Training Loss: 2.8535103797912598, Val Loss: 2.0030128955841064, Accuracy: 0.5073490142822266, Val Accuracy: 0.4988487958908081, Time: 29.21 sec\n",
      "Step 800 - Training Loss: 2.4766199588775635, Val Loss: 2.0055348873138428, Accuracy: 0.5045911073684692, Val Accuracy: 0.4982488453388214, Time: 28.93 sec\n",
      "Step 900 - Training Loss: 1.8087284564971924, Val Loss: 1.9796254634857178, Accuracy: 0.5046457648277283, Val Accuracy: 0.5047218203544617, Time: 26.95 sec\n",
      "Step 1000 - Training Loss: 1.9463984966278076, Val Loss: 1.9715840816497803, Accuracy: 0.5058025121688843, Val Accuracy: 0.5067539215087891, Time: 25.59 sec\n",
      "Step 1100 - Training Loss: 1.341498613357544, Val Loss: 1.97069251537323, Accuracy: 0.5077906250953674, Val Accuracy: 0.5070003271102905, Time: 26.49 sec\n",
      "Step 1200 - Training Loss: 1.3967856168746948, Val Loss: 1.973132848739624, Accuracy: 0.5090153813362122, Val Accuracy: 0.506417453289032, Time: 25.44 sec\n",
      "Step 1300 - Training Loss: 1.2535279989242554, Val Loss: 1.9751667976379395, Accuracy: 0.5100473761558533, Val Accuracy: 0.5059316158294678, Time: 25.99 sec\n",
      "Step 1400 - Training Loss: 1.2479947805404663, Val Loss: 1.9771345853805542, Accuracy: 0.5109368562698364, Val Accuracy: 0.5054582357406616, Time: 25.56 sec\n",
      "Step 1500 - Training Loss: 1.246207356452942, Val Loss: 1.978626012802124, Accuracy: 0.5117055177688599, Val Accuracy: 0.5051016807556152, Time: 24.70 sec\n",
      "Step 1600 - Training Loss: 1.2303754091262817, Val Loss: 1.9799610376358032, Accuracy: 0.5123797655105591, Val Accuracy: 0.504783034324646, Time: 26.05 sec\n",
      "Step 1700 - Training Loss: 1.241901159286499, Val Loss: 1.9807252883911133, Accuracy: 0.5129404067993164, Val Accuracy: 0.5046023726463318, Time: 26.77 sec\n",
      "Step 1800 - Training Loss: 1.6806015968322754, Val Loss: 1.9846798181533813, Accuracy: 0.5133828520774841, Val Accuracy: 0.5036141276359558, Time: 28.06 sec\n",
      "Step 1900 - Training Loss: 1.9950790405273438, Val Loss: 1.9990679025650024, Accuracy: 0.5139681100845337, Val Accuracy: 0.5000126361846924, Time: 26.81 sec\n",
      "Step 2000 - Training Loss: 1.4160406589508057, Val Loss: 2.0099244117736816, Accuracy: 0.5147876143455505, Val Accuracy: 0.4972970187664032, Time: 25.83 sec\n",
      "Step 2100 - Training Loss: 2.4373230934143066, Val Loss: 2.0131988525390625, Accuracy: 0.5148460865020752, Val Accuracy: 0.49647057056427, Time: 27.01 sec\n",
      "Step 2200 - Training Loss: 1.836682677268982, Val Loss: 2.0211942195892334, Accuracy: 0.5156288743019104, Val Accuracy: 0.49447810649871826, Time: 27.00 sec\n",
      "Step 2300 - Training Loss: 1.7300560474395752, Val Loss: 2.0296225547790527, Accuracy: 0.5163472294807434, Val Accuracy: 0.49237924814224243, Time: 26.29 sec\n",
      "Step 2400 - Training Loss: 2.13484525680542, Val Loss: 2.038595199584961, Accuracy: 0.5170761942863464, Val Accuracy: 0.4901425838470459, Time: 26.80 sec\n",
      "Step 2500 - Training Loss: 2.6380507946014404, Val Loss: 2.0407326221466064, Accuracy: 0.5174930095672607, Val Accuracy: 0.48961323499679565, Time: 26.73 sec\n",
      "Step 2600 - Training Loss: 1.8424192667007446, Val Loss: 2.039076089859009, Accuracy: 0.5180485248565674, Val Accuracy: 0.49003100395202637, Time: 28.40 sec\n",
      "Step 2700 - Training Loss: 1.4310991764068604, Val Loss: 2.036719560623169, Accuracy: 0.5184487104415894, Val Accuracy: 0.4906263053417206, Time: 27.95 sec\n",
      "Step 2800 - Training Loss: 2.024421453475952, Val Loss: 2.041785478591919, Accuracy: 0.5190318822860718, Val Accuracy: 0.48936450481414795, Time: 28.60 sec\n",
      "Step 2900 - Training Loss: 2.023869037628174, Val Loss: 2.0481531620025635, Accuracy: 0.5196027159690857, Val Accuracy: 0.4877781271934509, Time: 28.71 sec\n",
      "Step 3000 - Training Loss: 2.2172324657440186, Val Loss: 2.0566956996917725, Accuracy: 0.5201393961906433, Val Accuracy: 0.4856473505496979, Time: 27.61 sec\n",
      "Step 3100 - Training Loss: 1.908516526222229, Val Loss: 2.0657975673675537, Accuracy: 0.5206312537193298, Val Accuracy: 0.4833764433860779, Time: 29.11 sec\n",
      "Step 3200 - Training Loss: 1.7042350769042969, Val Loss: 2.067551374435425, Accuracy: 0.5209859013557434, Val Accuracy: 0.4829421937465668, Time: 26.95 sec\n",
      "Step 3300 - Training Loss: 1.4956891536712646, Val Loss: 2.065439462661743, Accuracy: 0.5210373401641846, Val Accuracy: 0.4834749102592468, Time: 27.85 sec\n",
      "Step 3400 - Training Loss: 1.2899377346038818, Val Loss: 2.063324451446533, Accuracy: 0.5210970044136047, Val Accuracy: 0.48400843143463135, Time: 27.31 sec\n",
      "Step 3500 - Training Loss: 1.4723166227340698, Val Loss: 2.0615158081054688, Accuracy: 0.5211370587348938, Val Accuracy: 0.48446521162986755, Time: 26.54 sec\n",
      "Step 3600 - Training Loss: 1.373551607131958, Val Loss: 2.058336019515991, Accuracy: 0.5212253332138062, Val Accuracy: 0.48526373505592346, Time: 26.72 sec\n",
      "Step 3700 - Training Loss: 1.3739436864852905, Val Loss: 2.05570912361145, Accuracy: 0.5213072896003723, Val Accuracy: 0.485923707485199, Time: 26.55 sec\n",
      "Step 3800 - Training Loss: 1.2750881910324097, Val Loss: 2.0529754161834717, Accuracy: 0.5213757157325745, Val Accuracy: 0.4866103529930115, Time: 28.64 sec\n",
      "Step 3900 - Training Loss: 1.267081618309021, Val Loss: 2.0511345863342285, Accuracy: 0.5213943123817444, Val Accuracy: 0.4870738983154297, Time: 27.54 sec\n",
      "Step 4000 - Training Loss: 1.451553225517273, Val Loss: 2.049856424331665, Accuracy: 0.5214219093322754, Val Accuracy: 0.4873969852924347, Time: 28.60 sec\n",
      "Step 4100 - Training Loss: 1.0421087741851807, Val Loss: 2.048574924468994, Accuracy: 0.5214478373527527, Val Accuracy: 0.4877207279205322, Time: 27.97 sec\n",
      "Step 4200 - Training Loss: 1.4420900344848633, Val Loss: 2.0474185943603516, Accuracy: 0.5214728713035583, Val Accuracy: 0.48801299929618835, Time: 27.24 sec\n",
      "Step 4300 - Training Loss: 1.354872465133667, Val Loss: 2.0453670024871826, Accuracy: 0.5215093493461609, Val Accuracy: 0.4885283410549164, Time: 25.57 sec\n",
      "Step 4400 - Training Loss: 1.4716897010803223, Val Loss: 2.040182590484619, Accuracy: 0.5214971899986267, Val Accuracy: 0.4898229241371155, Time: 26.98 sec\n",
      "Step 4500 - Training Loss: 2.3790388107299805, Val Loss: 2.040433168411255, Accuracy: 0.5216205716133118, Val Accuracy: 0.4897593855857849, Time: 27.73 sec\n",
      "Step 4600 - Training Loss: 2.584951639175415, Val Loss: 2.0413827896118164, Accuracy: 0.5217588543891907, Val Accuracy: 0.48952293395996094, Time: 27.52 sec\n",
      "Step 4700 - Training Loss: 1.786602258682251, Val Loss: 2.0442371368408203, Accuracy: 0.5220098495483398, Val Accuracy: 0.48881053924560547, Time: 24.56 sec\n",
      "Step 4800 - Training Loss: 1.6445426940917969, Val Loss: 2.04742431640625, Accuracy: 0.5222613215446472, Val Accuracy: 0.4880145192146301, Time: 24.71 sec\n",
      "Step 4900 - Training Loss: 1.185526728630066, Val Loss: 2.049055814743042, Accuracy: 0.5223177075386047, Val Accuracy: 0.48760858178138733, Time: 25.64 sec\n",
      "Step 5000 - Training Loss: 1.5859311819076538, Val Loss: 2.0514566898345947, Accuracy: 0.5224272012710571, Val Accuracy: 0.48700979351997375, Time: 25.75 sec\n",
      "Step 5100 - Training Loss: 1.5881705284118652, Val Loss: 2.056555986404419, Accuracy: 0.5226643681526184, Val Accuracy: 0.48573607206344604, Time: 25.55 sec\n",
      "Step 5200 - Training Loss: 1.9848823547363281, Val Loss: 2.0613911151885986, Accuracy: 0.5228726863861084, Val Accuracy: 0.4845276474952698, Time: 25.16 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5300 - Training Loss: 1.7809243202209473, Val Loss: 2.06623911857605, Accuracy: 0.523080050945282, Val Accuracy: 0.48331648111343384, Time: 25.16 sec\n",
      "Step 5400 - Training Loss: 2.1341006755828857, Val Loss: 2.070960283279419, Accuracy: 0.5231185555458069, Val Accuracy: 0.48213744163513184, Time: 26.25 sec\n",
      "Step 5500 - Training Loss: 1.477333426475525, Val Loss: 2.07253360748291, Accuracy: 0.523141086101532, Val Accuracy: 0.48174288868904114, Time: 26.00 sec\n",
      "Step 5600 - Training Loss: 1.4906220436096191, Val Loss: 2.0749170780181885, Accuracy: 0.5231845378875732, Val Accuracy: 0.48114556074142456, Time: 24.73 sec\n",
      "Step 5700 - Training Loss: 1.276725172996521, Val Loss: 2.075991630554199, Accuracy: 0.5231435894966125, Val Accuracy: 0.4808770418167114, Time: 25.40 sec\n",
      "Step 5800 - Training Loss: 1.310171365737915, Val Loss: 2.076775074005127, Accuracy: 0.5230368375778198, Val Accuracy: 0.48068246245384216, Time: 25.75 sec\n",
      "Step 5900 - Training Loss: 1.0835024118423462, Val Loss: 2.0720505714416504, Accuracy: 0.5229208469390869, Val Accuracy: 0.4806537330150604, Time: 26.43 sec\n",
      "Step 6000 - Training Loss: 1.0384057760238647, Val Loss: 2.055819034576416, Accuracy: 0.5228691101074219, Val Accuracy: 0.4806860387325287, Time: 25.51 sec\n",
      "Step 6100 - Training Loss: 1.0134907960891724, Val Loss: 2.038552761077881, Accuracy: 0.5228599309921265, Val Accuracy: 0.4809880256652832, Time: 24.79 sec\n",
      "Step 6200 - Training Loss: 0.9992850422859192, Val Loss: 2.0218045711517334, Accuracy: 0.5228549242019653, Val Accuracy: 0.4812942445278168, Time: 25.04 sec\n",
      "Step 6300 - Training Loss: 0.9849196672439575, Val Loss: 2.0055880546569824, Accuracy: 0.5228492617607117, Val Accuracy: 0.481591135263443, Time: 25.01 sec\n",
      "Step 6400 - Training Loss: 0.9808399081230164, Val Loss: 1.9898782968521118, Accuracy: 0.5228435397148132, Val Accuracy: 0.48187923431396484, Time: 25.31 sec\n",
      "Step 6500 - Training Loss: 0.9836732745170593, Val Loss: 1.9746516942977905, Accuracy: 0.5228358507156372, Val Accuracy: 0.4821615219116211, Time: 25.02 sec\n",
      "Step 6600 - Training Loss: 0.9885884523391724, Val Loss: 1.9598864316940308, Accuracy: 0.5228326320648193, Val Accuracy: 0.4824388325214386, Time: 25.72 sec\n",
      "Step 6700 - Training Loss: 0.97645103931427, Val Loss: 1.9455620050430298, Accuracy: 0.522841215133667, Val Accuracy: 0.4826633930206299, Time: 25.22 sec\n",
      "Step 6800 - Training Loss: 0.9594415426254272, Val Loss: 1.9316586256027222, Accuracy: 0.5228662490844727, Val Accuracy: 0.4827668368816376, Time: 25.03 sec\n",
      "Step 6900 - Training Loss: 0.9785414934158325, Val Loss: 1.9181582927703857, Accuracy: 0.5229246020317078, Val Accuracy: 0.4828948974609375, Time: 25.45 sec\n",
      "Step 7000 - Training Loss: 0.9832661151885986, Val Loss: 1.905043601989746, Accuracy: 0.5230763554573059, Val Accuracy: 0.4831514060497284, Time: 25.10 sec\n",
      "Step 7100 - Training Loss: 0.9812650680541992, Val Loss: 1.8922983407974243, Accuracy: 0.5234560966491699, Val Accuracy: 0.4836595356464386, Time: 25.11 sec\n",
      "Step 7200 - Training Loss: 1.0054210424423218, Val Loss: 1.8799045085906982, Accuracy: 0.5239944458007812, Val Accuracy: 0.4847191572189331, Time: 25.72 sec\n",
      "Step 7300 - Training Loss: 0.9312997460365295, Val Loss: 1.8678354024887085, Accuracy: 0.5246444344520569, Val Accuracy: 0.4859261214733124, Time: 24.87 sec\n",
      "Step 7400 - Training Loss: 0.9702438712120056, Val Loss: 1.8560774326324463, Accuracy: 0.5252068638801575, Val Accuracy: 0.48700153827667236, Time: 25.14 sec\n",
      "Step 7500 - Training Loss: 0.9494919776916504, Val Loss: 1.8445873260498047, Accuracy: 0.5257940888404846, Val Accuracy: 0.48811548948287964, Time: 25.19 sec\n",
      "Step 7600 - Training Loss: 1.0027297735214233, Val Loss: 1.8334063291549683, Accuracy: 0.5263823866844177, Val Accuracy: 0.489082396030426, Time: 25.21 sec\n",
      "Step 7700 - Training Loss: 0.9674606919288635, Val Loss: 1.8225046396255493, Accuracy: 0.5269559025764465, Val Accuracy: 0.4900722801685333, Time: 25.81 sec\n",
      "Step 7800 - Training Loss: 0.9483628273010254, Val Loss: 1.8118665218353271, Accuracy: 0.5275292992591858, Val Accuracy: 0.4910825490951538, Time: 26.89 sec\n",
      "Step 7900 - Training Loss: 1.0064117908477783, Val Loss: 1.801552176475525, Accuracy: 0.5280919075012207, Val Accuracy: 0.4919312000274658, Time: 27.26 sec\n",
      "Step 8000 - Training Loss: 0.9467700123786926, Val Loss: 1.791403889656067, Accuracy: 0.5286933779716492, Val Accuracy: 0.4928428828716278, Time: 26.26 sec\n",
      "Step 8100 - Training Loss: 0.9676679372787476, Val Loss: 1.7814806699752808, Accuracy: 0.5292649865150452, Val Accuracy: 0.4937664866447449, Time: 25.89 sec\n",
      "Step 8200 - Training Loss: 0.9630296230316162, Val Loss: 1.771809458732605, Accuracy: 0.5298282504081726, Val Accuracy: 0.4945795238018036, Time: 26.03 sec\n",
      "Step 8300 - Training Loss: 0.9441523551940918, Val Loss: 1.7624220848083496, Accuracy: 0.5303134322166443, Val Accuracy: 0.49515849351882935, Time: 25.76 sec\n",
      "Step 8400 - Training Loss: 0.9947513937950134, Val Loss: 1.7533069849014282, Accuracy: 0.530754566192627, Val Accuracy: 0.4957972764968872, Time: 25.81 sec\n",
      "Step 8500 - Training Loss: 0.9627841114997864, Val Loss: 1.744372010231018, Accuracy: 0.5311998724937439, Val Accuracy: 0.4964790940284729, Time: 25.53 sec\n",
      "Step 8600 - Training Loss: 0.9434306025505066, Val Loss: 1.7356477975845337, Accuracy: 0.5316624045372009, Val Accuracy: 0.49716877937316895, Time: 25.53 sec\n",
      "Step 8700 - Training Loss: 0.9830840229988098, Val Loss: 1.7271729707717896, Accuracy: 0.532139003276825, Val Accuracy: 0.4977647662162781, Time: 25.84 sec\n",
      "Step 8800 - Training Loss: 0.9327057600021362, Val Loss: 1.7189100980758667, Accuracy: 0.5326216816902161, Val Accuracy: 0.4981902837753296, Time: 26.00 sec\n",
      "Step 8900 - Training Loss: 0.9816636443138123, Val Loss: 1.7107845544815063, Accuracy: 0.5330740809440613, Val Accuracy: 0.4988824427127838, Time: 26.20 sec\n",
      "Step 9000 - Training Loss: 0.929284930229187, Val Loss: 1.702887773513794, Accuracy: 0.53354811668396, Val Accuracy: 0.499397873878479, Time: 27.82 sec\n",
      "Step 9100 - Training Loss: 0.9630823731422424, Val Loss: 1.6951643228530884, Accuracy: 0.534002959728241, Val Accuracy: 0.4999368190765381, Time: 27.35 sec\n",
      "Step 9200 - Training Loss: 0.9378512501716614, Val Loss: 1.687609076499939, Accuracy: 0.5344457030296326, Val Accuracy: 0.5004605650901794, Time: 29.27 sec\n",
      "Step 9300 - Training Loss: 0.9616529941558838, Val Loss: 1.6802113056182861, Accuracy: 0.5348702669143677, Val Accuracy: 0.5009209513664246, Time: 26.72 sec\n",
      "Step 9400 - Training Loss: 0.9791312217712402, Val Loss: 1.672975778579712, Accuracy: 0.5352874398231506, Val Accuracy: 0.5013636350631714, Time: 26.06 sec\n",
      "Step 9500 - Training Loss: 0.9549965858459473, Val Loss: 1.6658926010131836, Accuracy: 0.5357229113578796, Val Accuracy: 0.5016899108886719, Time: 25.40 sec\n",
      "Step 9600 - Training Loss: 0.9996796250343323, Val Loss: 1.6589568853378296, Accuracy: 0.5361350178718567, Val Accuracy: 0.5020038485527039, Time: 25.65 sec\n",
      "Step 9700 - Training Loss: 0.9856685400009155, Val Loss: 1.6521642208099365, Accuracy: 0.5365579128265381, Val Accuracy: 0.5023044943809509, Time: 25.53 sec\n",
      "Step 9800 - Training Loss: 0.9824554324150085, Val Loss: 1.645510196685791, Accuracy: 0.5369719862937927, Val Accuracy: 0.5025566220283508, Time: 25.65 sec\n",
      "Step 9900 - Training Loss: 0.9345458745956421, Val Loss: 1.6389905214309692, Accuracy: 0.5373814105987549, Val Accuracy: 0.5028364658355713, Time: 25.64 sec\n",
      "Step 10000 - Training Loss: 0.9307891726493835, Val Loss: 1.632598638534546, Accuracy: 0.5377821922302246, Val Accuracy: 0.5032493472099304, Time: 25.63 sec\n",
      "Step 10100 - Training Loss: 0.975003182888031, Val Loss: 1.626335859298706, Accuracy: 0.5381740927696228, Val Accuracy: 0.5036109685897827, Time: 26.48 sec\n",
      "Step 10200 - Training Loss: 0.9467915296554565, Val Loss: 1.620195984840393, Accuracy: 0.538561224937439, Val Accuracy: 0.5039675831794739, Time: 26.70 sec\n",
      "Step 10300 - Training Loss: 0.9705930948257446, Val Loss: 1.6141752004623413, Accuracy: 0.5389663577079773, Val Accuracy: 0.5043626427650452, Time: 26.38 sec\n",
      "Step 10400 - Training Loss: 0.9293849468231201, Val Loss: 1.608270287513733, Accuracy: 0.5393581390380859, Val Accuracy: 0.5046350955963135, Time: 25.98 sec\n",
      "Step 10500 - Training Loss: 1.0040520429611206, Val Loss: 1.602477788925171, Accuracy: 0.5397368669509888, Val Accuracy: 0.5049841403961182, Time: 25.46 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10600 - Training Loss: 0.959322988986969, Val Loss: 1.5967944860458374, Accuracy: 0.5400885939598083, Val Accuracy: 0.5053096413612366, Time: 25.39 sec\n",
      "Step 10700 - Training Loss: 0.8980516195297241, Val Loss: 1.5912175178527832, Accuracy: 0.5404479503631592, Val Accuracy: 0.5056734681129456, Time: 26.76 sec\n",
      "Step 10800 - Training Loss: 0.9838892221450806, Val Loss: 1.58574378490448, Accuracy: 0.5408077239990234, Val Accuracy: 0.5060162544250488, Time: 27.26 sec\n",
      "Step 10900 - Training Loss: 0.9678964614868164, Val Loss: 1.580370545387268, Accuracy: 0.5411508083343506, Val Accuracy: 0.506312370300293, Time: 27.65 sec\n",
      "Step 11000 - Training Loss: 1.0597370862960815, Val Loss: 1.5750948190689087, Accuracy: 0.5415011048316956, Val Accuracy: 0.5065907835960388, Time: 26.92 sec\n",
      "Step 11100 - Training Loss: 0.931010901927948, Val Loss: 1.5699143409729004, Accuracy: 0.5418481230735779, Val Accuracy: 0.5069180727005005, Time: 26.48 sec\n",
      "Step 11200 - Training Loss: 0.9318222403526306, Val Loss: 1.564826250076294, Accuracy: 0.5421845316886902, Val Accuracy: 0.5072280168533325, Time: 26.06 sec\n",
      "Step 11300 - Training Loss: 0.9325265884399414, Val Loss: 1.5598281621932983, Accuracy: 0.5425006747245789, Val Accuracy: 0.5076244473457336, Time: 25.72 sec\n",
      "Step 11400 - Training Loss: 0.9539546370506287, Val Loss: 1.554911732673645, Accuracy: 0.5428160429000854, Val Accuracy: 0.5079241991043091, Time: 25.81 sec\n",
      "Step 11500 - Training Loss: 0.942143440246582, Val Loss: 1.5500868558883667, Accuracy: 0.5431228876113892, Val Accuracy: 0.508180558681488, Time: 25.41 sec\n",
      "Step 11600 - Training Loss: 0.9858888983726501, Val Loss: 1.5453428030014038, Accuracy: 0.5434314012527466, Val Accuracy: 0.5085216760635376, Time: 26.72 sec\n",
      "Step 11700 - Training Loss: 0.9160544872283936, Val Loss: 1.540682077407837, Accuracy: 0.5437340140342712, Val Accuracy: 0.5087668895721436, Time: 26.75 sec\n",
      "Step 11800 - Training Loss: 1.015476107597351, Val Loss: 1.5361003875732422, Accuracy: 0.5440331101417542, Val Accuracy: 0.5089439749717712, Time: 25.83 sec\n",
      "Step 11900 - Training Loss: 0.9622408151626587, Val Loss: 1.5315958261489868, Accuracy: 0.5443333387374878, Val Accuracy: 0.5091888308525085, Time: 26.53 sec\n",
      "Step 12000 - Training Loss: 0.9784297347068787, Val Loss: 1.5271661281585693, Accuracy: 0.5446163415908813, Val Accuracy: 0.509407103061676, Time: 25.52 sec\n",
      "Step 12100 - Training Loss: 0.9575029611587524, Val Loss: 1.5228097438812256, Accuracy: 0.544897198677063, Val Accuracy: 0.5096327066421509, Time: 25.57 sec\n",
      "Step 12200 - Training Loss: 0.9713165760040283, Val Loss: 1.5185247659683228, Accuracy: 0.5451590418815613, Val Accuracy: 0.5099257230758667, Time: 25.66 sec\n",
      "Step 12300 - Training Loss: 0.9755319356918335, Val Loss: 1.5143095254898071, Accuracy: 0.5454358458518982, Val Accuracy: 0.510172963142395, Time: 25.30 sec\n",
      "Step 12400 - Training Loss: 0.9550195336341858, Val Loss: 1.5101622343063354, Accuracy: 0.5456809997558594, Val Accuracy: 0.5103917121887207, Time: 25.15 sec\n",
      "Step 12500 - Training Loss: 0.9409528970718384, Val Loss: 1.506081223487854, Accuracy: 0.5459179282188416, Val Accuracy: 0.5105578899383545, Time: 25.16 sec\n",
      "Step 12600 - Training Loss: 0.9366235136985779, Val Loss: 1.5020650625228882, Accuracy: 0.5461390614509583, Val Accuracy: 0.5107524991035461, Time: 25.22 sec\n",
      "Step 12700 - Training Loss: 0.9697784781455994, Val Loss: 1.4981120824813843, Accuracy: 0.5463704466819763, Val Accuracy: 0.5110063552856445, Time: 25.52 sec\n",
      "Step 12800 - Training Loss: 0.963539719581604, Val Loss: 1.4942208528518677, Accuracy: 0.5466077923774719, Val Accuracy: 0.5113127827644348, Time: 25.58 sec\n",
      "Step 12900 - Training Loss: 0.9604043364524841, Val Loss: 1.4903899431228638, Accuracy: 0.5468173623085022, Val Accuracy: 0.5115838050842285, Time: 25.16 sec\n",
      "Step 13000 - Training Loss: 0.9725772142410278, Val Loss: 1.4866180419921875, Accuracy: 0.5470110774040222, Val Accuracy: 0.511884331703186, Time: 25.50 sec\n",
      "Step 13100 - Training Loss: 0.9104029536247253, Val Loss: 1.4829037189483643, Accuracy: 0.547249972820282, Val Accuracy: 0.5121639370918274, Time: 25.36 sec\n",
      "Step 13200 - Training Loss: 0.9106446504592896, Val Loss: 1.479245662689209, Accuracy: 0.5474770665168762, Val Accuracy: 0.5123996734619141, Time: 25.11 sec\n",
      "Step 13300 - Training Loss: 0.9637386798858643, Val Loss: 1.4756420850753784, Accuracy: 0.5476494431495667, Val Accuracy: 0.5126516819000244, Time: 25.63 sec\n",
      "Step 13400 - Training Loss: 0.9432846903800964, Val Loss: 1.472091794013977, Accuracy: 0.5478529930114746, Val Accuracy: 0.5128834247589111, Time: 25.20 sec\n",
      "Step 13500 - Training Loss: 0.9539990425109863, Val Loss: 1.468595027923584, Accuracy: 0.5480511784553528, Val Accuracy: 0.5131494402885437, Time: 26.16 sec\n",
      "Step 13600 - Training Loss: 0.9591951966285706, Val Loss: 1.4651497602462769, Accuracy: 0.5482518672943115, Val Accuracy: 0.513371467590332, Time: 30.91 sec\n",
      "Step 13700 - Training Loss: 0.9975699782371521, Val Loss: 1.4617546796798706, Accuracy: 0.5484728813171387, Val Accuracy: 0.5135294198989868, Time: 36.86 sec\n",
      "Step 13800 - Training Loss: 0.9303244948387146, Val Loss: 1.4584089517593384, Accuracy: 0.5487013459205627, Val Accuracy: 0.5136969089508057, Time: 35.06 sec\n",
      "Step 13900 - Training Loss: 0.9617902636528015, Val Loss: 1.4551112651824951, Accuracy: 0.5489092469215393, Val Accuracy: 0.513820230960846, Time: 35.18 sec\n",
      "Step 14000 - Training Loss: 1.0034829378128052, Val Loss: 1.4518606662750244, Accuracy: 0.549112856388092, Val Accuracy: 0.5139369964599609, Time: 33.41 sec\n",
      "Step 14100 - Training Loss: 0.9865133762359619, Val Loss: 1.4486562013626099, Accuracy: 0.5493137836456299, Val Accuracy: 0.5141134262084961, Time: 34.40 sec\n",
      "Step 14200 - Training Loss: 0.9811773300170898, Val Loss: 1.445496916770935, Accuracy: 0.549512505531311, Val Accuracy: 0.5142592787742615, Time: 33.81 sec\n",
      "Step 14300 - Training Loss: 0.9448177218437195, Val Loss: 1.442381739616394, Accuracy: 0.5497130155563354, Val Accuracy: 0.5143839120864868, Time: 33.83 sec\n",
      "Step 14400 - Training Loss: 0.9745367765426636, Val Loss: 1.43930983543396, Accuracy: 0.5498759746551514, Val Accuracy: 0.5145977139472961, Time: 34.07 sec\n",
      "Step 14500 - Training Loss: 0.9611802697181702, Val Loss: 1.436280369758606, Accuracy: 0.5500528812408447, Val Accuracy: 0.5147366523742676, Time: 34.02 sec\n",
      "Step 14600 - Training Loss: 0.957550585269928, Val Loss: 1.4332882165908813, Accuracy: 0.550214946269989, Val Accuracy: 0.5149176716804504, Time: 34.05 sec\n",
      "Step 14700 - Training Loss: 1.004577398300171, Val Loss: 1.4303408861160278, Accuracy: 0.5503693222999573, Val Accuracy: 0.5150502324104309, Time: 33.92 sec\n",
      "Step 14800 - Training Loss: 0.9899495840072632, Val Loss: 1.4274333715438843, Accuracy: 0.5505430102348328, Val Accuracy: 0.5151461958885193, Time: 33.63 sec\n",
      "Step 14900 - Training Loss: 0.9547790884971619, Val Loss: 1.4245648384094238, Accuracy: 0.5507134199142456, Val Accuracy: 0.515247106552124, Time: 32.90 sec\n",
      "Step 15000 - Training Loss: 0.9632523655891418, Val Loss: 1.4217346906661987, Accuracy: 0.5508875250816345, Val Accuracy: 0.5153679251670837, Time: 33.25 sec\n",
      "Step 15100 - Training Loss: 0.9570608735084534, Val Loss: 1.418939232826233, Accuracy: 0.551041305065155, Val Accuracy: 0.5154818892478943, Time: 33.40 sec\n",
      "Step 15200 - Training Loss: 0.9276480674743652, Val Loss: 1.4161832332611084, Accuracy: 0.551192045211792, Val Accuracy: 0.5156446695327759, Time: 33.03 sec\n",
      "Step 15300 - Training Loss: 0.9238834977149963, Val Loss: 1.4134632349014282, Accuracy: 0.5513407588005066, Val Accuracy: 0.5157975554466248, Time: 33.75 sec\n",
      "Step 15400 - Training Loss: 0.9250422716140747, Val Loss: 1.4107786417007446, Accuracy: 0.5515248775482178, Val Accuracy: 0.5158419013023376, Time: 34.54 sec\n",
      "Step 15500 - Training Loss: 0.9660890102386475, Val Loss: 1.4081286191940308, Accuracy: 0.5516893267631531, Val Accuracy: 0.515826940536499, Time: 33.57 sec\n",
      "Step 15600 - Training Loss: 0.9816364049911499, Val Loss: 1.4055125713348389, Accuracy: 0.5518513917922974, Val Accuracy: 0.5158811807632446, Time: 33.80 sec\n",
      "Step 15700 - Training Loss: 0.9530760049819946, Val Loss: 1.4029297828674316, Accuracy: 0.5519869923591614, Val Accuracy: 0.5159853100776672, Time: 33.60 sec\n",
      "Step 15800 - Training Loss: 0.9285786747932434, Val Loss: 1.4003797769546509, Accuracy: 0.5521629452705383, Val Accuracy: 0.5160427093505859, Time: 33.23 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15900 - Training Loss: 0.9793992042541504, Val Loss: 1.3978618383407593, Accuracy: 0.5523133873939514, Val Accuracy: 0.516116201877594, Time: 33.21 sec\n",
      "Step 16000 - Training Loss: 0.948866069316864, Val Loss: 1.395375370979309, Accuracy: 0.5524501800537109, Val Accuracy: 0.5162891745567322, Time: 33.59 sec\n",
      "Step 16100 - Training Loss: 0.9259026646614075, Val Loss: 1.3927762508392334, Accuracy: 0.5525863170623779, Val Accuracy: 0.5164667367935181, Time: 34.05 sec\n",
      "Step 16200 - Training Loss: 0.9413063526153564, Val Loss: 1.3901461362838745, Accuracy: 0.5527216196060181, Val Accuracy: 0.5166378021240234, Time: 33.09 sec\n",
      "Step 16300 - Training Loss: 1.002831220626831, Val Loss: 1.3875141143798828, Accuracy: 0.5528481006622314, Val Accuracy: 0.5168536305427551, Time: 33.10 sec\n",
      "Step 16400 - Training Loss: 0.9737650156021118, Val Loss: 1.3850101232528687, Accuracy: 0.5529791712760925, Val Accuracy: 0.5169628858566284, Time: 33.91 sec\n",
      "Step 16500 - Training Loss: 0.9636158347129822, Val Loss: 1.3827637434005737, Accuracy: 0.5531027317047119, Val Accuracy: 0.5169656276702881, Time: 34.48 sec\n",
      "Step 16600 - Training Loss: 0.9103839993476868, Val Loss: 1.3802239894866943, Accuracy: 0.5532432198524475, Val Accuracy: 0.5170899033546448, Time: 33.64 sec\n",
      "Step 16700 - Training Loss: 0.9322706460952759, Val Loss: 1.3777453899383545, Accuracy: 0.5533832907676697, Val Accuracy: 0.5172359943389893, Time: 34.12 sec\n",
      "Step 16800 - Training Loss: 0.9014676809310913, Val Loss: 1.3753749132156372, Accuracy: 0.553529679775238, Val Accuracy: 0.5173149108886719, Time: 33.39 sec\n",
      "Step 16900 - Training Loss: 0.9372841119766235, Val Loss: 1.3729426860809326, Accuracy: 0.5536721348762512, Val Accuracy: 0.5174596905708313, Time: 33.56 sec\n",
      "Step 17000 - Training Loss: 0.9502654075622559, Val Loss: 1.3705984354019165, Accuracy: 0.5537983775138855, Val Accuracy: 0.5175774097442627, Time: 33.69 sec\n",
      "Step 17100 - Training Loss: 0.9714446663856506, Val Loss: 1.3682183027267456, Accuracy: 0.5539374351501465, Val Accuracy: 0.5177313089370728, Time: 34.64 sec\n",
      "Step 17200 - Training Loss: 1.0068767070770264, Val Loss: 1.365861177444458, Accuracy: 0.5540759563446045, Val Accuracy: 0.5178805589675903, Time: 33.88 sec\n",
      "Step 17300 - Training Loss: 0.9593946933746338, Val Loss: 1.3635153770446777, Accuracy: 0.5542126893997192, Val Accuracy: 0.5180442929267883, Time: 33.76 sec\n",
      "Step 17400 - Training Loss: 0.9497479200363159, Val Loss: 1.3612221479415894, Accuracy: 0.5543287396430969, Val Accuracy: 0.5181627869606018, Time: 33.52 sec\n",
      "Step 17500 - Training Loss: 0.9104928374290466, Val Loss: 1.3589318990707397, Accuracy: 0.5544689297676086, Val Accuracy: 0.518311083316803, Time: 34.21 sec\n",
      "Step 17600 - Training Loss: 0.9968850612640381, Val Loss: 1.3566653728485107, Accuracy: 0.5545802116394043, Val Accuracy: 0.5185300707817078, Time: 33.36 sec\n",
      "Step 17700 - Training Loss: 0.942049503326416, Val Loss: 1.3544244766235352, Accuracy: 0.554699182510376, Val Accuracy: 0.5187085270881653, Time: 33.34 sec\n",
      "Step 17800 - Training Loss: 0.9302834272384644, Val Loss: 1.352216124534607, Accuracy: 0.5548144578933716, Val Accuracy: 0.5188433527946472, Time: 33.25 sec\n",
      "Step 17900 - Training Loss: 0.9670332074165344, Val Loss: 1.3501331806182861, Accuracy: 0.5549128651618958, Val Accuracy: 0.5189794301986694, Time: 33.77 sec\n",
      "Step 18000 - Training Loss: 0.9960956573486328, Val Loss: 1.3482495546340942, Accuracy: 0.5550187230110168, Val Accuracy: 0.5190056562423706, Time: 33.81 sec\n",
      "Step 18100 - Training Loss: 0.9505683183670044, Val Loss: 1.3462190628051758, Accuracy: 0.5551226139068604, Val Accuracy: 0.5190525650978088, Time: 33.68 sec\n",
      "Step 18200 - Training Loss: 0.99929279088974, Val Loss: 1.3441078662872314, Accuracy: 0.5552291870117188, Val Accuracy: 0.5191594362258911, Time: 34.05 sec\n",
      "Step 18300 - Training Loss: 0.983205258846283, Val Loss: 1.342018485069275, Accuracy: 0.555337131023407, Val Accuracy: 0.5193368196487427, Time: 34.21 sec\n",
      "Step 18400 - Training Loss: 0.9681342840194702, Val Loss: 1.3399423360824585, Accuracy: 0.5554500818252563, Val Accuracy: 0.5195105075836182, Time: 26.22 sec\n",
      "Step 18500 - Training Loss: 0.9715947508811951, Val Loss: 1.3378887176513672, Accuracy: 0.5555599927902222, Val Accuracy: 0.5196657180786133, Time: 25.76 sec\n",
      "Step 18600 - Training Loss: 0.9443517923355103, Val Loss: 1.3358758687973022, Accuracy: 0.5556525588035583, Val Accuracy: 0.519828200340271, Time: 25.66 sec\n",
      "Step 18700 - Training Loss: 0.9397975206375122, Val Loss: 1.3338675498962402, Accuracy: 0.5557470917701721, Val Accuracy: 0.5199854373931885, Time: 25.32 sec\n",
      "Step 18800 - Training Loss: 0.9617194533348083, Val Loss: 1.331878900527954, Accuracy: 0.5558305382728577, Val Accuracy: 0.5201740860939026, Time: 25.45 sec\n",
      "Step 18900 - Training Loss: 0.9122833609580994, Val Loss: 1.329918384552002, Accuracy: 0.5559192299842834, Val Accuracy: 0.520359992980957, Time: 26.00 sec\n",
      "Step 19000 - Training Loss: 0.9414573907852173, Val Loss: 1.3279714584350586, Accuracy: 0.5560080409049988, Val Accuracy: 0.5205309987068176, Time: 25.84 sec\n",
      "Step 19100 - Training Loss: 0.9811309576034546, Val Loss: 1.326045036315918, Accuracy: 0.5561217665672302, Val Accuracy: 0.5206926465034485, Time: 25.41 sec\n",
      "Step 19200 - Training Loss: 0.964275062084198, Val Loss: 1.3242089748382568, Accuracy: 0.556218147277832, Val Accuracy: 0.5207719802856445, Time: 25.04 sec\n",
      "Step 19300 - Training Loss: 0.960477888584137, Val Loss: 1.3223328590393066, Accuracy: 0.5563145875930786, Val Accuracy: 0.5208688378334045, Time: 25.11 sec\n",
      "Step 19400 - Training Loss: 0.9908099174499512, Val Loss: 1.3204792737960815, Accuracy: 0.5564082264900208, Val Accuracy: 0.5210121273994446, Time: 25.27 sec\n",
      "Step 19500 - Training Loss: 0.9900604486465454, Val Loss: 1.3186330795288086, Accuracy: 0.5564955472946167, Val Accuracy: 0.5211087465286255, Time: 25.33 sec\n",
      "Step 19600 - Training Loss: 0.9495998620986938, Val Loss: 1.3168865442276, Accuracy: 0.5565694570541382, Val Accuracy: 0.5211689472198486, Time: 25.35 sec\n",
      "Step 19700 - Training Loss: 0.9539685845375061, Val Loss: 1.3151500225067139, Accuracy: 0.556662917137146, Val Accuracy: 0.5212550759315491, Time: 25.14 sec\n",
      "Step 19800 - Training Loss: 0.9919142127037048, Val Loss: 1.3133920431137085, Accuracy: 0.5567672252655029, Val Accuracy: 0.5213340520858765, Time: 25.42 sec\n",
      "Step 19900 - Training Loss: 0.9931250214576721, Val Loss: 1.3117183446884155, Accuracy: 0.5568679571151733, Val Accuracy: 0.521371066570282, Time: 26.31 sec\n",
      "Step 20000 - Training Loss: 0.9587071537971497, Val Loss: 1.3099634647369385, Accuracy: 0.5569536089897156, Val Accuracy: 0.5214333534240723, Time: 26.79 sec\n",
      "Step 20100 - Training Loss: 0.9473284482955933, Val Loss: 1.308240294456482, Accuracy: 0.5570332407951355, Val Accuracy: 0.5215358734130859, Time: 26.59 sec\n",
      "Step 20200 - Training Loss: 0.9519854187965393, Val Loss: 1.3065217733383179, Accuracy: 0.5571233034133911, Val Accuracy: 0.5216432809829712, Time: 25.85 sec\n",
      "Step 20300 - Training Loss: 0.9513732194900513, Val Loss: 1.304832100868225, Accuracy: 0.5572143793106079, Val Accuracy: 0.5217300057411194, Time: 26.81 sec\n",
      "Step 20400 - Training Loss: 0.9535021781921387, Val Loss: 1.3031444549560547, Accuracy: 0.5572992563247681, Val Accuracy: 0.5218431949615479, Time: 26.81 sec\n",
      "Step 20500 - Training Loss: 0.9597553014755249, Val Loss: 1.3014706373214722, Accuracy: 0.5573848485946655, Val Accuracy: 0.521909236907959, Time: 26.17 sec\n",
      "Step 20600 - Training Loss: 0.9815059304237366, Val Loss: 1.2998144626617432, Accuracy: 0.5574694871902466, Val Accuracy: 0.5220277309417725, Time: 27.40 sec\n",
      "Step 20700 - Training Loss: 0.9676794409751892, Val Loss: 1.2981903553009033, Accuracy: 0.5575564503669739, Val Accuracy: 0.522142767906189, Time: 28.60 sec\n",
      "Step 20800 - Training Loss: 0.9100657105445862, Val Loss: 1.296571135520935, Accuracy: 0.5576438307762146, Val Accuracy: 0.5222302675247192, Time: 27.45 sec\n",
      "Step 20900 - Training Loss: 0.9600093960762024, Val Loss: 1.294988989830017, Accuracy: 0.5577208995819092, Val Accuracy: 0.5223325490951538, Time: 27.95 sec\n",
      "Step 21000 - Training Loss: 0.935544490814209, Val Loss: 1.2934050559997559, Accuracy: 0.5577899813652039, Val Accuracy: 0.5224544405937195, Time: 28.52 sec\n",
      "Step 21100 - Training Loss: 0.9421315789222717, Val Loss: 1.29183828830719, Accuracy: 0.5578691363334656, Val Accuracy: 0.5225493311882019, Time: 28.03 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21200 - Training Loss: 1.0080476999282837, Val Loss: 1.2902730703353882, Accuracy: 0.5579460263252258, Val Accuracy: 0.522670567035675, Time: 28.15 sec\n",
      "Step 21300 - Training Loss: 0.9322990775108337, Val Loss: 1.2887386083602905, Accuracy: 0.5580172538757324, Val Accuracy: 0.5227648019790649, Time: 27.59 sec\n",
      "Step 21400 - Training Loss: 0.9210122227668762, Val Loss: 1.287214756011963, Accuracy: 0.558103621006012, Val Accuracy: 0.5228488445281982, Time: 28.60 sec\n",
      "Step 21500 - Training Loss: 0.9777243137359619, Val Loss: 1.2856959104537964, Accuracy: 0.5581836700439453, Val Accuracy: 0.5229693055152893, Time: 27.99 sec\n",
      "Step 21600 - Training Loss: 0.9355846643447876, Val Loss: 1.2841880321502686, Accuracy: 0.5582623481750488, Val Accuracy: 0.5231232047080994, Time: 28.29 sec\n",
      "Step 21700 - Training Loss: 0.9957861304283142, Val Loss: 1.2827129364013672, Accuracy: 0.5583327412605286, Val Accuracy: 0.5232357382774353, Time: 29.37 sec\n",
      "Step 21800 - Training Loss: 0.9363264441490173, Val Loss: 1.2812327146530151, Accuracy: 0.5584144592285156, Val Accuracy: 0.5233858227729797, Time: 28.73 sec\n",
      "Step 21900 - Training Loss: 0.9887768626213074, Val Loss: 1.2797915935516357, Accuracy: 0.5584956407546997, Val Accuracy: 0.5235015749931335, Time: 28.00 sec\n",
      "Step 22000 - Training Loss: 1.0270737409591675, Val Loss: 1.278387188911438, Accuracy: 0.5585761070251465, Val Accuracy: 0.5235623717308044, Time: 27.19 sec\n",
      "Step 22100 - Training Loss: 0.9639186859130859, Val Loss: 1.276949167251587, Accuracy: 0.5586737990379333, Val Accuracy: 0.5236671566963196, Time: 26.51 sec\n",
      "Step 22200 - Training Loss: 0.9306465983390808, Val Loss: 1.275578498840332, Accuracy: 0.558761715888977, Val Accuracy: 0.5237317085266113, Time: 27.04 sec\n",
      "Step 22300 - Training Loss: 0.9737406969070435, Val Loss: 1.274165153503418, Accuracy: 0.5588388442993164, Val Accuracy: 0.5238533616065979, Time: 27.28 sec\n",
      "Step 22400 - Training Loss: 0.9527748823165894, Val Loss: 1.272839903831482, Accuracy: 0.5589101314544678, Val Accuracy: 0.5239845514297485, Time: 27.88 sec\n",
      "Step 22500 - Training Loss: 0.9475767016410828, Val Loss: 1.271691918373108, Accuracy: 0.5589838624000549, Val Accuracy: 0.5241789221763611, Time: 26.37 sec\n",
      "Step 22600 - Training Loss: 0.9478206038475037, Val Loss: 1.2705398797988892, Accuracy: 0.5590541958808899, Val Accuracy: 0.5243529677391052, Time: 26.95 sec\n",
      "Step 22700 - Training Loss: 0.948013961315155, Val Loss: 1.2694059610366821, Accuracy: 0.55912184715271, Val Accuracy: 0.5245380401611328, Time: 25.95 sec\n",
      "Step 22800 - Training Loss: 0.9906139969825745, Val Loss: 1.2683284282684326, Accuracy: 0.559190034866333, Val Accuracy: 0.5246747732162476, Time: 26.22 sec\n",
      "Step 22900 - Training Loss: 0.9780269861221313, Val Loss: 1.2672275304794312, Accuracy: 0.5592591166496277, Val Accuracy: 0.5248238444328308, Time: 27.18 sec\n",
      "Step 23000 - Training Loss: 0.9466894268989563, Val Loss: 1.2661142349243164, Accuracy: 0.5593264698982239, Val Accuracy: 0.5249933004379272, Time: 26.45 sec\n",
      "Step 23100 - Training Loss: 0.9250199794769287, Val Loss: 1.2650154829025269, Accuracy: 0.5593888759613037, Val Accuracy: 0.5251522064208984, Time: 26.71 sec\n",
      "Step 23200 - Training Loss: 0.9692988991737366, Val Loss: 1.2639260292053223, Accuracy: 0.5594645142555237, Val Accuracy: 0.5253270268440247, Time: 26.52 sec\n",
      "Step 23300 - Training Loss: 0.9684597253799438, Val Loss: 1.2629287242889404, Accuracy: 0.5595272779464722, Val Accuracy: 0.5254579782485962, Time: 26.38 sec\n",
      "Step 23400 - Training Loss: 0.941297709941864, Val Loss: 1.2618571519851685, Accuracy: 0.5595790147781372, Val Accuracy: 0.5256541967391968, Time: 26.42 sec\n",
      "Step 23500 - Training Loss: 0.9342939257621765, Val Loss: 1.2608442306518555, Accuracy: 0.5596482753753662, Val Accuracy: 0.5258010029792786, Time: 26.43 sec\n",
      "Step 23600 - Training Loss: 0.9678109884262085, Val Loss: 1.2597988843917847, Accuracy: 0.5597139596939087, Val Accuracy: 0.5259671211242676, Time: 26.88 sec\n",
      "Step 23700 - Training Loss: 0.9282691478729248, Val Loss: 1.258745551109314, Accuracy: 0.5597928166389465, Val Accuracy: 0.5261537432670593, Time: 27.17 sec\n",
      "Step 23800 - Training Loss: 0.9280444383621216, Val Loss: 1.2577029466629028, Accuracy: 0.559856653213501, Val Accuracy: 0.5263242125511169, Time: 27.25 sec\n",
      "Step 23900 - Training Loss: 0.9274529814720154, Val Loss: 1.2566959857940674, Accuracy: 0.5599120855331421, Val Accuracy: 0.5264452695846558, Time: 26.68 sec\n",
      "Step 24000 - Training Loss: 0.9475795030593872, Val Loss: 1.2556743621826172, Accuracy: 0.5599684119224548, Val Accuracy: 0.5266162753105164, Time: 27.27 sec\n",
      "Step 24100 - Training Loss: 0.9277565479278564, Val Loss: 1.2546974420547485, Accuracy: 0.5600162148475647, Val Accuracy: 0.5267524123191833, Time: 26.75 sec\n",
      "Step 24200 - Training Loss: 0.9537525773048401, Val Loss: 1.2537020444869995, Accuracy: 0.5600810050964355, Val Accuracy: 0.5269015431404114, Time: 27.87 sec\n",
      "Step 24300 - Training Loss: 0.942455530166626, Val Loss: 1.2529017925262451, Accuracy: 0.5601303577423096, Val Accuracy: 0.5269460678100586, Time: 27.58 sec\n",
      "Step 24400 - Training Loss: 0.9287350177764893, Val Loss: 1.2521309852600098, Accuracy: 0.560203492641449, Val Accuracy: 0.5270078778266907, Time: 28.16 sec\n",
      "Step 24500 - Training Loss: 0.9782750606536865, Val Loss: 1.2512599229812622, Accuracy: 0.5602641701698303, Val Accuracy: 0.5270974636077881, Time: 28.09 sec\n",
      "Step 24600 - Training Loss: 0.968457043170929, Val Loss: 1.2504873275756836, Accuracy: 0.5603305101394653, Val Accuracy: 0.5271850228309631, Time: 28.12 sec\n",
      "Step 24700 - Training Loss: 0.9253084659576416, Val Loss: 1.2495414018630981, Accuracy: 0.5603910088539124, Val Accuracy: 0.5273494124412537, Time: 26.69 sec\n",
      "Step 24800 - Training Loss: 0.9325447082519531, Val Loss: 1.248587727546692, Accuracy: 0.5604604482650757, Val Accuracy: 0.5274692177772522, Time: 26.71 sec\n",
      "Step 24900 - Training Loss: 0.9495233297348022, Val Loss: 1.247625708580017, Accuracy: 0.5605155229568481, Val Accuracy: 0.5276570916175842, Time: 27.34 sec\n",
      "Step 25000 - Training Loss: 0.9381073117256165, Val Loss: 1.2467067241668701, Accuracy: 0.5605784058570862, Val Accuracy: 0.5278244018554688, Time: 26.39 sec\n",
      "Step 25100 - Training Loss: 0.9550982713699341, Val Loss: 1.2457664012908936, Accuracy: 0.5606298446655273, Val Accuracy: 0.5280138254165649, Time: 26.02 sec\n",
      "Step 25200 - Training Loss: 1.0089222192764282, Val Loss: 1.2448259592056274, Accuracy: 0.560687780380249, Val Accuracy: 0.5281816720962524, Time: 26.37 sec\n",
      "Step 25300 - Training Loss: 0.9116207957267761, Val Loss: 1.2438956499099731, Accuracy: 0.5607553124427795, Val Accuracy: 0.5283488035202026, Time: 25.68 sec\n",
      "Step 25400 - Training Loss: 0.9458553194999695, Val Loss: 1.2429699897766113, Accuracy: 0.5608025789260864, Val Accuracy: 0.5285212993621826, Time: 25.19 sec\n",
      "Step 25500 - Training Loss: 0.9477959871292114, Val Loss: 1.2420774698257446, Accuracy: 0.5608475208282471, Val Accuracy: 0.5286564230918884, Time: 26.56 sec\n",
      "Step 25600 - Training Loss: 0.9813114404678345, Val Loss: 1.241167664527893, Accuracy: 0.5608963370323181, Val Accuracy: 0.5288002490997314, Time: 27.50 sec\n",
      "Step 25700 - Training Loss: 0.9220600724220276, Val Loss: 1.2402812242507935, Accuracy: 0.5609546899795532, Val Accuracy: 0.5289688110351562, Time: 28.26 sec\n",
      "Step 25800 - Training Loss: 0.9981220364570618, Val Loss: 1.2393823862075806, Accuracy: 0.5610096454620361, Val Accuracy: 0.5291606187820435, Time: 28.88 sec\n",
      "Step 25900 - Training Loss: 0.9423657655715942, Val Loss: 1.238491177558899, Accuracy: 0.5610601902008057, Val Accuracy: 0.5293456315994263, Time: 28.07 sec\n",
      "Step 26000 - Training Loss: 0.9754473567008972, Val Loss: 1.2376056909561157, Accuracy: 0.5611162185668945, Val Accuracy: 0.5295175313949585, Time: 29.00 sec\n",
      "Step 26100 - Training Loss: 0.9684895873069763, Val Loss: 1.2367643117904663, Accuracy: 0.5611622929573059, Val Accuracy: 0.52964186668396, Time: 28.41 sec\n",
      "Step 26200 - Training Loss: 0.9855583310127258, Val Loss: 1.2358916997909546, Accuracy: 0.5612145662307739, Val Accuracy: 0.5298000574111938, Time: 28.78 sec\n",
      "Step 26300 - Training Loss: 0.9616055488586426, Val Loss: 1.2350255250930786, Accuracy: 0.5612680315971375, Val Accuracy: 0.5299635529518127, Time: 29.08 sec\n",
      "Step 26400 - Training Loss: 0.9529708027839661, Val Loss: 1.234203577041626, Accuracy: 0.5613138675689697, Val Accuracy: 0.5300881862640381, Time: 30.95 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26500 - Training Loss: 0.9797714948654175, Val Loss: 1.2333505153656006, Accuracy: 0.5613670945167542, Val Accuracy: 0.5302581191062927, Time: 35.33 sec\n",
      "Step 26600 - Training Loss: 0.9294916391372681, Val Loss: 1.2325496673583984, Accuracy: 0.5614163875579834, Val Accuracy: 0.5303751826286316, Time: 37.03 sec\n",
      "Step 26700 - Training Loss: 0.9672417640686035, Val Loss: 1.2317310571670532, Accuracy: 0.561487078666687, Val Accuracy: 0.5304515957832336, Time: 32.05 sec\n",
      "Step 26800 - Training Loss: 0.9793763160705566, Val Loss: 1.2308995723724365, Accuracy: 0.561549723148346, Val Accuracy: 0.5305850505828857, Time: 29.46 sec\n",
      "Step 26900 - Training Loss: 0.9298467040061951, Val Loss: 1.230088710784912, Accuracy: 0.5616089701652527, Val Accuracy: 0.5307413339614868, Time: 29.53 sec\n",
      "Step 27000 - Training Loss: 0.9447996020317078, Val Loss: 1.2292910814285278, Accuracy: 0.5616636276245117, Val Accuracy: 0.5308849215507507, Time: 28.66 sec\n",
      "Step 27100 - Training Loss: 0.9263113141059875, Val Loss: 1.2284817695617676, Accuracy: 0.5617188811302185, Val Accuracy: 0.5310212969779968, Time: 30.07 sec\n",
      "Step 27200 - Training Loss: 0.9476948976516724, Val Loss: 1.2277016639709473, Accuracy: 0.5617622137069702, Val Accuracy: 0.5311406254768372, Time: 29.36 sec\n",
      "Step 27300 - Training Loss: 0.9806510806083679, Val Loss: 1.226901888847351, Accuracy: 0.5618050694465637, Val Accuracy: 0.5312773585319519, Time: 34.30 sec\n",
      "Step 27400 - Training Loss: 0.9531660676002502, Val Loss: 1.2261154651641846, Accuracy: 0.5618577003479004, Val Accuracy: 0.5313544273376465, Time: 32.36 sec\n",
      "Step 27500 - Training Loss: 1.0072717666625977, Val Loss: 1.2253419160842896, Accuracy: 0.5619086623191833, Val Accuracy: 0.5314843654632568, Time: 31.02 sec\n",
      "Step 27600 - Training Loss: 0.9546874761581421, Val Loss: 1.224564552307129, Accuracy: 0.5619663596153259, Val Accuracy: 0.5316024422645569, Time: 29.83 sec\n",
      "Step 27700 - Training Loss: 0.965050458908081, Val Loss: 1.2238308191299438, Accuracy: 0.5620201230049133, Val Accuracy: 0.531684160232544, Time: 28.90 sec\n",
      "Step 27800 - Training Loss: 1.0297551155090332, Val Loss: 1.2231122255325317, Accuracy: 0.562067449092865, Val Accuracy: 0.5317626595497131, Time: 30.14 sec\n",
      "Step 27900 - Training Loss: 0.9434125423431396, Val Loss: 1.222428321838379, Accuracy: 0.5621049404144287, Val Accuracy: 0.5318459868431091, Time: 29.43 sec\n",
      "Step 28000 - Training Loss: 0.9091827273368835, Val Loss: 1.2217105627059937, Accuracy: 0.562154233455658, Val Accuracy: 0.5319701433181763, Time: 29.19 sec\n",
      "Step 28100 - Training Loss: 0.9465936422348022, Val Loss: 1.2210179567337036, Accuracy: 0.562212347984314, Val Accuracy: 0.5320761203765869, Time: 29.49 sec\n",
      "Step 28200 - Training Loss: 0.930589497089386, Val Loss: 1.2202601432800293, Accuracy: 0.5622657537460327, Val Accuracy: 0.5322242379188538, Time: 30.67 sec\n",
      "Step 28300 - Training Loss: 0.9757000803947449, Val Loss: 1.2195255756378174, Accuracy: 0.5623114705085754, Val Accuracy: 0.532360315322876, Time: 30.03 sec\n",
      "Step 28400 - Training Loss: 0.992853581905365, Val Loss: 1.218780517578125, Accuracy: 0.5623648166656494, Val Accuracy: 0.5324585437774658, Time: 28.13 sec\n",
      "Step 28500 - Training Loss: 0.9330544471740723, Val Loss: 1.2180373668670654, Accuracy: 0.5624184012413025, Val Accuracy: 0.5325800180435181, Time: 28.31 sec\n",
      "Step 28600 - Training Loss: 1.019816279411316, Val Loss: 1.217313528060913, Accuracy: 0.5624611973762512, Val Accuracy: 0.5327259302139282, Time: 28.13 sec\n",
      "Step 28700 - Training Loss: 1.0118515491485596, Val Loss: 1.2165837287902832, Accuracy: 0.5625053644180298, Val Accuracy: 0.5328425168991089, Time: 28.26 sec\n",
      "Step 28800 - Training Loss: 0.9497582912445068, Val Loss: 1.2158597707748413, Accuracy: 0.562549889087677, Val Accuracy: 0.5329540371894836, Time: 28.06 sec\n",
      "Step 28900 - Training Loss: 0.9662067890167236, Val Loss: 1.2151488065719604, Accuracy: 0.562588632106781, Val Accuracy: 0.5330567359924316, Time: 28.58 sec\n",
      "Step 29000 - Training Loss: 0.91552734375, Val Loss: 1.2144445180892944, Accuracy: 0.5626242756843567, Val Accuracy: 0.5331677794456482, Time: 29.74 sec\n",
      "Step 29100 - Training Loss: 0.9341734647750854, Val Loss: 1.2137519121170044, Accuracy: 0.5626616477966309, Val Accuracy: 0.5332791805267334, Time: 28.41 sec\n",
      "Step 29200 - Training Loss: 0.9798619151115417, Val Loss: 1.2130424976348877, Accuracy: 0.5627111196517944, Val Accuracy: 0.5334044098854065, Time: 28.19 sec\n",
      "Step 29300 - Training Loss: 0.9563409686088562, Val Loss: 1.2123782634735107, Accuracy: 0.5627515316009521, Val Accuracy: 0.5335127115249634, Time: 27.50 sec\n",
      "Step 29400 - Training Loss: 0.9428108334541321, Val Loss: 1.2117278575897217, Accuracy: 0.5627843737602234, Val Accuracy: 0.5335848927497864, Time: 28.82 sec\n",
      "Step 29500 - Training Loss: 0.9525818824768066, Val Loss: 1.2110430002212524, Accuracy: 0.5628299713134766, Val Accuracy: 0.5336970686912537, Time: 28.04 sec\n",
      "Step 29600 - Training Loss: 0.9523146748542786, Val Loss: 1.2103773355484009, Accuracy: 0.5628758072853088, Val Accuracy: 0.5337905287742615, Time: 28.40 sec\n",
      "Step 29700 - Training Loss: 0.9501035213470459, Val Loss: 1.2097638845443726, Accuracy: 0.5629196763038635, Val Accuracy: 0.5338451266288757, Time: 29.11 sec\n",
      "Step 29800 - Training Loss: 0.9666833281517029, Val Loss: 1.2091128826141357, Accuracy: 0.5629575252532959, Val Accuracy: 0.5339329838752747, Time: 28.92 sec\n",
      "Step 29900 - Training Loss: 0.9564254283905029, Val Loss: 1.2084378004074097, Accuracy: 0.5629991292953491, Val Accuracy: 0.5340572595596313, Time: 29.36 sec\n",
      "Step 30000 - Training Loss: 0.9774158596992493, Val Loss: 1.20778226852417, Accuracy: 0.5630397796630859, Val Accuracy: 0.5341634154319763, Time: 29.05 sec\n",
      "Step 30100 - Training Loss: 0.9973662495613098, Val Loss: 1.2071330547332764, Accuracy: 0.5630733370780945, Val Accuracy: 0.5342810153961182, Time: 29.22 sec\n",
      "Step 30200 - Training Loss: 0.9560132026672363, Val Loss: 1.206467628479004, Accuracy: 0.5631223917007446, Val Accuracy: 0.5344129204750061, Time: 29.70 sec\n",
      "Step 30300 - Training Loss: 0.9366551041603088, Val Loss: 1.2058067321777344, Accuracy: 0.5631676912307739, Val Accuracy: 0.5345306992530823, Time: 28.93 sec\n",
      "Step 30400 - Training Loss: 0.9765731692314148, Val Loss: 1.2051512002944946, Accuracy: 0.5632005333900452, Val Accuracy: 0.5346617102622986, Time: 29.11 sec\n",
      "Step 30500 - Training Loss: 0.9599356651306152, Val Loss: 1.204498529434204, Accuracy: 0.5632340908050537, Val Accuracy: 0.5347916483879089, Time: 29.54 sec\n",
      "Step 30600 - Training Loss: 0.9767405390739441, Val Loss: 1.2039107084274292, Accuracy: 0.5632792115211487, Val Accuracy: 0.5348299741744995, Time: 29.60 sec\n",
      "Step 30700 - Training Loss: 1.0009613037109375, Val Loss: 1.2032780647277832, Accuracy: 0.5633187890052795, Val Accuracy: 0.5349273681640625, Time: 29.65 sec\n",
      "Step 30800 - Training Loss: 0.9737100601196289, Val Loss: 1.2026667594909668, Accuracy: 0.5633530020713806, Val Accuracy: 0.5350382924079895, Time: 29.38 sec\n",
      "Step 30900 - Training Loss: 0.9498963356018066, Val Loss: 1.2020363807678223, Accuracy: 0.5633858442306519, Val Accuracy: 0.5351229906082153, Time: 29.61 sec\n",
      "Step 31000 - Training Loss: 0.967697024345398, Val Loss: 1.2014065980911255, Accuracy: 0.5634241700172424, Val Accuracy: 0.5352334976196289, Time: 29.27 sec\n",
      "Step 31100 - Training Loss: 0.9472136497497559, Val Loss: 1.2007906436920166, Accuracy: 0.5634580850601196, Val Accuracy: 0.5353636145591736, Time: 29.79 sec\n",
      "Step 31200 - Training Loss: 0.8807421922683716, Val Loss: 1.200175166130066, Accuracy: 0.5634914636611938, Val Accuracy: 0.5354719161987305, Time: 32.72 sec\n",
      "Step 31300 - Training Loss: 0.9216508269309998, Val Loss: 1.1995739936828613, Accuracy: 0.5635281205177307, Val Accuracy: 0.5355559587478638, Time: 32.22 sec\n",
      "Step 31400 - Training Loss: 0.9429954290390015, Val Loss: 1.198958158493042, Accuracy: 0.5635644197463989, Val Accuracy: 0.5356402397155762, Time: 31.15 sec\n",
      "Step 31500 - Training Loss: 0.9546499252319336, Val Loss: 1.1983447074890137, Accuracy: 0.5636019110679626, Val Accuracy: 0.5357652902603149, Time: 32.41 sec\n",
      "Step 31600 - Training Loss: 0.9613538980484009, Val Loss: 1.1977453231811523, Accuracy: 0.5636405944824219, Val Accuracy: 0.5358694195747375, Time: 27.92 sec\n",
      "Step 31700 - Training Loss: 0.9930642247200012, Val Loss: 1.1971540451049805, Accuracy: 0.5636749863624573, Val Accuracy: 0.5359544157981873, Time: 26.61 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31800 - Training Loss: 0.9820702075958252, Val Loss: 1.19655179977417, Accuracy: 0.5637006163597107, Val Accuracy: 0.5360774397850037, Time: 26.59 sec\n",
      "Step 31900 - Training Loss: 0.9455766677856445, Val Loss: 1.1959677934646606, Accuracy: 0.5637431144714355, Val Accuracy: 0.5361689925193787, Time: 27.16 sec\n",
      "Step 32000 - Training Loss: 0.9866363406181335, Val Loss: 1.1954143047332764, Accuracy: 0.5637810230255127, Val Accuracy: 0.5362637639045715, Time: 26.56 sec\n",
      "Step 32100 - Training Loss: 0.9955801367759705, Val Loss: 1.1948541402816772, Accuracy: 0.563805878162384, Val Accuracy: 0.5363281965255737, Time: 26.12 sec\n",
      "Step 32200 - Training Loss: 0.9689653515815735, Val Loss: 1.1943258047103882, Accuracy: 0.5638439655303955, Val Accuracy: 0.5363954901695251, Time: 26.74 sec\n",
      "Step 32300 - Training Loss: 0.9289356470108032, Val Loss: 1.1937428712844849, Accuracy: 0.56387859582901, Val Accuracy: 0.5365104079246521, Time: 26.66 sec\n",
      "Step 32400 - Training Loss: 0.9761534929275513, Val Loss: 1.1932094097137451, Accuracy: 0.5639066696166992, Val Accuracy: 0.5365943312644958, Time: 25.60 sec\n",
      "Step 32500 - Training Loss: 0.9508389234542847, Val Loss: 1.1926628351211548, Accuracy: 0.5639359951019287, Val Accuracy: 0.5366809368133545, Time: 26.51 sec\n",
      "Step 32600 - Training Loss: 0.997249960899353, Val Loss: 1.1920990943908691, Accuracy: 0.5639607906341553, Val Accuracy: 0.5367805361747742, Time: 25.90 sec\n",
      "Step 32700 - Training Loss: 0.9719043970108032, Val Loss: 1.1915359497070312, Accuracy: 0.5639835596084595, Val Accuracy: 0.5368763208389282, Time: 26.53 sec\n",
      "Step 32800 - Training Loss: 0.9612978100776672, Val Loss: 1.1909719705581665, Accuracy: 0.5640074014663696, Val Accuracy: 0.5369791388511658, Time: 26.14 sec\n",
      "Step 32900 - Training Loss: 0.9500855803489685, Val Loss: 1.1904387474060059, Accuracy: 0.5640343427658081, Val Accuracy: 0.5370649695396423, Time: 26.64 sec\n",
      "Step 33000 - Training Loss: 0.9772014021873474, Val Loss: 1.1898813247680664, Accuracy: 0.5640699863433838, Val Accuracy: 0.5371281504631042, Time: 26.22 sec\n",
      "Step 33100 - Training Loss: 0.9636310338973999, Val Loss: 1.189329981803894, Accuracy: 0.5641034245491028, Val Accuracy: 0.5372095108032227, Time: 26.20 sec\n",
      "Step 33200 - Training Loss: 0.8981980085372925, Val Loss: 1.1887859106063843, Accuracy: 0.5641342997550964, Val Accuracy: 0.5372835993766785, Time: 26.04 sec\n",
      "Step 33300 - Training Loss: 0.9310479164123535, Val Loss: 1.1882389783859253, Accuracy: 0.5641579627990723, Val Accuracy: 0.5373526811599731, Time: 26.36 sec\n",
      "Step 33400 - Training Loss: 0.9342671036720276, Val Loss: 1.1877039670944214, Accuracy: 0.5641837120056152, Val Accuracy: 0.5374094247817993, Time: 26.66 sec\n",
      "Step 33500 - Training Loss: 0.9407817721366882, Val Loss: 1.187161922454834, Accuracy: 0.564215898513794, Val Accuracy: 0.5375232100486755, Time: 26.47 sec\n",
      "Step 33600 - Training Loss: 0.9700926542282104, Val Loss: 1.1866424083709717, Accuracy: 0.5642430186271667, Val Accuracy: 0.5375640988349915, Time: 25.80 sec\n",
      "Step 33700 - Training Loss: 0.9279025197029114, Val Loss: 1.186113715171814, Accuracy: 0.5642704963684082, Val Accuracy: 0.5376389026641846, Time: 26.10 sec\n",
      "Step 33800 - Training Loss: 0.9999226331710815, Val Loss: 1.1855896711349487, Accuracy: 0.5643068552017212, Val Accuracy: 0.5377299189567566, Time: 26.20 sec\n",
      "Step 33900 - Training Loss: 0.9749534726142883, Val Loss: 1.1850569248199463, Accuracy: 0.5643433332443237, Val Accuracy: 0.537826418876648, Time: 26.52 sec\n",
      "Step 34000 - Training Loss: 0.9879907965660095, Val Loss: 1.184551477432251, Accuracy: 0.5643765330314636, Val Accuracy: 0.5379093289375305, Time: 26.06 sec\n",
      "Step 34100 - Training Loss: 0.9648104906082153, Val Loss: 1.184024691581726, Accuracy: 0.5644068121910095, Val Accuracy: 0.5380152463912964, Time: 26.21 sec\n",
      "Step 34200 - Training Loss: 0.9096907377243042, Val Loss: 1.18350088596344, Accuracy: 0.5644367933273315, Val Accuracy: 0.5380936861038208, Time: 26.06 sec\n",
      "Step 34300 - Training Loss: 0.9764811396598816, Val Loss: 1.1830098628997803, Accuracy: 0.5644691586494446, Val Accuracy: 0.5381526350975037, Time: 25.93 sec\n",
      "Step 34400 - Training Loss: 0.9578518867492676, Val Loss: 1.1825133562088013, Accuracy: 0.564497709274292, Val Accuracy: 0.5382158756256104, Time: 26.27 sec\n",
      "Step 34500 - Training Loss: 0.9685012102127075, Val Loss: 1.1820518970489502, Accuracy: 0.5645105242729187, Val Accuracy: 0.5382691025733948, Time: 26.21 sec\n",
      "Step 34600 - Training Loss: 0.912774384021759, Val Loss: 1.181604027748108, Accuracy: 0.5645367503166199, Val Accuracy: 0.5383239984512329, Time: 26.57 sec\n",
      "Step 34700 - Training Loss: 0.9604478478431702, Val Loss: 1.1811273097991943, Accuracy: 0.5645606517791748, Val Accuracy: 0.5383638143539429, Time: 26.32 sec\n",
      "Step 34800 - Training Loss: 0.9342411160469055, Val Loss: 1.1807026863098145, Accuracy: 0.5645930767059326, Val Accuracy: 0.5383874177932739, Time: 26.18 sec\n",
      "Step 34900 - Training Loss: 0.9815758466720581, Val Loss: 1.1801984310150146, Accuracy: 0.5646195411682129, Val Accuracy: 0.5384379029273987, Time: 26.16 sec\n",
      "Step 35000 - Training Loss: 0.9412570595741272, Val Loss: 1.179714560508728, Accuracy: 0.5646336078643799, Val Accuracy: 0.5385032892227173, Time: 26.43 sec\n",
      "Step 35100 - Training Loss: 0.9585625529289246, Val Loss: 1.179215908050537, Accuracy: 0.5646578669548035, Val Accuracy: 0.5385887622833252, Time: 25.90 sec\n",
      "Step 35200 - Training Loss: 0.9630008935928345, Val Loss: 1.1787562370300293, Accuracy: 0.5646761059761047, Val Accuracy: 0.5386474132537842, Time: 26.10 sec\n",
      "Step 35300 - Training Loss: 0.9678115844726562, Val Loss: 1.1782933473587036, Accuracy: 0.5646939277648926, Val Accuracy: 0.5387071371078491, Time: 26.48 sec\n",
      "Step 35400 - Training Loss: 0.9628434181213379, Val Loss: 1.1778504848480225, Accuracy: 0.5647096633911133, Val Accuracy: 0.5387608408927917, Time: 26.40 sec\n",
      "Step 35500 - Training Loss: 0.965691328048706, Val Loss: 1.177376389503479, Accuracy: 0.5647340416908264, Val Accuracy: 0.5388358235359192, Time: 26.60 sec\n",
      "Step 35600 - Training Loss: 0.936690628528595, Val Loss: 1.1769026517868042, Accuracy: 0.5647684335708618, Val Accuracy: 0.5389019846916199, Time: 26.36 sec\n",
      "Step 35700 - Training Loss: 0.9426397085189819, Val Loss: 1.1764212846755981, Accuracy: 0.5648089051246643, Val Accuracy: 0.5389807224273682, Time: 26.37 sec\n",
      "Step 35800 - Training Loss: 0.967873215675354, Val Loss: 1.1759909391403198, Accuracy: 0.5648377537727356, Val Accuracy: 0.5390130877494812, Time: 26.76 sec\n",
      "Step 35900 - Training Loss: 0.9521481990814209, Val Loss: 1.1755181550979614, Accuracy: 0.5648611187934875, Val Accuracy: 0.5391016602516174, Time: 26.39 sec\n",
      "Step 36000 - Training Loss: 0.9668869376182556, Val Loss: 1.1750508546829224, Accuracy: 0.5648815035820007, Val Accuracy: 0.5391675233840942, Time: 25.93 sec\n",
      "Step 36100 - Training Loss: 0.9409714937210083, Val Loss: 1.1746164560317993, Accuracy: 0.5648974776268005, Val Accuracy: 0.5392191410064697, Time: 26.23 sec\n",
      "Step 36200 - Training Loss: 0.9883490800857544, Val Loss: 1.1742223501205444, Accuracy: 0.5649248957633972, Val Accuracy: 0.5392410159111023, Time: 26.04 sec\n",
      "Step 36300 - Training Loss: 0.9618619680404663, Val Loss: 1.1738132238388062, Accuracy: 0.5649423599243164, Val Accuracy: 0.5392634868621826, Time: 25.28 sec\n",
      "Step 36400 - Training Loss: 0.9530866742134094, Val Loss: 1.1733996868133545, Accuracy: 0.5649584531784058, Val Accuracy: 0.5393202304840088, Time: 25.62 sec\n",
      "Step 36500 - Training Loss: 0.9649574160575867, Val Loss: 1.1729868650436401, Accuracy: 0.5649949312210083, Val Accuracy: 0.539376437664032, Time: 25.50 sec\n",
      "Step 36600 - Training Loss: 0.9749205708503723, Val Loss: 1.1725983619689941, Accuracy: 0.5650131702423096, Val Accuracy: 0.5393826961517334, Time: 25.97 sec\n",
      "Step 36700 - Training Loss: 0.9587965607643127, Val Loss: 1.1722837686538696, Accuracy: 0.5650237798690796, Val Accuracy: 0.5393713116645813, Time: 25.62 sec\n",
      "Step 36800 - Training Loss: 0.9799402952194214, Val Loss: 1.171881914138794, Accuracy: 0.5650410056114197, Val Accuracy: 0.539400577545166, Time: 25.75 sec\n",
      "Step 36900 - Training Loss: 0.9304187297821045, Val Loss: 1.1714682579040527, Accuracy: 0.5650612115859985, Val Accuracy: 0.5394337773323059, Time: 26.13 sec\n",
      "Step 37000 - Training Loss: 0.9090554714202881, Val Loss: 1.1710383892059326, Accuracy: 0.5650792121887207, Val Accuracy: 0.5394949316978455, Time: 25.70 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37100 - Training Loss: 0.9207532405853271, Val Loss: 1.17061448097229, Accuracy: 0.565101146697998, Val Accuracy: 0.5395623445510864, Time: 25.92 sec\n",
      "Step 37200 - Training Loss: 0.9443327784538269, Val Loss: 1.1702003479003906, Accuracy: 0.5651256442070007, Val Accuracy: 0.5396157503128052, Time: 25.87 sec\n",
      "Step 37300 - Training Loss: 0.9478700757026672, Val Loss: 1.1698873043060303, Accuracy: 0.5651510953903198, Val Accuracy: 0.5396372079849243, Time: 25.84 sec\n",
      "Step 37400 - Training Loss: 0.9839963912963867, Val Loss: 1.1695349216461182, Accuracy: 0.5651739239692688, Val Accuracy: 0.5396655201911926, Time: 25.88 sec\n",
      "Step 37500 - Training Loss: 0.9660111665725708, Val Loss: 1.1691062450408936, Accuracy: 0.565203070640564, Val Accuracy: 0.5397531986236572, Time: 26.46 sec\n",
      "Step 37600 - Training Loss: 0.963981568813324, Val Loss: 1.1686683893203735, Accuracy: 0.5652318000793457, Val Accuracy: 0.5398126840591431, Time: 26.95 sec\n",
      "Step 37700 - Training Loss: 0.9677571058273315, Val Loss: 1.1683043241500854, Accuracy: 0.5652567744255066, Val Accuracy: 0.5398391485214233, Time: 25.90 sec\n",
      "Step 37800 - Training Loss: 0.9841550588607788, Val Loss: 1.1679060459136963, Accuracy: 0.565282940864563, Val Accuracy: 0.5398819446563721, Time: 26.19 sec\n",
      "Step 37900 - Training Loss: 0.9049076437950134, Val Loss: 1.1676274538040161, Accuracy: 0.5652989745140076, Val Accuracy: 0.5398783087730408, Time: 26.23 sec\n",
      "Step 38000 - Training Loss: 0.9524651169776917, Val Loss: 1.167259931564331, Accuracy: 0.5653156638145447, Val Accuracy: 0.5399115085601807, Time: 26.23 sec\n",
      "Step 38100 - Training Loss: 0.9419186115264893, Val Loss: 1.1668745279312134, Accuracy: 0.5653395056724548, Val Accuracy: 0.5399599075317383, Time: 25.77 sec\n",
      "Step 38200 - Training Loss: 0.934764564037323, Val Loss: 1.1664866209030151, Accuracy: 0.5653685927391052, Val Accuracy: 0.5399954915046692, Time: 25.92 sec\n",
      "Step 38300 - Training Loss: 0.9691111445426941, Val Loss: 1.1661242246627808, Accuracy: 0.5654020309448242, Val Accuracy: 0.5400212407112122, Time: 27.60 sec\n",
      "Step 38400 - Training Loss: 0.9382498264312744, Val Loss: 1.1657485961914062, Accuracy: 0.5654287934303284, Val Accuracy: 0.5400184988975525, Time: 27.27 sec\n",
      "Step 38500 - Training Loss: 0.9838964343070984, Val Loss: 1.1653578281402588, Accuracy: 0.5654584765434265, Val Accuracy: 0.5400528907775879, Time: 27.18 sec\n",
      "Step 38600 - Training Loss: 0.9478829503059387, Val Loss: 1.164966106414795, Accuracy: 0.5654779076576233, Val Accuracy: 0.5400782227516174, Time: 27.64 sec\n",
      "Step 38700 - Training Loss: 0.9406043291091919, Val Loss: 1.1646007299423218, Accuracy: 0.565497100353241, Val Accuracy: 0.5400819778442383, Time: 27.37 sec\n",
      "Step 38800 - Training Loss: 0.9279995560646057, Val Loss: 1.1642484664916992, Accuracy: 0.5655062198638916, Val Accuracy: 0.5400910377502441, Time: 27.33 sec\n",
      "Step 38900 - Training Loss: 0.9466039538383484, Val Loss: 1.163836121559143, Accuracy: 0.5655239224433899, Val Accuracy: 0.5401468276977539, Time: 27.17 sec\n",
      "Step 39000 - Training Loss: 0.939752459526062, Val Loss: 1.1634608507156372, Accuracy: 0.5655403137207031, Val Accuracy: 0.540180504322052, Time: 26.92 sec\n",
      "Step 39100 - Training Loss: 0.9434900879859924, Val Loss: 1.163096308708191, Accuracy: 0.5655595064163208, Val Accuracy: 0.5401912331581116, Time: 27.18 sec\n",
      "Step 39200 - Training Loss: 0.9316005110740662, Val Loss: 1.1627254486083984, Accuracy: 0.5655736923217773, Val Accuracy: 0.5401877760887146, Time: 27.27 sec\n",
      "Step 39300 - Training Loss: 0.9401260614395142, Val Loss: 1.1623209714889526, Accuracy: 0.565590500831604, Val Accuracy: 0.5401756763458252, Time: 27.45 sec\n",
      "Step 39400 - Training Loss: 1.0018442869186401, Val Loss: 1.1619185209274292, Accuracy: 0.565605103969574, Val Accuracy: 0.5401834845542908, Time: 27.44 sec\n",
      "Step 39500 - Training Loss: 0.9123834371566772, Val Loss: 1.1615180969238281, Accuracy: 0.5656179785728455, Val Accuracy: 0.5402422547340393, Time: 27.72 sec\n",
      "Step 39600 - Training Loss: 0.9489538073539734, Val Loss: 1.1611195802688599, Accuracy: 0.5656248331069946, Val Accuracy: 0.5402948260307312, Time: 27.17 sec\n",
      "Step 39700 - Training Loss: 0.9087668061256409, Val Loss: 1.160723090171814, Accuracy: 0.5656515955924988, Val Accuracy: 0.5402961373329163, Time: 27.30 sec\n",
      "Step 39800 - Training Loss: 0.9730144143104553, Val Loss: 1.1603285074234009, Accuracy: 0.5656726360321045, Val Accuracy: 0.5403252840042114, Time: 26.81 sec\n",
      "Step 39900 - Training Loss: 0.9440523982048035, Val Loss: 1.1599358320236206, Accuracy: 0.5656970739364624, Val Accuracy: 0.540375828742981, Time: 27.01 sec\n",
      "Step 40000 - Training Loss: 0.969733476638794, Val Loss: 1.1595451831817627, Accuracy: 0.565714955329895, Val Accuracy: 0.5404338836669922, Time: 27.01 sec\n",
      "Step 40100 - Training Loss: 0.9805190563201904, Val Loss: 1.159156322479248, Accuracy: 0.5657311081886292, Val Accuracy: 0.5404436588287354, Time: 26.88 sec\n",
      "Step 40200 - Training Loss: 0.9653701186180115, Val Loss: 1.1587693691253662, Accuracy: 0.5657498836517334, Val Accuracy: 0.5404667258262634, Time: 29.32 sec\n",
      "Step 40300 - Training Loss: 0.9496018886566162, Val Loss: 1.1583843231201172, Accuracy: 0.5657739639282227, Val Accuracy: 0.5404700636863708, Time: 26.36 sec\n",
      "Step 40400 - Training Loss: 0.9380199313163757, Val Loss: 1.158001184463501, Accuracy: 0.5657852292060852, Val Accuracy: 0.540458619594574, Time: 26.58 sec\n",
      "Step 40500 - Training Loss: 0.9275955557823181, Val Loss: 1.157619833946228, Accuracy: 0.5657990574836731, Val Accuracy: 0.5404734015464783, Time: 26.28 sec\n",
      "Step 40600 - Training Loss: 0.9749430418014526, Val Loss: 1.1572402715682983, Accuracy: 0.565812885761261, Val Accuracy: 0.5404896140098572, Time: 27.16 sec\n",
      "Step 40700 - Training Loss: 0.9738767743110657, Val Loss: 1.1568626165390015, Accuracy: 0.5658339262008667, Val Accuracy: 0.540515661239624, Time: 26.86 sec\n",
      "Step 40800 - Training Loss: 0.9404329657554626, Val Loss: 1.1564867496490479, Accuracy: 0.5658508539199829, Val Accuracy: 0.5405628681182861, Time: 27.10 sec\n",
      "Step 40900 - Training Loss: 0.9827857613563538, Val Loss: 1.1561126708984375, Accuracy: 0.5658714175224304, Val Accuracy: 0.5406186580657959, Time: 26.86 sec\n",
      "Step 41000 - Training Loss: 0.962243914604187, Val Loss: 1.1557403802871704, Accuracy: 0.5658844709396362, Val Accuracy: 0.5406687259674072, Time: 26.91 sec\n",
      "Step 41100 - Training Loss: 0.9410445690155029, Val Loss: 1.1553698778152466, Accuracy: 0.5658987164497375, Val Accuracy: 0.5407136082649231, Time: 26.67 sec\n",
      "Step 41200 - Training Loss: 0.9518889784812927, Val Loss: 1.155001163482666, Accuracy: 0.5659186840057373, Val Accuracy: 0.5407442450523376, Time: 26.21 sec\n",
      "Step 41300 - Training Loss: 0.928968608379364, Val Loss: 1.1546341180801392, Accuracy: 0.5659332871437073, Val Accuracy: 0.5407707095146179, Time: 26.61 sec\n",
      "Step 41400 - Training Loss: 0.9597599506378174, Val Loss: 1.1542688608169556, Accuracy: 0.5659463405609131, Val Accuracy: 0.540784478187561, Time: 27.55 sec\n",
      "Step 41500 - Training Loss: 0.9657722115516663, Val Loss: 1.1539052724838257, Accuracy: 0.5659604072570801, Val Accuracy: 0.5407940745353699, Time: 26.99 sec\n",
      "Step 41600 - Training Loss: 0.9603059887886047, Val Loss: 1.153543472290039, Accuracy: 0.5659720301628113, Val Accuracy: 0.5408114790916443, Time: 26.65 sec\n",
      "Step 41700 - Training Loss: 0.977027177810669, Val Loss: 1.1531832218170166, Accuracy: 0.5659820437431335, Val Accuracy: 0.540849506855011, Time: 25.89 sec\n",
      "Step 41800 - Training Loss: 0.929000198841095, Val Loss: 1.1528247594833374, Accuracy: 0.5659950971603394, Val Accuracy: 0.5409090518951416, Time: 25.58 sec\n",
      "Step 41900 - Training Loss: 0.952248215675354, Val Loss: 1.152467966079712, Accuracy: 0.5660117268562317, Val Accuracy: 0.5409553647041321, Time: 25.97 sec\n",
      "Step 42000 - Training Loss: 0.9611157774925232, Val Loss: 1.1521128416061401, Accuracy: 0.5660236477851868, Val Accuracy: 0.5410060882568359, Time: 26.30 sec\n",
      "Step 42100 - Training Loss: 0.9777239561080933, Val Loss: 1.151759386062622, Accuracy: 0.566038966178894, Val Accuracy: 0.5410665273666382, Time: 26.45 sec\n",
      "Step 42200 - Training Loss: 0.9485025405883789, Val Loss: 1.1514075994491577, Accuracy: 0.5660430788993835, Val Accuracy: 0.541084349155426, Time: 26.61 sec\n",
      "Step 42300 - Training Loss: 0.9204688668251038, Val Loss: 1.1510573625564575, Accuracy: 0.5660602450370789, Val Accuracy: 0.5411509275436401, Time: 26.89 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42400 - Training Loss: 0.9376758933067322, Val Loss: 1.150708794593811, Accuracy: 0.5660673379898071, Val Accuracy: 0.5411915183067322, Time: 26.61 sec\n",
      "Step 42500 - Training Loss: 0.9874077439308167, Val Loss: 1.1503617763519287, Accuracy: 0.5660818219184875, Val Accuracy: 0.5412551760673523, Time: 26.45 sec\n",
      "Step 42600 - Training Loss: 0.9664528965950012, Val Loss: 1.1500163078308105, Accuracy: 0.5660977363586426, Val Accuracy: 0.5413023233413696, Time: 26.13 sec\n",
      "Step 42700 - Training Loss: 0.9807676076889038, Val Loss: 1.149672508239746, Accuracy: 0.5661173462867737, Val Accuracy: 0.5413455367088318, Time: 26.45 sec\n",
      "Step 42800 - Training Loss: 0.9360988736152649, Val Loss: 1.1493302583694458, Accuracy: 0.5661218762397766, Val Accuracy: 0.5413900017738342, Time: 26.70 sec\n",
      "Step 42900 - Training Loss: 0.9551201462745667, Val Loss: 1.1489896774291992, Accuracy: 0.5661220550537109, Val Accuracy: 0.5414490699768066, Time: 26.51 sec\n",
      "Step 43000 - Training Loss: 1.0020283460617065, Val Loss: 1.1486505270004272, Accuracy: 0.5661309361457825, Val Accuracy: 0.541438639163971, Time: 25.61 sec\n",
      "Step 43100 - Training Loss: 0.9227880835533142, Val Loss: 1.1483129262924194, Accuracy: 0.566152811050415, Val Accuracy: 0.5414509773254395, Time: 26.28 sec\n",
      "Step 43200 - Training Loss: 1.0055110454559326, Val Loss: 1.1479768753051758, Accuracy: 0.5661620497703552, Val Accuracy: 0.541500985622406, Time: 26.43 sec\n",
      "Step 43300 - Training Loss: 0.9618575572967529, Val Loss: 1.1476422548294067, Accuracy: 0.5661763548851013, Val Accuracy: 0.5415616035461426, Time: 26.07 sec\n",
      "Step 43400 - Training Loss: 0.9115564823150635, Val Loss: 1.1473093032836914, Accuracy: 0.5661856532096863, Val Accuracy: 0.5415764451026917, Time: 25.87 sec\n",
      "Step 43500 - Training Loss: 0.9461925029754639, Val Loss: 1.1469777822494507, Accuracy: 0.5662015676498413, Val Accuracy: 0.5415729880332947, Time: 25.96 sec\n",
      "Step 43600 - Training Loss: 0.9495775699615479, Val Loss: 1.1466476917266846, Accuracy: 0.5662179589271545, Val Accuracy: 0.5415400862693787, Time: 26.20 sec\n",
      "Step 43700 - Training Loss: 0.9566710591316223, Val Loss: 1.1463191509246826, Accuracy: 0.5662327408790588, Val Accuracy: 0.5415017604827881, Time: 26.53 sec\n",
      "Step 43800 - Training Loss: 0.9128851890563965, Val Loss: 1.1459920406341553, Accuracy: 0.5662510991096497, Val Accuracy: 0.5414527058601379, Time: 26.39 sec\n",
      "Step 43900 - Training Loss: 0.9414188861846924, Val Loss: 1.1456663608551025, Accuracy: 0.5662744045257568, Val Accuracy: 0.5413630604743958, Time: 26.83 sec\n",
      "Step 44000 - Training Loss: 0.9700759649276733, Val Loss: 1.145342230796814, Accuracy: 0.5662888884544373, Val Accuracy: 0.5413270592689514, Time: 26.54 sec\n",
      "Step 44100 - Training Loss: 0.9378425478935242, Val Loss: 1.14501953125, Accuracy: 0.5663068890571594, Val Accuracy: 0.5413007736206055, Time: 26.37 sec\n",
      "Step 44200 - Training Loss: 0.9352315664291382, Val Loss: 1.144698143005371, Accuracy: 0.5663253664970398, Val Accuracy: 0.541267454624176, Time: 26.44 sec\n",
      "Step 44300 - Training Loss: 0.9634051322937012, Val Loss: 1.1443783044815063, Accuracy: 0.5663464069366455, Val Accuracy: 0.5412055850028992, Time: 26.24 sec\n",
      "Step 44400 - Training Loss: 0.9207464456558228, Val Loss: 1.1440597772598267, Accuracy: 0.5663684010505676, Val Accuracy: 0.5411351919174194, Time: 26.38 sec\n",
      "Step 44500 - Training Loss: 0.9707568287849426, Val Loss: 1.1437426805496216, Accuracy: 0.5663867592811584, Val Accuracy: 0.5410643219947815, Time: 26.68 sec\n",
      "Step 44600 - Training Loss: 1.004529356956482, Val Loss: 1.1434270143508911, Accuracy: 0.5664033889770508, Val Accuracy: 0.5409954786300659, Time: 28.66 sec\n",
      "Step 44700 - Training Loss: 0.9475323557853699, Val Loss: 1.1431126594543457, Accuracy: 0.5664175152778625, Val Accuracy: 0.54092937707901, Time: 27.20 sec\n",
      "Step 44800 - Training Loss: 0.9802044630050659, Val Loss: 1.142799735069275, Accuracy: 0.566441535949707, Val Accuracy: 0.540846586227417, Time: 27.15 sec\n",
      "Step 44900 - Training Loss: 0.9570253491401672, Val Loss: 1.1424882411956787, Accuracy: 0.5664650201797485, Val Accuracy: 0.5407629013061523, Time: 28.18 sec\n",
      "Step 45000 - Training Loss: 0.9687445759773254, Val Loss: 1.1421780586242676, Accuracy: 0.5664845705032349, Val Accuracy: 0.5406787395477295, Time: 27.97 sec\n",
      "Step 45100 - Training Loss: 0.9316750168800354, Val Loss: 1.1418691873550415, Accuracy: 0.5665099024772644, Val Accuracy: 0.5406312942504883, Time: 26.47 sec\n",
      "Step 45200 - Training Loss: 0.9279032349586487, Val Loss: 1.1415616273880005, Accuracy: 0.5665207505226135, Val Accuracy: 0.5405942797660828, Time: 26.99 sec\n",
      "Step 45300 - Training Loss: 0.9753620624542236, Val Loss: 1.141255497932434, Accuracy: 0.5665339827537537, Val Accuracy: 0.5405820608139038, Time: 26.92 sec\n",
      "Step 45400 - Training Loss: 0.9478874206542969, Val Loss: 1.1409505605697632, Accuracy: 0.5665533542633057, Val Accuracy: 0.5405724048614502, Time: 26.05 sec\n",
      "Step 45500 - Training Loss: 0.9495778679847717, Val Loss: 1.140647053718567, Accuracy: 0.5665635466575623, Val Accuracy: 0.5405392050743103, Time: 25.94 sec\n",
      "Step 45600 - Training Loss: 0.9237591028213501, Val Loss: 1.1403447389602661, Accuracy: 0.5665788650512695, Val Accuracy: 0.5404856204986572, Time: 26.38 sec\n",
      "Step 45700 - Training Loss: 0.9035936594009399, Val Loss: 1.14004385471344, Accuracy: 0.5665910840034485, Val Accuracy: 0.5404770970344543, Time: 25.65 sec\n",
      "Step 45800 - Training Loss: 0.9243493676185608, Val Loss: 1.1397441625595093, Accuracy: 0.5666056275367737, Val Accuracy: 0.5404647588729858, Time: 25.82 sec\n",
      "Step 45900 - Training Loss: 0.9798824787139893, Val Loss: 1.1394457817077637, Accuracy: 0.5666216611862183, Val Accuracy: 0.5404490828514099, Time: 26.09 sec\n",
      "Step 46000 - Training Loss: 0.9420958757400513, Val Loss: 1.1391485929489136, Accuracy: 0.5666356682777405, Val Accuracy: 0.5404098629951477, Time: 25.52 sec\n",
      "Step 46100 - Training Loss: 0.908087432384491, Val Loss: 1.138852834701538, Accuracy: 0.5666560530662537, Val Accuracy: 0.540375828742981, Time: 26.24 sec\n",
      "Step 46200 - Training Loss: 1.0045310258865356, Val Loss: 1.1385581493377686, Accuracy: 0.5666676163673401, Val Accuracy: 0.5402970910072327, Time: 26.02 sec\n",
      "Step 46300 - Training Loss: 0.9866999387741089, Val Loss: 1.1382648944854736, Accuracy: 0.5666794776916504, Val Accuracy: 0.5402510762214661, Time: 25.75 sec\n",
      "Step 46400 - Training Loss: 0.9757592678070068, Val Loss: 1.1379727125167847, Accuracy: 0.566697359085083, Val Accuracy: 0.540192186832428, Time: 25.60 sec\n",
      "Step 46500 - Training Loss: 1.0277206897735596, Val Loss: 1.1376818418502808, Accuracy: 0.5667185187339783, Val Accuracy: 0.5401578545570374, Time: 25.81 sec\n",
      "Step 46600 - Training Loss: 0.9803520441055298, Val Loss: 1.1373921632766724, Accuracy: 0.5667362809181213, Val Accuracy: 0.5401057600975037, Time: 25.75 sec\n",
      "Step 46700 - Training Loss: 0.9559348821640015, Val Loss: 1.137103796005249, Accuracy: 0.5667606592178345, Val Accuracy: 0.5400628447532654, Time: 26.23 sec\n",
      "Step 46800 - Training Loss: 0.9661275148391724, Val Loss: 1.1368165016174316, Accuracy: 0.566780149936676, Val Accuracy: 0.5400233864784241, Time: 26.12 sec\n",
      "Step 46900 - Training Loss: 0.9245355725288391, Val Loss: 1.1365305185317993, Accuracy: 0.5667953491210938, Val Accuracy: 0.5399776697158813, Time: 25.62 sec\n",
      "Step 47000 - Training Loss: 0.977299153804779, Val Loss: 1.136245608329773, Accuracy: 0.5668103694915771, Val Accuracy: 0.5399025082588196, Time: 25.52 sec\n",
      "Step 47100 - Training Loss: 0.9393629431724548, Val Loss: 1.1359620094299316, Accuracy: 0.5668259263038635, Val Accuracy: 0.5398300290107727, Time: 25.45 sec\n",
      "Step 47200 - Training Loss: 0.9769245386123657, Val Loss: 1.1356794834136963, Accuracy: 0.5668399930000305, Val Accuracy: 0.539786159992218, Time: 25.28 sec\n",
      "Step 47300 - Training Loss: 0.9406279921531677, Val Loss: 1.135398268699646, Accuracy: 0.5668506026268005, Val Accuracy: 0.5397506356239319, Time: 25.55 sec\n",
      "Step 47400 - Training Loss: 0.9593645334243774, Val Loss: 1.1351181268692017, Accuracy: 0.566861093044281, Val Accuracy: 0.5396966338157654, Time: 25.56 sec\n",
      "Step 47500 - Training Loss: 0.9268832802772522, Val Loss: 1.1348391771316528, Accuracy: 0.5668646693229675, Val Accuracy: 0.5396202206611633, Time: 25.64 sec\n",
      "Step 47600 - Training Loss: 0.9266810417175293, Val Loss: 1.13456130027771, Accuracy: 0.5668678283691406, Val Accuracy: 0.5395578145980835, Time: 25.22 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 47700 - Training Loss: 0.9899172782897949, Val Loss: 1.1342846155166626, Accuracy: 0.5668771266937256, Val Accuracy: 0.5395318865776062, Time: 25.27 sec\n",
      "Step 47800 - Training Loss: 0.9370957016944885, Val Loss: 1.1340090036392212, Accuracy: 0.5668838620185852, Val Accuracy: 0.5394960045814514, Time: 25.22 sec\n",
      "Step 47900 - Training Loss: 0.9470220804214478, Val Loss: 1.1337345838546753, Accuracy: 0.566889762878418, Val Accuracy: 0.5394469499588013, Time: 25.70 sec\n",
      "Step 48000 - Training Loss: 0.9812646508216858, Val Loss: 1.133461356163025, Accuracy: 0.566904604434967, Val Accuracy: 0.539382815361023, Time: 25.44 sec\n",
      "Step 48100 - Training Loss: 0.9607893824577332, Val Loss: 1.1331892013549805, Accuracy: 0.5669175386428833, Val Accuracy: 0.5393521189689636, Time: 25.16 sec\n",
      "Step 48200 - Training Loss: 0.9716461896896362, Val Loss: 1.132918119430542, Accuracy: 0.5669304728507996, Val Accuracy: 0.5393334627151489, Time: 25.46 sec\n",
      "Step 48300 - Training Loss: 0.9224730730056763, Val Loss: 1.1326481103897095, Accuracy: 0.5669470429420471, Val Accuracy: 0.5392959713935852, Time: 25.29 sec\n",
      "Step 48400 - Training Loss: 0.9515154957771301, Val Loss: 1.132379174232483, Accuracy: 0.5669581890106201, Val Accuracy: 0.539264976978302, Time: 25.35 sec\n",
      "Step 48500 - Training Loss: 0.9702645540237427, Val Loss: 1.1321114301681519, Accuracy: 0.5669736266136169, Val Accuracy: 0.5392311215400696, Time: 25.50 sec\n",
      "Step 48600 - Training Loss: 0.9881697297096252, Val Loss: 1.1318446397781372, Accuracy: 0.5669824481010437, Val Accuracy: 0.5391836762428284, Time: 25.33 sec\n",
      "Step 48700 - Training Loss: 0.9772456884384155, Val Loss: 1.131579041481018, Accuracy: 0.566996693611145, Val Accuracy: 0.539129376411438, Time: 25.63 sec\n",
      "Step 48800 - Training Loss: 0.9589780569076538, Val Loss: 1.1313145160675049, Accuracy: 0.5670097470283508, Val Accuracy: 0.539075493812561, Time: 25.68 sec\n",
      "Step 48900 - Training Loss: 0.9852207899093628, Val Loss: 1.131050944328308, Accuracy: 0.5670195817947388, Val Accuracy: 0.5390312075614929, Time: 25.50 sec\n",
      "Step 49000 - Training Loss: 0.9325344562530518, Val Loss: 1.1307885646820068, Accuracy: 0.5670322179794312, Val Accuracy: 0.5389719605445862, Time: 25.33 sec\n",
      "Step 49100 - Training Loss: 0.9427564740180969, Val Loss: 1.130527138710022, Accuracy: 0.5670403838157654, Val Accuracy: 0.538897693157196, Time: 25.48 sec\n",
      "Step 49200 - Training Loss: 0.9656561613082886, Val Loss: 1.130266785621643, Accuracy: 0.5670515894889832, Val Accuracy: 0.5388596653938293, Time: 25.61 sec\n",
      "Step 49300 - Training Loss: 0.9633298516273499, Val Loss: 1.1300073862075806, Accuracy: 0.5670595765113831, Val Accuracy: 0.5387989282608032, Time: 25.48 sec\n",
      "Step 49400 - Training Loss: 0.9303433895111084, Val Loss: 1.1297491788864136, Accuracy: 0.5670656561851501, Val Accuracy: 0.5387977957725525, Time: 25.42 sec\n",
      "Step 49500 - Training Loss: 0.9992257356643677, Val Loss: 1.129491925239563, Accuracy: 0.5670740008354187, Val Accuracy: 0.5388016104698181, Time: 25.68 sec\n",
      "Step 49600 - Training Loss: 0.9539451003074646, Val Loss: 1.1292356252670288, Accuracy: 0.5670852661132812, Val Accuracy: 0.538790762424469, Time: 26.18 sec\n",
      "Step 49700 - Training Loss: 0.9267281889915466, Val Loss: 1.1289803981781006, Accuracy: 0.5670947432518005, Val Accuracy: 0.5387458801269531, Time: 27.10 sec\n",
      "Step 49800 - Training Loss: 0.9263585805892944, Val Loss: 1.1287261247634888, Accuracy: 0.5671113729476929, Val Accuracy: 0.5386832356452942, Time: 26.29 sec\n",
      "Step 49900 - Training Loss: 0.8981586694717407, Val Loss: 1.128472924232483, Accuracy: 0.5671204924583435, Val Accuracy: 0.538654625415802, Time: 26.37 sec\n",
      "Step 50000 - Training Loss: 1.0069189071655273, Val Loss: 1.1282206773757935, Accuracy: 0.5671335458755493, Val Accuracy: 0.5386279225349426, Time: 27.08 sec\n",
      "Step 50100 - Training Loss: 0.9537330269813538, Val Loss: 1.1279693841934204, Accuracy: 0.5671446323394775, Val Accuracy: 0.5385578870773315, Time: 27.89 sec\n",
      "Step 50200 - Training Loss: 0.9650195837020874, Val Loss: 1.1277191638946533, Accuracy: 0.5671536922454834, Val Accuracy: 0.5384947657585144, Time: 27.85 sec\n",
      "Step 50300 - Training Loss: 0.9956117272377014, Val Loss: 1.1274698972702026, Accuracy: 0.5671602487564087, Val Accuracy: 0.538441002368927, Time: 26.57 sec\n",
      "Step 50400 - Training Loss: 0.9255762100219727, Val Loss: 1.1272215843200684, Accuracy: 0.567168116569519, Val Accuracy: 0.5383943319320679, Time: 26.38 sec\n",
      "Step 50500 - Training Loss: 0.9195646643638611, Val Loss: 1.1269742250442505, Accuracy: 0.5671762824058533, Val Accuracy: 0.5383554697036743, Time: 28.43 sec\n",
      "Step 50600 - Training Loss: 0.9778707027435303, Val Loss: 1.126727819442749, Accuracy: 0.5671770572662354, Val Accuracy: 0.5382981896400452, Time: 28.22 sec\n",
      "Step 50700 - Training Loss: 0.9719986915588379, Val Loss: 1.126482367515564, Accuracy: 0.5671802163124084, Val Accuracy: 0.5382381081581116, Time: 26.89 sec\n",
      "Step 50800 - Training Loss: 0.96952223777771, Val Loss: 1.1262378692626953, Accuracy: 0.5671917796134949, Val Accuracy: 0.5381693243980408, Time: 27.25 sec\n",
      "Step 50900 - Training Loss: 0.9481676816940308, Val Loss: 1.125994324684143, Accuracy: 0.5672062635421753, Val Accuracy: 0.5381309390068054, Time: 26.60 sec\n",
      "Step 51000 - Training Loss: 0.9574606418609619, Val Loss: 1.1257517337799072, Accuracy: 0.567221999168396, Val Accuracy: 0.5381060838699341, Time: 26.07 sec\n",
      "Step 51100 - Training Loss: 0.9518099427223206, Val Loss: 1.1255100965499878, Accuracy: 0.5672279000282288, Val Accuracy: 0.5380670428276062, Time: 26.15 sec\n",
      "Step 51200 - Training Loss: 0.9275640845298767, Val Loss: 1.1252692937850952, Accuracy: 0.5672324299812317, Val Accuracy: 0.5380147099494934, Time: 26.60 sec\n",
      "Step 51300 - Training Loss: 0.9437187910079956, Val Loss: 1.125029444694519, Accuracy: 0.5672446489334106, Val Accuracy: 0.5379777550697327, Time: 26.52 sec\n",
      "Step 51400 - Training Loss: 0.967856228351593, Val Loss: 1.1247905492782593, Accuracy: 0.5672508478164673, Val Accuracy: 0.5379232168197632, Time: 26.36 sec\n",
      "Step 51500 - Training Loss: 0.9509626030921936, Val Loss: 1.124552607536316, Accuracy: 0.5672566294670105, Val Accuracy: 0.537872850894928, Time: 26.29 sec\n",
      "Step 51600 - Training Loss: 0.9279221296310425, Val Loss: 1.1243155002593994, Accuracy: 0.5672621130943298, Val Accuracy: 0.5378261208534241, Time: 27.36 sec\n",
      "Step 51700 - Training Loss: 0.977199912071228, Val Loss: 1.1240792274475098, Accuracy: 0.5672672986984253, Val Accuracy: 0.5377959609031677, Time: 27.18 sec\n",
      "Step 51800 - Training Loss: 0.9438949227333069, Val Loss: 1.123844027519226, Accuracy: 0.5672738552093506, Val Accuracy: 0.5377464890480042, Time: 26.18 sec\n",
      "Step 51900 - Training Loss: 0.9396795630455017, Val Loss: 1.1236095428466797, Accuracy: 0.5672885179519653, Val Accuracy: 0.5377151370048523, Time: 25.75 sec\n",
      "Step 52000 - Training Loss: 0.9450002312660217, Val Loss: 1.1233760118484497, Accuracy: 0.5672988295555115, Val Accuracy: 0.5377190113067627, Time: 26.15 sec\n",
      "Step 52100 - Training Loss: 0.944412350654602, Val Loss: 1.1231434345245361, Accuracy: 0.5673033595085144, Val Accuracy: 0.5376791954040527, Time: 26.31 sec\n",
      "Step 52200 - Training Loss: 0.9613369703292847, Val Loss: 1.1229116916656494, Accuracy: 0.5673180818557739, Val Accuracy: 0.5376976728439331, Time: 26.67 sec\n",
      "Step 52300 - Training Loss: 0.9316613078117371, Val Loss: 1.1226807832717896, Accuracy: 0.5673235058784485, Val Accuracy: 0.5376929640769958, Time: 31.48 sec\n",
      "Step 52400 - Training Loss: 0.9427959322929382, Val Loss: 1.1224507093429565, Accuracy: 0.5673338174819946, Val Accuracy: 0.537676215171814, Time: 35.13 sec\n",
      "Step 52500 - Training Loss: 0.9432539343833923, Val Loss: 1.12222158908844, Accuracy: 0.5673452019691467, Val Accuracy: 0.5376271605491638, Time: 33.40 sec\n",
      "Step 52600 - Training Loss: 0.9962928891181946, Val Loss: 1.1219931840896606, Accuracy: 0.5673604011535645, Val Accuracy: 0.5375710725784302, Time: 34.92 sec\n",
      "Step 52700 - Training Loss: 0.9400410056114197, Val Loss: 1.1217657327651978, Accuracy: 0.5673668384552002, Val Accuracy: 0.5375440120697021, Time: 32.88 sec\n",
      "Step 52800 - Training Loss: 0.9554756283760071, Val Loss: 1.1215391159057617, Accuracy: 0.5673712491989136, Val Accuracy: 0.5375276207923889, Time: 30.95 sec\n",
      "Step 52900 - Training Loss: 0.9366647601127625, Val Loss: 1.121313452720642, Accuracy: 0.5673770904541016, Val Accuracy: 0.5375382900238037, Time: 31.09 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53000 - Training Loss: 1.0178673267364502, Val Loss: 1.1210885047912598, Accuracy: 0.5673811435699463, Val Accuracy: 0.5375341773033142, Time: 30.94 sec\n",
      "Step 53100 - Training Loss: 0.9377695322036743, Val Loss: 1.1208643913269043, Accuracy: 0.5673831701278687, Val Accuracy: 0.5375365018844604, Time: 30.75 sec\n",
      "Step 53200 - Training Loss: 0.9641565680503845, Val Loss: 1.1206411123275757, Accuracy: 0.5673863887786865, Val Accuracy: 0.5375231504440308, Time: 30.80 sec\n",
      "Step 53300 - Training Loss: 0.9385672807693481, Val Loss: 1.120418667793274, Accuracy: 0.5673930644989014, Val Accuracy: 0.5374901294708252, Time: 31.01 sec\n",
      "Step 53400 - Training Loss: 0.9339967370033264, Val Loss: 1.120197057723999, Accuracy: 0.5674065351486206, Val Accuracy: 0.5375204086303711, Time: 31.04 sec\n",
      "Step 53500 - Training Loss: 0.976984977722168, Val Loss: 1.1199761629104614, Accuracy: 0.567416787147522, Val Accuracy: 0.5374694466590881, Time: 30.98 sec\n",
      "Step 53600 - Training Loss: 0.9620378613471985, Val Loss: 1.1197562217712402, Accuracy: 0.5674172639846802, Val Accuracy: 0.5374600291252136, Time: 30.80 sec\n",
      "Step 53700 - Training Loss: 0.9114631414413452, Val Loss: 1.1195369958877563, Accuracy: 0.5674229860305786, Val Accuracy: 0.5374516844749451, Time: 30.94 sec\n",
      "Step 53800 - Training Loss: 0.9682264924049377, Val Loss: 1.1193186044692993, Accuracy: 0.5674278736114502, Val Accuracy: 0.5374326705932617, Time: 30.62 sec\n",
      "Step 53900 - Training Loss: 0.9217214584350586, Val Loss: 1.1191009283065796, Accuracy: 0.5674344301223755, Val Accuracy: 0.5374195575714111, Time: 30.60 sec\n",
      "Step 54000 - Training Loss: 0.961669921875, Val Loss: 1.1188842058181763, Accuracy: 0.5674417614936829, Val Accuracy: 0.5373846888542175, Time: 30.29 sec\n",
      "Step 54100 - Training Loss: 0.9513945579528809, Val Loss: 1.1186681985855103, Accuracy: 0.5674511194229126, Val Accuracy: 0.5374158620834351, Time: 30.72 sec\n",
      "Step 54200 - Training Loss: 0.9856706261634827, Val Loss: 1.1184529066085815, Accuracy: 0.5674607753753662, Val Accuracy: 0.5373644232749939, Time: 30.73 sec\n",
      "Step 54300 - Training Loss: 0.9685318470001221, Val Loss: 1.1182384490966797, Accuracy: 0.5674688220024109, Val Accuracy: 0.5373519062995911, Time: 30.99 sec\n",
      "Step 54400 - Training Loss: 0.9239463210105896, Val Loss: 1.1180247068405151, Accuracy: 0.5674738883972168, Val Accuracy: 0.5373981595039368, Time: 30.72 sec\n",
      "Step 54500 - Training Loss: 1.0109968185424805, Val Loss: 1.1178117990493774, Accuracy: 0.5674809813499451, Val Accuracy: 0.5374212265014648, Time: 31.23 sec\n",
      "Step 54600 - Training Loss: 0.9488815665245056, Val Loss: 1.1175997257232666, Accuracy: 0.5674909353256226, Val Accuracy: 0.5374646782875061, Time: 30.82 sec\n",
      "Step 54700 - Training Loss: 0.9779025912284851, Val Loss: 1.117388367652893, Accuracy: 0.5675023794174194, Val Accuracy: 0.5374912023544312, Time: 30.70 sec\n",
      "Step 54800 - Training Loss: 0.9344329237937927, Val Loss: 1.1171777248382568, Accuracy: 0.5675129294395447, Val Accuracy: 0.5375347137451172, Time: 32.70 sec\n",
      "Step 54900 - Training Loss: 0.9720608592033386, Val Loss: 1.116967797279358, Accuracy: 0.5675164461135864, Val Accuracy: 0.5375292301177979, Time: 32.41 sec\n",
      "Step 55000 - Training Loss: 0.9335928559303284, Val Loss: 1.1167587041854858, Accuracy: 0.5675303339958191, Val Accuracy: 0.5375415682792664, Time: 31.37 sec\n",
      "Step 55100 - Training Loss: 0.926213800907135, Val Loss: 1.116550326347351, Accuracy: 0.5675315260887146, Val Accuracy: 0.5375677347183228, Time: 31.20 sec\n",
      "Step 55200 - Training Loss: 0.965115487575531, Val Loss: 1.1163426637649536, Accuracy: 0.5675404071807861, Val Accuracy: 0.5375811457633972, Time: 30.68 sec\n",
      "Step 55300 - Training Loss: 0.9684086441993713, Val Loss: 1.116135835647583, Accuracy: 0.567552387714386, Val Accuracy: 0.5375787019729614, Time: 30.80 sec\n",
      "Step 55400 - Training Loss: 0.9411989450454712, Val Loss: 1.1159296035766602, Accuracy: 0.5675608515739441, Val Accuracy: 0.5375515222549438, Time: 30.24 sec\n",
      "Step 55500 - Training Loss: 0.9603875279426575, Val Loss: 1.1157242059707642, Accuracy: 0.567573070526123, Val Accuracy: 0.5375455617904663, Time: 30.71 sec\n",
      "Step 55600 - Training Loss: 0.9652866125106812, Val Loss: 1.1155195236206055, Accuracy: 0.5675827860832214, Val Accuracy: 0.5375377535820007, Time: 29.70 sec\n",
      "Step 55700 - Training Loss: 0.951255202293396, Val Loss: 1.115315556526184, Accuracy: 0.5675950646400452, Val Accuracy: 0.5375490188598633, Time: 29.97 sec\n",
      "Step 55800 - Training Loss: 0.9711891412734985, Val Loss: 1.1151123046875, Accuracy: 0.5676016807556152, Val Accuracy: 0.5375579595565796, Time: 29.98 sec\n",
      "Step 55900 - Training Loss: 0.9314146637916565, Val Loss: 1.1149097681045532, Accuracy: 0.5676082372665405, Val Accuracy: 0.5375527739524841, Time: 30.02 sec\n",
      "Step 56000 - Training Loss: 0.9306780099868774, Val Loss: 1.1147079467773438, Accuracy: 0.5676142573356628, Val Accuracy: 0.5375668406486511, Time: 30.10 sec\n",
      "Step 56100 - Training Loss: 0.9440969228744507, Val Loss: 1.114506721496582, Accuracy: 0.5676237344741821, Val Accuracy: 0.5375521779060364, Time: 30.63 sec\n",
      "Step 56200 - Training Loss: 0.9375348091125488, Val Loss: 1.1143063306808472, Accuracy: 0.5676329731941223, Val Accuracy: 0.5375122427940369, Time: 30.93 sec\n",
      "Step 56300 - Training Loss: 0.9448226690292358, Val Loss: 1.1141066551208496, Accuracy: 0.5676354169845581, Val Accuracy: 0.5374747514724731, Time: 33.37 sec\n",
      "Step 56400 - Training Loss: 1.008927822113037, Val Loss: 1.1139075756072998, Accuracy: 0.5676388740539551, Val Accuracy: 0.5374621152877808, Time: 34.75 sec\n",
      "Step 56500 - Training Loss: 0.9035651087760925, Val Loss: 1.1137093305587769, Accuracy: 0.5676431655883789, Val Accuracy: 0.5374128222465515, Time: 35.78 sec\n",
      "Step 56600 - Training Loss: 0.9839680790901184, Val Loss: 1.1135116815567017, Accuracy: 0.5676500201225281, Val Accuracy: 0.5373712778091431, Time: 36.43 sec\n",
      "Step 56700 - Training Loss: 0.9266721606254578, Val Loss: 1.1133146286010742, Accuracy: 0.5676609873771667, Val Accuracy: 0.5373291969299316, Time: 36.73 sec\n",
      "Step 56800 - Training Loss: 0.9269890785217285, Val Loss: 1.1131184101104736, Accuracy: 0.5676671266555786, Val Accuracy: 0.5372993350028992, Time: 36.24 sec\n",
      "Step 56900 - Training Loss: 0.9606707096099854, Val Loss: 1.1129227876663208, Accuracy: 0.5676857233047485, Val Accuracy: 0.537255585193634, Time: 35.79 sec\n",
      "Step 57000 - Training Loss: 0.9457986950874329, Val Loss: 1.1127278804779053, Accuracy: 0.567699134349823, Val Accuracy: 0.5372284054756165, Time: 36.30 sec\n",
      "Step 57100 - Training Loss: 0.9572682976722717, Val Loss: 1.112533688545227, Accuracy: 0.5677093267440796, Val Accuracy: 0.5371721386909485, Time: 35.76 sec\n",
      "Step 57200 - Training Loss: 0.950323224067688, Val Loss: 1.1123400926589966, Accuracy: 0.5677168369293213, Val Accuracy: 0.5371679663658142, Time: 36.68 sec\n",
      "Step 57300 - Training Loss: 0.9484075307846069, Val Loss: 1.1121470928192139, Accuracy: 0.5677193403244019, Val Accuracy: 0.5371798276901245, Time: 35.56 sec\n",
      "Step 57400 - Training Loss: 0.9360449910163879, Val Loss: 1.111954927444458, Accuracy: 0.5677213668823242, Val Accuracy: 0.5371600389480591, Time: 30.01 sec\n",
      "Step 57500 - Training Loss: 0.9124701619148254, Val Loss: 1.1117632389068604, Accuracy: 0.5677275657653809, Val Accuracy: 0.5371519327163696, Time: 30.68 sec\n",
      "Step 57600 - Training Loss: 0.9637796878814697, Val Loss: 1.1115723848342896, Accuracy: 0.5677288174629211, Val Accuracy: 0.5371638536453247, Time: 30.83 sec\n",
      "Step 57700 - Training Loss: 0.9429433345794678, Val Loss: 1.1113821268081665, Accuracy: 0.5677379965782166, Val Accuracy: 0.5371779203414917, Time: 34.32 sec\n",
      "Step 57800 - Training Loss: 0.9713377356529236, Val Loss: 1.1111924648284912, Accuracy: 0.5677406191825867, Val Accuracy: 0.5371509790420532, Time: 36.43 sec\n",
      "Step 57900 - Training Loss: 0.955958366394043, Val Loss: 1.1110033988952637, Accuracy: 0.5677340626716614, Val Accuracy: 0.5371367335319519, Time: 35.56 sec\n",
      "Step 58000 - Training Loss: 0.9733953475952148, Val Loss: 1.1108150482177734, Accuracy: 0.5677331686019897, Val Accuracy: 0.5371378660202026, Time: 36.32 sec\n",
      "Step 58100 - Training Loss: 0.9943300485610962, Val Loss: 1.1106274127960205, Accuracy: 0.5677410960197449, Val Accuracy: 0.5371240377426147, Time: 32.32 sec\n",
      "Step 58200 - Training Loss: 0.9602872133255005, Val Loss: 1.1104402542114258, Accuracy: 0.5677436590194702, Val Accuracy: 0.5371200442314148, Time: 28.24 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 58300 - Training Loss: 0.9312503337860107, Val Loss: 1.1102538108825684, Accuracy: 0.5677480101585388, Val Accuracy: 0.5371119379997253, Time: 26.76 sec\n",
      "Step 58400 - Training Loss: 0.9823417067527771, Val Loss: 1.1100679636001587, Accuracy: 0.5677462816238403, Val Accuracy: 0.537169337272644, Time: 26.14 sec\n",
      "Step 58500 - Training Loss: 0.9468596577644348, Val Loss: 1.1098828315734863, Accuracy: 0.5677515864372253, Val Accuracy: 0.5371743440628052, Time: 26.00 sec\n",
      "Step 58600 - Training Loss: 1.0085538625717163, Val Loss: 1.1096981763839722, Accuracy: 0.5677586793899536, Val Accuracy: 0.5371533036231995, Time: 26.18 sec\n",
      "Step 58700 - Training Loss: 0.9762323498725891, Val Loss: 1.1095142364501953, Accuracy: 0.5677628517150879, Val Accuracy: 0.5371226072311401, Time: 27.10 sec\n",
      "Step 58800 - Training Loss: 0.9693577289581299, Val Loss: 1.1093308925628662, Accuracy: 0.5677745938301086, Val Accuracy: 0.5371297001838684, Time: 25.95 sec\n",
      "Step 58900 - Training Loss: 0.937081515789032, Val Loss: 1.1091482639312744, Accuracy: 0.5677805542945862, Val Accuracy: 0.5371388792991638, Time: 25.97 sec\n",
      "Step 59000 - Training Loss: 0.9582995772361755, Val Loss: 1.1089661121368408, Accuracy: 0.5677824020385742, Val Accuracy: 0.5371344089508057, Time: 26.17 sec\n",
      "Step 59100 - Training Loss: 0.9467750787734985, Val Loss: 1.108784556388855, Accuracy: 0.5677927732467651, Val Accuracy: 0.5371475219726562, Time: 26.13 sec\n",
      "Step 59200 - Training Loss: 0.9480620622634888, Val Loss: 1.1086037158966064, Accuracy: 0.567803680896759, Val Accuracy: 0.537126898765564, Time: 25.44 sec\n",
      "Step 59300 - Training Loss: 0.9467228651046753, Val Loss: 1.1084233522415161, Accuracy: 0.5678071975708008, Val Accuracy: 0.537131667137146, Time: 25.63 sec\n",
      "Step 59400 - Training Loss: 0.9297236800193787, Val Loss: 1.108243703842163, Accuracy: 0.5678113698959351, Val Accuracy: 0.5371599793434143, Time: 26.69 sec\n",
      "Step 59500 - Training Loss: 0.9301088452339172, Val Loss: 1.1080645322799683, Accuracy: 0.5678126811981201, Val Accuracy: 0.5371584892272949, Time: 26.80 sec\n",
      "Step 59600 - Training Loss: 0.9674127697944641, Val Loss: 1.1078860759735107, Accuracy: 0.5678209662437439, Val Accuracy: 0.5371481776237488, Time: 26.69 sec\n",
      "Step 59700 - Training Loss: 0.9511520266532898, Val Loss: 1.1077080965042114, Accuracy: 0.5678226947784424, Val Accuracy: 0.5371529459953308, Time: 25.62 sec\n",
      "Step 59800 - Training Loss: 0.9292227625846863, Val Loss: 1.1075307130813599, Accuracy: 0.567822277545929, Val Accuracy: 0.5371056199073792, Time: 25.51 sec\n",
      "Step 59900 - Training Loss: 0.981848418712616, Val Loss: 1.1073540449142456, Accuracy: 0.5678239464759827, Val Accuracy: 0.5370607972145081, Time: 25.63 sec\n",
      "Step 60000 - Training Loss: 0.9676450490951538, Val Loss: 1.1071778535842896, Accuracy: 0.5678229331970215, Val Accuracy: 0.537027895450592, Time: 25.62 sec\n",
      "Step 60100 - Training Loss: 0.9611449837684631, Val Loss: 1.1070021390914917, Accuracy: 0.5678290724754333, Val Accuracy: 0.5370151996612549, Time: 25.65 sec\n",
      "Step 60200 - Training Loss: 0.9343283176422119, Val Loss: 1.1068271398544312, Accuracy: 0.567829966545105, Val Accuracy: 0.5370095372200012, Time: 25.72 sec\n",
      "Step 60300 - Training Loss: 0.988588809967041, Val Loss: 1.1066527366638184, Accuracy: 0.5678338408470154, Val Accuracy: 0.5370110273361206, Time: 26.03 sec\n",
      "Step 60400 - Training Loss: 0.976802408695221, Val Loss: 1.1064788103103638, Accuracy: 0.5678390264511108, Val Accuracy: 0.5369961857795715, Time: 25.46 sec\n",
      "Step 60500 - Training Loss: 0.9471745491027832, Val Loss: 1.106305480003357, Accuracy: 0.5678463578224182, Val Accuracy: 0.5370093584060669, Time: 25.73 sec\n",
      "Step 60600 - Training Loss: 0.9781578779220581, Val Loss: 1.1061327457427979, Accuracy: 0.5678521394729614, Val Accuracy: 0.5369837880134583, Time: 25.65 sec\n",
      "Step 60700 - Training Loss: 0.9393607974052429, Val Loss: 1.105960488319397, Accuracy: 0.5678573250770569, Val Accuracy: 0.5369692444801331, Time: 25.57 sec\n",
      "Step 60800 - Training Loss: 0.9359006285667419, Val Loss: 1.1057888269424438, Accuracy: 0.5678629279136658, Val Accuracy: 0.5369406938552856, Time: 25.90 sec\n",
      "Step 60900 - Training Loss: 0.9632310271263123, Val Loss: 1.1056177616119385, Accuracy: 0.5678660273551941, Val Accuracy: 0.5369179248809814, Time: 25.46 sec\n",
      "Step 61000 - Training Loss: 0.9161795377731323, Val Loss: 1.1054472923278809, Accuracy: 0.567869246006012, Val Accuracy: 0.5369218587875366, Time: 25.49 sec\n",
      "Step 61100 - Training Loss: 0.9723424315452576, Val Loss: 1.1052772998809814, Accuracy: 0.5678762197494507, Val Accuracy: 0.5369445085525513, Time: 25.60 sec\n",
      "Step 61200 - Training Loss: 0.9428885579109192, Val Loss: 1.1051077842712402, Accuracy: 0.5678804516792297, Val Accuracy: 0.536980152130127, Time: 25.82 sec\n",
      "Step 61300 - Training Loss: 0.9655032753944397, Val Loss: 1.1049389839172363, Accuracy: 0.5678824186325073, Val Accuracy: 0.5370269417762756, Time: 25.88 sec\n",
      "Step 61400 - Training Loss: 0.9558727741241455, Val Loss: 1.104770541191101, Accuracy: 0.5678845047950745, Val Accuracy: 0.5370575785636902, Time: 25.55 sec\n",
      "Step 61500 - Training Loss: 1.0289751291275024, Val Loss: 1.1046028137207031, Accuracy: 0.5678862929344177, Val Accuracy: 0.5370874404907227, Time: 25.90 sec\n",
      "Step 61600 - Training Loss: 0.9255616068840027, Val Loss: 1.1044354438781738, Accuracy: 0.5678883194923401, Val Accuracy: 0.537104606628418, Time: 25.46 sec\n",
      "Step 61700 - Training Loss: 0.9766080975532532, Val Loss: 1.1042687892913818, Accuracy: 0.5678889751434326, Val Accuracy: 0.5371263027191162, Time: 25.27 sec\n",
      "Step 61800 - Training Loss: 0.984191358089447, Val Loss: 1.1041024923324585, Accuracy: 0.5678938031196594, Val Accuracy: 0.5370950102806091, Time: 25.87 sec\n",
      "Step 61900 - Training Loss: 0.9651681780815125, Val Loss: 1.1039369106292725, Accuracy: 0.5678990483283997, Val Accuracy: 0.5370984077453613, Time: 25.60 sec\n",
      "Step 62000 - Training Loss: 0.9143445491790771, Val Loss: 1.103771686553955, Accuracy: 0.5678982734680176, Val Accuracy: 0.537097692489624, Time: 25.69 sec\n",
      "Step 62100 - Training Loss: 0.9011972546577454, Val Loss: 1.1036070585250854, Accuracy: 0.5678988099098206, Val Accuracy: 0.5370720624923706, Time: 25.61 sec\n",
      "Step 62200 - Training Loss: 0.9340213537216187, Val Loss: 1.1034430265426636, Accuracy: 0.5679044723510742, Val Accuracy: 0.5370832085609436, Time: 25.56 sec\n",
      "Step 62300 - Training Loss: 0.9628056287765503, Val Loss: 1.1032793521881104, Accuracy: 0.5679115653038025, Val Accuracy: 0.5371206998825073, Time: 26.06 sec\n",
      "Step 62400 - Training Loss: 0.961657702922821, Val Loss: 1.1031162738800049, Accuracy: 0.5679192543029785, Val Accuracy: 0.5371235609054565, Time: 26.03 sec\n",
      "Step 62500 - Training Loss: 0.9596710801124573, Val Loss: 1.1029537916183472, Accuracy: 0.5679218173027039, Val Accuracy: 0.5371375679969788, Time: 25.54 sec\n",
      "Step 62600 - Training Loss: 0.9366125464439392, Val Loss: 1.102791666984558, Accuracy: 0.5679208040237427, Val Accuracy: 0.5371344685554504, Time: 25.93 sec\n",
      "Step 62700 - Training Loss: 0.9246550798416138, Val Loss: 1.1026301383972168, Accuracy: 0.5679255723953247, Val Accuracy: 0.5371637940406799, Time: 26.16 sec\n",
      "Step 62800 - Training Loss: 0.9483696222305298, Val Loss: 1.1024690866470337, Accuracy: 0.5679333209991455, Val Accuracy: 0.5371848940849304, Time: 25.74 sec\n",
      "Step 62900 - Training Loss: 0.9479633569717407, Val Loss: 1.1023086309432983, Accuracy: 0.5679420828819275, Val Accuracy: 0.5372018814086914, Time: 25.48 sec\n",
      "Step 63000 - Training Loss: 0.9680972695350647, Val Loss: 1.1021485328674316, Accuracy: 0.5679469704627991, Val Accuracy: 0.5372283458709717, Time: 25.78 sec\n",
      "Step 63100 - Training Loss: 0.9270638823509216, Val Loss: 1.1019890308380127, Accuracy: 0.5679506659507751, Val Accuracy: 0.5371991991996765, Time: 25.16 sec\n",
      "Step 63200 - Training Loss: 0.9439043998718262, Val Loss: 1.101830005645752, Accuracy: 0.567956268787384, Val Accuracy: 0.5371859073638916, Time: 25.31 sec\n",
      "Step 63300 - Training Loss: 0.9735848307609558, Val Loss: 1.1016714572906494, Accuracy: 0.5679635405540466, Val Accuracy: 0.5371763110160828, Time: 25.58 sec\n",
      "Step 63400 - Training Loss: 0.9593914151191711, Val Loss: 1.1015135049819946, Accuracy: 0.5679627060890198, Val Accuracy: 0.5371912717819214, Time: 25.74 sec\n",
      "Step 63500 - Training Loss: 0.9905052781105042, Val Loss: 1.1013559103012085, Accuracy: 0.5679676532745361, Val Accuracy: 0.5372116565704346, Time: 25.73 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 63600 - Training Loss: 0.9581876397132874, Val Loss: 1.1011987924575806, Accuracy: 0.567969024181366, Val Accuracy: 0.5372023582458496, Time: 25.70 sec\n",
      "Step 63700 - Training Loss: 0.9446514248847961, Val Loss: 1.1010422706604004, Accuracy: 0.567968487739563, Val Accuracy: 0.5371852517127991, Time: 25.70 sec\n",
      "Step 63800 - Training Loss: 0.9296765923500061, Val Loss: 1.1008862257003784, Accuracy: 0.5679683089256287, Val Accuracy: 0.5372143387794495, Time: 25.60 sec\n",
      "Step 63900 - Training Loss: 0.95110684633255, Val Loss: 1.100730538368225, Accuracy: 0.5679753422737122, Val Accuracy: 0.537224292755127, Time: 25.37 sec\n",
      "Step 64000 - Training Loss: 0.9827178120613098, Val Loss: 1.1005754470825195, Accuracy: 0.5679818987846375, Val Accuracy: 0.5371902585029602, Time: 25.73 sec\n",
      "Step 64100 - Training Loss: 0.9832057356834412, Val Loss: 1.1004208326339722, Accuracy: 0.567978024482727, Val Accuracy: 0.5371786952018738, Time: 25.60 sec\n",
      "Step 64200 - Training Loss: 0.9506491422653198, Val Loss: 1.1002665758132935, Accuracy: 0.5679779052734375, Val Accuracy: 0.5371593236923218, Time: 25.77 sec\n",
      "Step 64300 - Training Loss: 0.9493308663368225, Val Loss: 1.1001129150390625, Accuracy: 0.5679827928543091, Val Accuracy: 0.5371378660202026, Time: 25.35 sec\n",
      "Step 64400 - Training Loss: 0.9308155179023743, Val Loss: 1.0999597311019897, Accuracy: 0.5679887533187866, Val Accuracy: 0.5371409058570862, Time: 25.50 sec\n",
      "Step 64500 - Training Loss: 0.9565082788467407, Val Loss: 1.0998069047927856, Accuracy: 0.5679956674575806, Val Accuracy: 0.5371382832527161, Time: 25.81 sec\n",
      "Step 64600 - Training Loss: 0.9512985348701477, Val Loss: 1.0996545553207397, Accuracy: 0.5679985284805298, Val Accuracy: 0.537145733833313, Time: 26.77 sec\n",
      "Step 64700 - Training Loss: 0.9935562610626221, Val Loss: 1.0995028018951416, Accuracy: 0.5680021047592163, Val Accuracy: 0.537156343460083, Time: 26.27 sec\n",
      "Step 64800 - Training Loss: 0.938694179058075, Val Loss: 1.099351406097412, Accuracy: 0.5680066347122192, Val Accuracy: 0.5371531248092651, Time: 33.93 sec\n",
      "Step 64900 - Training Loss: 0.9095103740692139, Val Loss: 1.0992004871368408, Accuracy: 0.5680127739906311, Val Accuracy: 0.5371736288070679, Time: 34.77 sec\n",
      "Step 65000 - Training Loss: 0.9211030602455139, Val Loss: 1.0990500450134277, Accuracy: 0.568014919757843, Val Accuracy: 0.5371764898300171, Time: 36.61 sec\n",
      "Step 65100 - Training Loss: 0.9529325366020203, Val Loss: 1.0989000797271729, Accuracy: 0.5680196285247803, Val Accuracy: 0.5372082591056824, Time: 36.60 sec\n",
      "Step 65200 - Training Loss: 0.9321602582931519, Val Loss: 1.0987504720687866, Accuracy: 0.5680221319198608, Val Accuracy: 0.5372536182403564, Time: 36.06 sec\n",
      "Step 65300 - Training Loss: 0.9657666087150574, Val Loss: 1.0986013412475586, Accuracy: 0.5680313110351562, Val Accuracy: 0.5372589230537415, Time: 36.68 sec\n",
      "Step 65400 - Training Loss: 0.9797400832176208, Val Loss: 1.0984526872634888, Accuracy: 0.5680386424064636, Val Accuracy: 0.5372419953346252, Time: 36.62 sec\n",
      "Step 65500 - Training Loss: 0.9606608748435974, Val Loss: 1.0983045101165771, Accuracy: 0.5680372714996338, Val Accuracy: 0.5372299551963806, Time: 35.00 sec\n",
      "Step 65600 - Training Loss: 0.9101263284683228, Val Loss: 1.0981568098068237, Accuracy: 0.5680426955223083, Val Accuracy: 0.5372011065483093, Time: 35.53 sec\n",
      "Step 65700 - Training Loss: 0.9533068537712097, Val Loss: 1.098009467124939, Accuracy: 0.5680508017539978, Val Accuracy: 0.5371875762939453, Time: 35.86 sec\n",
      "Step 65800 - Training Loss: 0.9353389143943787, Val Loss: 1.0978626012802124, Accuracy: 0.5680527687072754, Val Accuracy: 0.5371409058570862, Time: 36.19 sec\n",
      "Step 65900 - Training Loss: 0.9653609991073608, Val Loss: 1.097716212272644, Accuracy: 0.5680556893348694, Val Accuracy: 0.5371246933937073, Time: 36.39 sec\n",
      "Step 66000 - Training Loss: 0.9405723810195923, Val Loss: 1.0975701808929443, Accuracy: 0.5680572390556335, Val Accuracy: 0.5370800495147705, Time: 36.90 sec\n",
      "Step 66100 - Training Loss: 0.966529130935669, Val Loss: 1.0974246263504028, Accuracy: 0.5680592060089111, Val Accuracy: 0.5370752215385437, Time: 37.22 sec\n",
      "Step 66200 - Training Loss: 0.948976993560791, Val Loss: 1.0972795486450195, Accuracy: 0.5680660605430603, Val Accuracy: 0.5370922684669495, Time: 36.26 sec\n",
      "Step 66300 - Training Loss: 0.9483516812324524, Val Loss: 1.0971348285675049, Accuracy: 0.5680689811706543, Val Accuracy: 0.5371050238609314, Time: 35.64 sec\n",
      "Step 66400 - Training Loss: 0.931010901927948, Val Loss: 1.0969905853271484, Accuracy: 0.5680665373802185, Val Accuracy: 0.5370728969573975, Time: 37.14 sec\n",
      "Step 66500 - Training Loss: 0.9697856903076172, Val Loss: 1.0968466997146606, Accuracy: 0.5680710673332214, Val Accuracy: 0.5370599031448364, Time: 35.54 sec\n",
      "Step 66600 - Training Loss: 0.9241760969161987, Val Loss: 1.096703290939331, Accuracy: 0.5680754780769348, Val Accuracy: 0.537040114402771, Time: 37.84 sec\n",
      "Step 66700 - Training Loss: 0.967119574546814, Val Loss: 1.0965603590011597, Accuracy: 0.5680802464485168, Val Accuracy: 0.537013590335846, Time: 38.48 sec\n",
      "Step 66800 - Training Loss: 0.9255964756011963, Val Loss: 1.096417784690857, Accuracy: 0.5680825710296631, Val Accuracy: 0.5370009541511536, Time: 37.61 sec\n",
      "Step 66900 - Training Loss: 0.9869272112846375, Val Loss: 1.0962756872177124, Accuracy: 0.568088948726654, Val Accuracy: 0.5369774699211121, Time: 34.63 sec\n",
      "Step 67000 - Training Loss: 0.9235929846763611, Val Loss: 1.0961339473724365, Accuracy: 0.5680932402610779, Val Accuracy: 0.5369306206703186, Time: 33.93 sec\n",
      "Step 67100 - Training Loss: 0.9010745286941528, Val Loss: 1.0959925651550293, Accuracy: 0.5680952668190002, Val Accuracy: 0.5369086265563965, Time: 34.40 sec\n",
      "Step 67200 - Training Loss: 0.9521040916442871, Val Loss: 1.0958517789840698, Accuracy: 0.5680986642837524, Val Accuracy: 0.536892294883728, Time: 34.26 sec\n",
      "Step 67300 - Training Loss: 0.9854143261909485, Val Loss: 1.0957112312316895, Accuracy: 0.56810063123703, Val Accuracy: 0.5368720889091492, Time: 34.87 sec\n",
      "Step 67400 - Training Loss: 0.9447900652885437, Val Loss: 1.0955711603164673, Accuracy: 0.568111777305603, Val Accuracy: 0.5368499159812927, Time: 35.35 sec\n",
      "Step 67500 - Training Loss: 0.9457077980041504, Val Loss: 1.0954315662384033, Accuracy: 0.5681180953979492, Val Accuracy: 0.5368152260780334, Time: 36.83 sec\n",
      "Step 67600 - Training Loss: 0.9786891937255859, Val Loss: 1.095292329788208, Accuracy: 0.5681252479553223, Val Accuracy: 0.5367861986160278, Time: 34.88 sec\n",
      "Step 67700 - Training Loss: 0.96036297082901, Val Loss: 1.0951534509658813, Accuracy: 0.5681262016296387, Val Accuracy: 0.5367514491081238, Time: 34.97 sec\n",
      "Step 67800 - Training Loss: 0.9465906620025635, Val Loss: 1.095015048980713, Accuracy: 0.5681259632110596, Val Accuracy: 0.5367028713226318, Time: 34.87 sec\n",
      "Step 67900 - Training Loss: 0.9463741183280945, Val Loss: 1.094877004623413, Accuracy: 0.5681236386299133, Val Accuracy: 0.5366633534431458, Time: 34.89 sec\n",
      "Step 68000 - Training Loss: 0.9829772710800171, Val Loss: 1.094739317893982, Accuracy: 0.568128764629364, Val Accuracy: 0.5366398096084595, Time: 36.27 sec\n",
      "Step 68100 - Training Loss: 0.915320634841919, Val Loss: 1.094602108001709, Accuracy: 0.5681357979774475, Val Accuracy: 0.5366149544715881, Time: 35.13 sec\n",
      "Step 68200 - Training Loss: 0.9563677310943604, Val Loss: 1.0944652557373047, Accuracy: 0.5681414008140564, Val Accuracy: 0.536596953868866, Time: 35.65 sec\n",
      "Step 68300 - Training Loss: 0.9391669034957886, Val Loss: 1.094328761100769, Accuracy: 0.5681477189064026, Val Accuracy: 0.5365617871284485, Time: 35.16 sec\n",
      "Step 68400 - Training Loss: 0.9578147530555725, Val Loss: 1.0941927433013916, Accuracy: 0.5681514143943787, Val Accuracy: 0.5365768074989319, Time: 32.69 sec\n",
      "Step 68500 - Training Loss: 1.0124053955078125, Val Loss: 1.0940570831298828, Accuracy: 0.5681570768356323, Val Accuracy: 0.5365599989891052, Time: 29.09 sec\n",
      "Step 68600 - Training Loss: 0.9374062418937683, Val Loss: 1.0939217805862427, Accuracy: 0.568164050579071, Val Accuracy: 0.536545991897583, Time: 25.59 sec\n",
      "Step 68700 - Training Loss: 0.9152280688285828, Val Loss: 1.0937869548797607, Accuracy: 0.568164587020874, Val Accuracy: 0.5365211963653564, Time: 27.10 sec\n",
      "Step 68800 - Training Loss: 0.9643661379814148, Val Loss: 1.0936524868011475, Accuracy: 0.568165123462677, Val Accuracy: 0.5365042686462402, Time: 26.68 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 68900 - Training Loss: 0.9342302680015564, Val Loss: 1.0935183763504028, Accuracy: 0.5681661367416382, Val Accuracy: 0.5364965796470642, Time: 26.44 sec\n",
      "Step 69000 - Training Loss: 0.9649488925933838, Val Loss: 1.0933846235275269, Accuracy: 0.5681639909744263, Val Accuracy: 0.536466121673584, Time: 26.53 sec\n",
      "Step 69100 - Training Loss: 0.9316642880439758, Val Loss: 1.0932512283325195, Accuracy: 0.5681662559509277, Val Accuracy: 0.5364338159561157, Time: 26.62 sec\n",
      "Step 69200 - Training Loss: 0.9928224086761475, Val Loss: 1.0931183099746704, Accuracy: 0.5681663751602173, Val Accuracy: 0.5364323854446411, Time: 26.85 sec\n",
      "Step 69300 - Training Loss: 0.9568432569503784, Val Loss: 1.09298574924469, Accuracy: 0.568169891834259, Val Accuracy: 0.5364294052124023, Time: 26.26 sec\n",
      "Step 69400 - Training Loss: 0.9260870814323425, Val Loss: 1.0928535461425781, Accuracy: 0.5681757926940918, Val Accuracy: 0.536421000957489, Time: 26.14 sec\n",
      "Step 69500 - Training Loss: 0.9336926937103271, Val Loss: 1.092721700668335, Accuracy: 0.5681788325309753, Val Accuracy: 0.5364325642585754, Time: 26.74 sec\n",
      "Step 69600 - Training Loss: 0.9547487497329712, Val Loss: 1.0925902128219604, Accuracy: 0.5681812167167664, Val Accuracy: 0.5364472270011902, Time: 25.71 sec\n",
      "Step 69700 - Training Loss: 0.9469761848449707, Val Loss: 1.0924590826034546, Accuracy: 0.5681838989257812, Val Accuracy: 0.5364585518836975, Time: 25.79 sec\n",
      "Step 69800 - Training Loss: 0.9265013933181763, Val Loss: 1.092328429222107, Accuracy: 0.5681921243667603, Val Accuracy: 0.5364530086517334, Time: 26.01 sec\n",
      "Step 69900 - Training Loss: 0.9253724813461304, Val Loss: 1.0921980142593384, Accuracy: 0.5681982040405273, Val Accuracy: 0.5364237427711487, Time: 27.19 sec\n",
      "Step 70000 - Training Loss: 0.931585967540741, Val Loss: 1.092068076133728, Accuracy: 0.5681958794593811, Val Accuracy: 0.5364292860031128, Time: 26.89 sec\n",
      "Step 70100 - Training Loss: 0.9536645412445068, Val Loss: 1.0919384956359863, Accuracy: 0.5681941509246826, Val Accuracy: 0.5364289283752441, Time: 27.22 sec\n",
      "Step 70200 - Training Loss: 0.9408605694770813, Val Loss: 1.0918092727661133, Accuracy: 0.5681951642036438, Val Accuracy: 0.5364106893539429, Time: 26.84 sec\n",
      "Step 70300 - Training Loss: 0.943483829498291, Val Loss: 1.0916802883148193, Accuracy: 0.5681954026222229, Val Accuracy: 0.5364115238189697, Time: 27.28 sec\n",
      "Step 70400 - Training Loss: 0.9708831310272217, Val Loss: 1.0915517807006836, Accuracy: 0.5682001113891602, Val Accuracy: 0.5364130735397339, Time: 26.83 sec\n",
      "Step 70500 - Training Loss: 1.0243932008743286, Val Loss: 1.0914236307144165, Accuracy: 0.568202793598175, Val Accuracy: 0.5364035367965698, Time: 27.41 sec\n",
      "Step 70600 - Training Loss: 0.947955846786499, Val Loss: 1.091295838356018, Accuracy: 0.5682089924812317, Val Accuracy: 0.53644198179245, Time: 25.78 sec\n",
      "Step 70700 - Training Loss: 0.9912347197532654, Val Loss: 1.0911684036254883, Accuracy: 0.5682113170623779, Val Accuracy: 0.5364618897438049, Time: 25.94 sec\n",
      "Step 70800 - Training Loss: 0.9334618449211121, Val Loss: 1.0910413265228271, Accuracy: 0.5682135820388794, Val Accuracy: 0.5364799499511719, Time: 26.25 sec\n",
      "Step 70900 - Training Loss: 0.9548667073249817, Val Loss: 1.0909146070480347, Accuracy: 0.5682185888290405, Val Accuracy: 0.5365214943885803, Time: 26.46 sec\n",
      "Step 71000 - Training Loss: 0.9700628519058228, Val Loss: 1.0907881259918213, Accuracy: 0.5682252049446106, Val Accuracy: 0.5365578532218933, Time: 26.79 sec\n",
      "Step 71100 - Training Loss: 0.9481131434440613, Val Loss: 1.0906621217727661, Accuracy: 0.5682291984558105, Val Accuracy: 0.5365639328956604, Time: 27.43 sec\n",
      "Step 71200 - Training Loss: 0.9896501898765564, Val Loss: 1.0905364751815796, Accuracy: 0.568231463432312, Val Accuracy: 0.53656405210495, Time: 25.88 sec\n",
      "Step 71300 - Training Loss: 0.9272361397743225, Val Loss: 1.0904110670089722, Accuracy: 0.5682368278503418, Val Accuracy: 0.5365672707557678, Time: 26.61 sec\n",
      "Step 71400 - Training Loss: 0.9384239315986633, Val Loss: 1.090286135673523, Accuracy: 0.568240761756897, Val Accuracy: 0.5365523099899292, Time: 26.54 sec\n",
      "Step 71500 - Training Loss: 0.9518057703971863, Val Loss: 1.0901614427566528, Accuracy: 0.5682398676872253, Val Accuracy: 0.5365908145904541, Time: 26.34 sec\n",
      "Step 71600 - Training Loss: 0.9481341242790222, Val Loss: 1.090037226676941, Accuracy: 0.5682432651519775, Val Accuracy: 0.536611020565033, Time: 25.87 sec\n",
      "Step 71700 - Training Loss: 0.9712449312210083, Val Loss: 1.089913249015808, Accuracy: 0.5682427287101746, Val Accuracy: 0.5366254448890686, Time: 25.70 sec\n",
      "Step 71800 - Training Loss: 1.0071474313735962, Val Loss: 1.089789628982544, Accuracy: 0.568246066570282, Val Accuracy: 0.5366212725639343, Time: 26.20 sec\n",
      "Step 71900 - Training Loss: 0.8873668313026428, Val Loss: 1.0896663665771484, Accuracy: 0.568247377872467, Val Accuracy: 0.5366268157958984, Time: 26.18 sec\n",
      "Step 72000 - Training Loss: 0.9696282148361206, Val Loss: 1.089543342590332, Accuracy: 0.5682470798492432, Val Accuracy: 0.5366129279136658, Time: 26.37 sec\n",
      "Step 72100 - Training Loss: 0.9629549384117126, Val Loss: 1.0894207954406738, Accuracy: 0.5682509541511536, Val Accuracy: 0.5365869998931885, Time: 26.14 sec\n",
      "Step 72200 - Training Loss: 0.9185002446174622, Val Loss: 1.0892984867095947, Accuracy: 0.5682530999183655, Val Accuracy: 0.536579430103302, Time: 27.41 sec\n",
      "Step 72300 - Training Loss: 0.948700487613678, Val Loss: 1.0891765356063843, Accuracy: 0.5682587623596191, Val Accuracy: 0.5365534424781799, Time: 27.53 sec\n",
      "Step 72400 - Training Loss: 0.9490265846252441, Val Loss: 1.0890549421310425, Accuracy: 0.5682599544525146, Val Accuracy: 0.5365192890167236, Time: 27.19 sec\n",
      "Step 72500 - Training Loss: 0.9281118512153625, Val Loss: 1.0889337062835693, Accuracy: 0.5682674050331116, Val Accuracy: 0.536483645439148, Time: 27.23 sec\n",
      "Step 72600 - Training Loss: 0.9293698072433472, Val Loss: 1.0888127088546753, Accuracy: 0.5682746171951294, Val Accuracy: 0.53645259141922, Time: 27.28 sec\n",
      "Step 72700 - Training Loss: 0.9923943281173706, Val Loss: 1.08869206905365, Accuracy: 0.5682796239852905, Val Accuracy: 0.5364394783973694, Time: 26.59 sec\n",
      "Step 72800 - Training Loss: 0.9965352416038513, Val Loss: 1.0885717868804932, Accuracy: 0.568285346031189, Val Accuracy: 0.5364137291908264, Time: 27.46 sec\n",
      "Step 72900 - Training Loss: 0.9520385265350342, Val Loss: 1.088451862335205, Accuracy: 0.5682864189147949, Val Accuracy: 0.5363927483558655, Time: 27.83 sec\n",
      "Step 73000 - Training Loss: 0.9095961451530457, Val Loss: 1.088332176208496, Accuracy: 0.5682886242866516, Val Accuracy: 0.5364078283309937, Time: 26.84 sec\n",
      "Step 73100 - Training Loss: 0.9327743053436279, Val Loss: 1.0882129669189453, Accuracy: 0.568287193775177, Val Accuracy: 0.5363872051239014, Time: 27.81 sec\n",
      "Step 73200 - Training Loss: 0.9644652009010315, Val Loss: 1.088093876838684, Accuracy: 0.5682910084724426, Val Accuracy: 0.5363799333572388, Time: 26.97 sec\n",
      "Step 73300 - Training Loss: 0.9127230048179626, Val Loss: 1.087975263595581, Accuracy: 0.5682929754257202, Val Accuracy: 0.5363832116127014, Time: 27.15 sec\n",
      "Step 73400 - Training Loss: 0.9264518618583679, Val Loss: 1.0878568887710571, Accuracy: 0.5682985186576843, Val Accuracy: 0.5363636016845703, Time: 28.84 sec\n",
      "Step 73500 - Training Loss: 0.9765490889549255, Val Loss: 1.0877388715744019, Accuracy: 0.5683000683784485, Val Accuracy: 0.5363667011260986, Time: 31.13 sec\n",
      "Step 73600 - Training Loss: 0.9105730056762695, Val Loss: 1.0876210927963257, Accuracy: 0.5683045387268066, Val Accuracy: 0.5363916754722595, Time: 27.91 sec\n",
      "Step 73700 - Training Loss: 0.9549844264984131, Val Loss: 1.0875037908554077, Accuracy: 0.5683082342147827, Val Accuracy: 0.5363874435424805, Time: 28.45 sec\n",
      "Step 73800 - Training Loss: 0.9137988090515137, Val Loss: 1.0873866081237793, Accuracy: 0.5683059096336365, Val Accuracy: 0.5363854765892029, Time: 28.07 sec\n",
      "Step 73900 - Training Loss: 0.9683946371078491, Val Loss: 1.087269902229309, Accuracy: 0.568312406539917, Val Accuracy: 0.536406397819519, Time: 27.57 sec\n",
      "Step 74000 - Training Loss: 0.975908100605011, Val Loss: 1.087153434753418, Accuracy: 0.5683209300041199, Val Accuracy: 0.5364288687705994, Time: 27.06 sec\n",
      "Step 74100 - Training Loss: 0.952284038066864, Val Loss: 1.087037205696106, Accuracy: 0.5683303475379944, Val Accuracy: 0.536448061466217, Time: 28.28 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 74200 - Training Loss: 0.9813990592956543, Val Loss: 1.0869214534759521, Accuracy: 0.5683354139328003, Val Accuracy: 0.5364364385604858, Time: 29.21 sec\n",
      "Step 74300 - Training Loss: 0.9310081601142883, Val Loss: 1.086805820465088, Accuracy: 0.5683372616767883, Val Accuracy: 0.53644198179245, Time: 28.37 sec\n",
      "Step 74400 - Training Loss: 0.9279798269271851, Val Loss: 1.0866906642913818, Accuracy: 0.5683424472808838, Val Accuracy: 0.5364415049552917, Time: 28.82 sec\n",
      "Step 74500 - Training Loss: 0.9863569736480713, Val Loss: 1.0865757465362549, Accuracy: 0.5683489441871643, Val Accuracy: 0.5364235639572144, Time: 28.22 sec\n",
      "Step 74600 - Training Loss: 0.9617865085601807, Val Loss: 1.086461067199707, Accuracy: 0.5683565139770508, Val Accuracy: 0.5364429354667664, Time: 28.00 sec\n",
      "Step 74700 - Training Loss: 0.9204824566841125, Val Loss: 1.0863467454910278, Accuracy: 0.568359911441803, Val Accuracy: 0.5364326238632202, Time: 28.12 sec\n",
      "Step 74800 - Training Loss: 0.9929834604263306, Val Loss: 1.0862327814102173, Accuracy: 0.5683637261390686, Val Accuracy: 0.5364170670509338, Time: 28.10 sec\n",
      "Step 74900 - Training Loss: 0.9530616998672485, Val Loss: 1.0861190557479858, Accuracy: 0.5683698654174805, Val Accuracy: 0.5364140272140503, Time: 28.20 sec\n",
      "Step 75000 - Training Loss: 0.9396294355392456, Val Loss: 1.086005687713623, Accuracy: 0.5683728456497192, Val Accuracy: 0.5364372730255127, Time: 28.56 sec\n",
      "Step 75100 - Training Loss: 0.9272685050964355, Val Loss: 1.0858925580978394, Accuracy: 0.5683786869049072, Val Accuracy: 0.5364087820053101, Time: 28.66 sec\n",
      "Step 75200 - Training Loss: 0.9879446625709534, Val Loss: 1.0857796669006348, Accuracy: 0.568381130695343, Val Accuracy: 0.5363719463348389, Time: 27.23 sec\n",
      "Step 75300 - Training Loss: 0.9763333201408386, Val Loss: 1.0856671333312988, Accuracy: 0.5683818459510803, Val Accuracy: 0.5363386869430542, Time: 28.00 sec\n",
      "Step 75400 - Training Loss: 0.9558038711547852, Val Loss: 1.0855549573898315, Accuracy: 0.5683878064155579, Val Accuracy: 0.5363050103187561, Time: 27.54 sec\n",
      "Step 75500 - Training Loss: 0.987195611000061, Val Loss: 1.0854430198669434, Accuracy: 0.5683943629264832, Val Accuracy: 0.5363120436668396, Time: 27.99 sec\n",
      "Step 75600 - Training Loss: 0.9793119430541992, Val Loss: 1.0853313207626343, Accuracy: 0.5683988928794861, Val Accuracy: 0.5363333225250244, Time: 27.68 sec\n",
      "Step 75700 - Training Loss: 0.9508821964263916, Val Loss: 1.0852199792861938, Accuracy: 0.5684038400650024, Val Accuracy: 0.5363297462463379, Time: 26.96 sec\n",
      "Step 75800 - Training Loss: 0.9570143222808838, Val Loss: 1.085108995437622, Accuracy: 0.5684041976928711, Val Accuracy: 0.5363425612449646, Time: 28.47 sec\n",
      "Step 75900 - Training Loss: 0.9386616945266724, Val Loss: 1.0849982500076294, Accuracy: 0.5684049129486084, Val Accuracy: 0.536368727684021, Time: 28.03 sec\n",
      "Step 76000 - Training Loss: 0.9914288520812988, Val Loss: 1.0848877429962158, Accuracy: 0.5684091448783875, Val Accuracy: 0.5363592505455017, Time: 27.67 sec\n",
      "Step 76100 - Training Loss: 0.9514347910881042, Val Loss: 1.0847774744033813, Accuracy: 0.568409264087677, Val Accuracy: 0.5363336801528931, Time: 27.77 sec\n",
      "Step 76200 - Training Loss: 0.9838458299636841, Val Loss: 1.0846675634384155, Accuracy: 0.5684172511100769, Val Accuracy: 0.536302924156189, Time: 27.37 sec\n",
      "Step 76300 - Training Loss: 0.9205595850944519, Val Loss: 1.0845580101013184, Accuracy: 0.5684200525283813, Val Accuracy: 0.5362831354141235, Time: 27.11 sec\n",
      "Step 76400 - Training Loss: 0.9575458765029907, Val Loss: 1.0844486951828003, Accuracy: 0.5684212446212769, Val Accuracy: 0.5362933278083801, Time: 27.71 sec\n",
      "Step 76500 - Training Loss: 0.9304260611534119, Val Loss: 1.0843396186828613, Accuracy: 0.5684245228767395, Val Accuracy: 0.5363336801528931, Time: 27.72 sec\n",
      "Step 76600 - Training Loss: 1.0085543394088745, Val Loss: 1.0842307806015015, Accuracy: 0.5684291124343872, Val Accuracy: 0.5363431572914124, Time: 28.46 sec\n",
      "Step 76700 - Training Loss: 0.9706652760505676, Val Loss: 1.0841223001480103, Accuracy: 0.56843501329422, Val Accuracy: 0.5363468527793884, Time: 27.64 sec\n",
      "Step 76800 - Training Loss: 0.978804886341095, Val Loss: 1.0840140581130981, Accuracy: 0.5684450268745422, Val Accuracy: 0.5363267660140991, Time: 27.98 sec\n",
      "Step 76900 - Training Loss: 0.9137137532234192, Val Loss: 1.0839061737060547, Accuracy: 0.5684487223625183, Val Accuracy: 0.5363354682922363, Time: 27.49 sec\n",
      "Step 77000 - Training Loss: 0.9380876421928406, Val Loss: 1.0837985277175903, Accuracy: 0.5684494376182556, Val Accuracy: 0.5363332629203796, Time: 28.47 sec\n",
      "Step 77100 - Training Loss: 0.9235517978668213, Val Loss: 1.083691120147705, Accuracy: 0.5684475302696228, Val Accuracy: 0.5363333821296692, Time: 28.92 sec\n",
      "Step 77200 - Training Loss: 0.9351561665534973, Val Loss: 1.083583950996399, Accuracy: 0.5684502720832825, Val Accuracy: 0.5363072752952576, Time: 28.54 sec\n",
      "Step 77300 - Training Loss: 0.9243137240409851, Val Loss: 1.0834771394729614, Accuracy: 0.5684545636177063, Val Accuracy: 0.5363045334815979, Time: 27.49 sec\n",
      "Step 77400 - Training Loss: 0.9063066840171814, Val Loss: 1.083370566368103, Accuracy: 0.5684645771980286, Val Accuracy: 0.5363057255744934, Time: 27.05 sec\n",
      "Step 77500 - Training Loss: 0.9878957271575928, Val Loss: 1.0832642316818237, Accuracy: 0.5684698820114136, Val Accuracy: 0.5362976789474487, Time: 27.84 sec\n",
      "Step 77600 - Training Loss: 0.9977376461029053, Val Loss: 1.083158254623413, Accuracy: 0.5684748291969299, Val Accuracy: 0.53626549243927, Time: 27.38 sec\n",
      "Step 77700 - Training Loss: 0.9173737168312073, Val Loss: 1.0830525159835815, Accuracy: 0.5684748888015747, Val Accuracy: 0.5362793803215027, Time: 27.49 sec\n",
      "Step 77800 - Training Loss: 0.9487795829772949, Val Loss: 1.082947015762329, Accuracy: 0.5684773325920105, Val Accuracy: 0.536312997341156, Time: 27.50 sec\n",
      "Step 77900 - Training Loss: 0.9550560712814331, Val Loss: 1.0828417539596558, Accuracy: 0.5684760212898254, Val Accuracy: 0.5363248586654663, Time: 28.04 sec\n",
      "Step 78000 - Training Loss: 0.9576427340507507, Val Loss: 1.082736849784851, Accuracy: 0.568472146987915, Val Accuracy: 0.5363095998764038, Time: 27.35 sec\n",
      "Step 78100 - Training Loss: 0.9345560073852539, Val Loss: 1.0826321840286255, Accuracy: 0.5684810280799866, Val Accuracy: 0.536308765411377, Time: 27.76 sec\n",
      "Step 78200 - Training Loss: 0.9495952129364014, Val Loss: 1.082527756690979, Accuracy: 0.5684816241264343, Val Accuracy: 0.5362792611122131, Time: 26.68 sec\n",
      "Step 78300 - Training Loss: 0.9586023688316345, Val Loss: 1.0824235677719116, Accuracy: 0.5684852600097656, Val Accuracy: 0.5362769961357117, Time: 27.09 sec\n",
      "Step 78400 - Training Loss: 1.0097864866256714, Val Loss: 1.0823196172714233, Accuracy: 0.568486213684082, Val Accuracy: 0.5362852811813354, Time: 27.19 sec\n",
      "Step 78500 - Training Loss: 0.9272275567054749, Val Loss: 1.0822160243988037, Accuracy: 0.5684864521026611, Val Accuracy: 0.5362910032272339, Time: 27.38 sec\n",
      "Step 78600 - Training Loss: 0.9528164863586426, Val Loss: 1.0821126699447632, Accuracy: 0.5684904456138611, Val Accuracy: 0.5362668633460999, Time: 27.07 sec\n",
      "Step 78700 - Training Loss: 0.9490002989768982, Val Loss: 1.0820095539093018, Accuracy: 0.5684905052185059, Val Accuracy: 0.5362380743026733, Time: 26.98 sec\n",
      "Step 78800 - Training Loss: 0.9216874837875366, Val Loss: 1.0819066762924194, Accuracy: 0.5684952139854431, Val Accuracy: 0.5362154245376587, Time: 26.64 sec\n",
      "Step 78900 - Training Loss: 0.939629852771759, Val Loss: 1.0818041563034058, Accuracy: 0.5685008764266968, Val Accuracy: 0.5361897349357605, Time: 26.40 sec\n",
      "Step 79000 - Training Loss: 0.9690395593643188, Val Loss: 1.0817017555236816, Accuracy: 0.5685016512870789, Val Accuracy: 0.5361822247505188, Time: 26.10 sec\n",
      "Step 79100 - Training Loss: 1.0187594890594482, Val Loss: 1.0815997123718262, Accuracy: 0.568499743938446, Val Accuracy: 0.5361681580543518, Time: 26.44 sec\n",
      "Step 79200 - Training Loss: 0.9431561827659607, Val Loss: 1.0814977884292603, Accuracy: 0.5685015916824341, Val Accuracy: 0.5361371636390686, Time: 26.24 sec\n",
      "Step 79300 - Training Loss: 0.9629901647567749, Val Loss: 1.081396222114563, Accuracy: 0.5684999227523804, Val Accuracy: 0.5361194014549255, Time: 25.96 sec\n",
      "Step 79400 - Training Loss: 0.9636638760566711, Val Loss: 1.0812948942184448, Accuracy: 0.5685005784034729, Val Accuracy: 0.5360976457595825, Time: 27.18 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 79500 - Training Loss: 0.9281643629074097, Val Loss: 1.0811939239501953, Accuracy: 0.5685048699378967, Val Accuracy: 0.5360739827156067, Time: 27.51 sec\n",
      "Step 79600 - Training Loss: 0.9652828574180603, Val Loss: 1.0810930728912354, Accuracy: 0.5685061812400818, Val Accuracy: 0.5360564589500427, Time: 26.91 sec\n",
      "Step 79700 - Training Loss: 0.9286817312240601, Val Loss: 1.0809924602508545, Accuracy: 0.5685051083564758, Val Accuracy: 0.5360533595085144, Time: 27.08 sec\n",
      "Step 79800 - Training Loss: 0.955996036529541, Val Loss: 1.0808922052383423, Accuracy: 0.5685079097747803, Val Accuracy: 0.5360559821128845, Time: 27.63 sec\n",
      "Step 79900 - Training Loss: 0.9413303732872009, Val Loss: 1.0807920694351196, Accuracy: 0.5685102939605713, Val Accuracy: 0.5360385775566101, Time: 26.88 sec\n",
      "Step 80000 - Training Loss: 0.9710018038749695, Val Loss: 1.0806922912597656, Accuracy: 0.5685119032859802, Val Accuracy: 0.5360025763511658, Time: 26.42 sec\n",
      "Step 80100 - Training Loss: 0.9721040725708008, Val Loss: 1.0805926322937012, Accuracy: 0.5685112476348877, Val Accuracy: 0.5359684228897095, Time: 27.68 sec\n",
      "Step 80200 - Training Loss: 0.9501407146453857, Val Loss: 1.0804933309555054, Accuracy: 0.5685123801231384, Val Accuracy: 0.5359293222427368, Time: 27.69 sec\n",
      "Step 80300 - Training Loss: 0.9366143941879272, Val Loss: 1.0803942680358887, Accuracy: 0.5685129165649414, Val Accuracy: 0.5358943939208984, Time: 27.82 sec\n",
      "Step 80400 - Training Loss: 0.9548311829566956, Val Loss: 1.080295443534851, Accuracy: 0.5685133337974548, Val Accuracy: 0.5358605980873108, Time: 26.71 sec\n",
      "Step 80500 - Training Loss: 0.9559440016746521, Val Loss: 1.0801968574523926, Accuracy: 0.5685175061225891, Val Accuracy: 0.5358167290687561, Time: 27.00 sec\n",
      "Step 80600 - Training Loss: 0.93373703956604, Val Loss: 1.0800983905792236, Accuracy: 0.5685200691223145, Val Accuracy: 0.5358242988586426, Time: 27.44 sec\n",
      "Step 80700 - Training Loss: 0.9479734301567078, Val Loss: 1.0800002813339233, Accuracy: 0.5685222148895264, Val Accuracy: 0.5357965230941772, Time: 26.65 sec\n",
      "Step 80800 - Training Loss: 0.9653394818305969, Val Loss: 1.0799024105072021, Accuracy: 0.5685266852378845, Val Accuracy: 0.5357658863067627, Time: 26.80 sec\n",
      "Step 80900 - Training Loss: 0.9448525309562683, Val Loss: 1.07980477809906, Accuracy: 0.5685293078422546, Val Accuracy: 0.5357502698898315, Time: 26.99 sec\n",
      "Step 81000 - Training Loss: 0.9701418280601501, Val Loss: 1.079707384109497, Accuracy: 0.5685334801673889, Val Accuracy: 0.535716712474823, Time: 27.63 sec\n",
      "Step 81100 - Training Loss: 0.9493709206581116, Val Loss: 1.0796102285385132, Accuracy: 0.5685330033302307, Val Accuracy: 0.53568434715271, Time: 27.33 sec\n",
      "Step 81200 - Training Loss: 0.9456444978713989, Val Loss: 1.0795133113861084, Accuracy: 0.5685334205627441, Val Accuracy: 0.5356449484825134, Time: 27.78 sec\n",
      "Step 81300 - Training Loss: 0.9486474990844727, Val Loss: 1.0794166326522827, Accuracy: 0.5685331225395203, Val Accuracy: 0.5356026887893677, Time: 26.48 sec\n",
      "Step 81400 - Training Loss: 0.9108384847640991, Val Loss: 1.0793201923370361, Accuracy: 0.5685362815856934, Val Accuracy: 0.5355832576751709, Time: 26.35 sec\n",
      "Step 81500 - Training Loss: 0.9272578954696655, Val Loss: 1.0792239904403687, Accuracy: 0.5685427784919739, Val Accuracy: 0.5355438590049744, Time: 27.42 sec\n",
      "Step 81600 - Training Loss: 0.9133092761039734, Val Loss: 1.0791279077529907, Accuracy: 0.5685473084449768, Val Accuracy: 0.5355053544044495, Time: 27.15 sec\n",
      "Step 81700 - Training Loss: 0.9101120829582214, Val Loss: 1.0790321826934814, Accuracy: 0.5685515403747559, Val Accuracy: 0.5354827046394348, Time: 27.31 sec\n",
      "Step 81800 - Training Loss: 0.9083489775657654, Val Loss: 1.0789366960525513, Accuracy: 0.5685533285140991, Val Accuracy: 0.535450279712677, Time: 27.46 sec\n",
      "Step 81900 - Training Loss: 0.9389644861221313, Val Loss: 1.0788413286209106, Accuracy: 0.5685563683509827, Val Accuracy: 0.5354257822036743, Time: 27.43 sec\n",
      "Step 82000 - Training Loss: 0.9553322792053223, Val Loss: 1.0787463188171387, Accuracy: 0.5685598850250244, Val Accuracy: 0.5354066491127014, Time: 26.79 sec\n",
      "Step 82100 - Training Loss: 0.9748808741569519, Val Loss: 1.0786514282226562, Accuracy: 0.5685617923736572, Val Accuracy: 0.5353773236274719, Time: 26.86 sec\n",
      "Step 82200 - Training Loss: 0.9755404591560364, Val Loss: 1.0785568952560425, Accuracy: 0.5685614347457886, Val Accuracy: 0.5353540778160095, Time: 26.48 sec\n",
      "Step 82300 - Training Loss: 0.9810589551925659, Val Loss: 1.0784624814987183, Accuracy: 0.5685633420944214, Val Accuracy: 0.5353361368179321, Time: 26.68 sec\n",
      "Step 82400 - Training Loss: 0.9409312009811401, Val Loss: 1.0783683061599731, Accuracy: 0.5685705542564392, Val Accuracy: 0.5352973341941833, Time: 26.72 sec\n",
      "Step 82500 - Training Loss: 0.9801435470581055, Val Loss: 1.0782743692398071, Accuracy: 0.568572998046875, Val Accuracy: 0.5352599620819092, Time: 26.82 sec\n",
      "Step 82600 - Training Loss: 0.9565340280532837, Val Loss: 1.0781806707382202, Accuracy: 0.5685786008834839, Val Accuracy: 0.5352263450622559, Time: 27.43 sec\n",
      "Step 82700 - Training Loss: 0.9539020657539368, Val Loss: 1.0780872106552124, Accuracy: 0.5685811042785645, Val Accuracy: 0.5351854562759399, Time: 27.29 sec\n",
      "Step 82800 - Training Loss: 0.9507488012313843, Val Loss: 1.0779939889907837, Accuracy: 0.5685825347900391, Val Accuracy: 0.535153865814209, Time: 30.78 sec\n",
      "Step 82900 - Training Loss: 0.9281924962997437, Val Loss: 1.0779008865356445, Accuracy: 0.5685852766036987, Val Accuracy: 0.5351275205612183, Time: 29.06 sec\n",
      "Step 83000 - Training Loss: 0.9471107125282288, Val Loss: 1.077808141708374, Accuracy: 0.5685880780220032, Val Accuracy: 0.5350987911224365, Time: 26.27 sec\n",
      "Step 83100 - Training Loss: 0.9513649940490723, Val Loss: 1.077715516090393, Accuracy: 0.5685855150222778, Val Accuracy: 0.5350732803344727, Time: 26.19 sec\n",
      "Step 83200 - Training Loss: 0.9364496469497681, Val Loss: 1.0776231288909912, Accuracy: 0.5685859322547913, Val Accuracy: 0.5350372791290283, Time: 26.09 sec\n",
      "Step 83300 - Training Loss: 0.9307382702827454, Val Loss: 1.0775309801101685, Accuracy: 0.5685855150222778, Val Accuracy: 0.5350134968757629, Time: 27.26 sec\n",
      "Step 83400 - Training Loss: 0.9074544310569763, Val Loss: 1.0774390697479248, Accuracy: 0.5685863494873047, Val Accuracy: 0.5349993109703064, Time: 28.14 sec\n",
      "Step 83500 - Training Loss: 0.9352610111236572, Val Loss: 1.0773472785949707, Accuracy: 0.5685874819755554, Val Accuracy: 0.5349715948104858, Time: 27.21 sec\n",
      "Step 83600 - Training Loss: 0.9410308003425598, Val Loss: 1.0772558450698853, Accuracy: 0.5685898661613464, Val Accuracy: 0.5349633693695068, Time: 27.07 sec\n",
      "Step 83700 - Training Loss: 0.9393030405044556, Val Loss: 1.0771645307540894, Accuracy: 0.56859290599823, Val Accuracy: 0.5349331498146057, Time: 26.45 sec\n",
      "Step 83800 - Training Loss: 0.9546656012535095, Val Loss: 1.0770734548568726, Accuracy: 0.5685952305793762, Val Accuracy: 0.5349029302597046, Time: 26.87 sec\n",
      "Step 83900 - Training Loss: 0.9605383276939392, Val Loss: 1.0769826173782349, Accuracy: 0.5685951709747314, Val Accuracy: 0.5348690152168274, Time: 26.66 sec\n",
      "Step 84000 - Training Loss: 0.9510095715522766, Val Loss: 1.0768920183181763, Accuracy: 0.5685949325561523, Val Accuracy: 0.5348376631736755, Time: 29.08 sec\n",
      "Step 84100 - Training Loss: 0.9478131532669067, Val Loss: 1.0768015384674072, Accuracy: 0.5685967206954956, Val Accuracy: 0.5348150730133057, Time: 28.08 sec\n",
      "Step 84200 - Training Loss: 0.9488591551780701, Val Loss: 1.0767112970352173, Accuracy: 0.5685939192771912, Val Accuracy: 0.5347868204116821, Time: 27.41 sec\n",
      "Step 84300 - Training Loss: 0.933182418346405, Val Loss: 1.0766212940216064, Accuracy: 0.5685961842536926, Val Accuracy: 0.5347493886947632, Time: 27.68 sec\n",
      "Step 84400 - Training Loss: 0.9745384454727173, Val Loss: 1.0765315294265747, Accuracy: 0.5685943961143494, Val Accuracy: 0.5347557663917542, Time: 27.88 sec\n",
      "Step 84500 - Training Loss: 0.9554831981658936, Val Loss: 1.076442003250122, Accuracy: 0.5685941576957703, Val Accuracy: 0.5347305536270142, Time: 27.80 sec\n",
      "Step 84600 - Training Loss: 0.9333691596984863, Val Loss: 1.076352596282959, Accuracy: 0.5685943365097046, Val Accuracy: 0.5346909165382385, Time: 27.34 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 84700 - Training Loss: 0.9447942972183228, Val Loss: 1.076263427734375, Accuracy: 0.5685953497886658, Val Accuracy: 0.5346537828445435, Time: 26.60 sec\n",
      "Step 84800 - Training Loss: 0.9534649848937988, Val Loss: 1.0761744976043701, Accuracy: 0.5685993432998657, Val Accuracy: 0.534613847732544, Time: 26.91 sec\n",
      "Step 84900 - Training Loss: 0.9281878471374512, Val Loss: 1.0760856866836548, Accuracy: 0.5686012506484985, Val Accuracy: 0.5345780253410339, Time: 29.09 sec\n",
      "Step 85000 - Training Loss: 0.9651088118553162, Val Loss: 1.075997233390808, Accuracy: 0.5686013698577881, Val Accuracy: 0.5345428586006165, Time: 27.27 sec\n",
      "Step 85100 - Training Loss: 0.9630553126335144, Val Loss: 1.075908899307251, Accuracy: 0.5686017274856567, Val Accuracy: 0.534515917301178, Time: 27.39 sec\n",
      "Step 85200 - Training Loss: 0.934823215007782, Val Loss: 1.0758206844329834, Accuracy: 0.568601131439209, Val Accuracy: 0.5345118641853333, Time: 27.80 sec\n",
      "Step 85300 - Training Loss: 0.9577645063400269, Val Loss: 1.0757328271865845, Accuracy: 0.568607747554779, Val Accuracy: 0.5345026254653931, Time: 26.29 sec\n",
      "Step 85400 - Training Loss: 0.9366341233253479, Val Loss: 1.075645089149475, Accuracy: 0.568606436252594, Val Accuracy: 0.5344709753990173, Time: 26.17 sec\n",
      "Step 85500 - Training Loss: 0.9498354196548462, Val Loss: 1.0755575895309448, Accuracy: 0.5686085820198059, Val Accuracy: 0.5344421863555908, Time: 26.34 sec\n",
      "Step 85600 - Training Loss: 0.9741702675819397, Val Loss: 1.075470209121704, Accuracy: 0.5686120986938477, Val Accuracy: 0.534407913684845, Time: 26.17 sec\n",
      "Step 85700 - Training Loss: 0.9146411418914795, Val Loss: 1.075383186340332, Accuracy: 0.5686120390892029, Val Accuracy: 0.5343682169914246, Time: 26.16 sec\n",
      "Step 85800 - Training Loss: 0.9798709154129028, Val Loss: 1.0752962827682495, Accuracy: 0.5686142444610596, Val Accuracy: 0.5343363285064697, Time: 26.35 sec\n",
      "Step 85900 - Training Loss: 0.9328039884567261, Val Loss: 1.075209617614746, Accuracy: 0.5686161518096924, Val Accuracy: 0.5343030691146851, Time: 26.28 sec\n",
      "Step 86000 - Training Loss: 0.9668397903442383, Val Loss: 1.0751230716705322, Accuracy: 0.5686191320419312, Val Accuracy: 0.5342696309089661, Time: 27.36 sec\n",
      "Step 86100 - Training Loss: 0.9443978667259216, Val Loss: 1.0750367641448975, Accuracy: 0.5686202645301819, Val Accuracy: 0.5342399477958679, Time: 27.01 sec\n",
      "Step 86200 - Training Loss: 1.0123540163040161, Val Loss: 1.0749505758285522, Accuracy: 0.5686220526695251, Val Accuracy: 0.5342013835906982, Time: 26.98 sec\n",
      "Step 86300 - Training Loss: 0.9927949905395508, Val Loss: 1.0748647451400757, Accuracy: 0.5686240792274475, Val Accuracy: 0.5341829061508179, Time: 27.84 sec\n",
      "Step 86400 - Training Loss: 0.9333234429359436, Val Loss: 1.0747790336608887, Accuracy: 0.5686236023902893, Val Accuracy: 0.5341439843177795, Time: 27.65 sec\n",
      "Step 86500 - Training Loss: 0.9657710790634155, Val Loss: 1.0746934413909912, Accuracy: 0.5686256289482117, Val Accuracy: 0.5341049432754517, Time: 27.20 sec\n",
      "Step 86600 - Training Loss: 0.9674413204193115, Val Loss: 1.0746080875396729, Accuracy: 0.5686271786689758, Val Accuracy: 0.5340659618377686, Time: 26.08 sec\n",
      "Step 86700 - Training Loss: 0.9536856412887573, Val Loss: 1.0745229721069336, Accuracy: 0.5686280727386475, Val Accuracy: 0.534027099609375, Time: 27.24 sec\n",
      "Step 86800 - Training Loss: 1.002651333808899, Val Loss: 1.0744380950927734, Accuracy: 0.5686280131340027, Val Accuracy: 0.5339882969856262, Time: 27.00 sec\n",
      "Step 86900 - Training Loss: 0.9340430498123169, Val Loss: 1.0743533372879028, Accuracy: 0.5686314702033997, Val Accuracy: 0.533949613571167, Time: 27.92 sec\n",
      "Step 87000 - Training Loss: 0.9575613141059875, Val Loss: 1.0742686986923218, Accuracy: 0.5686354041099548, Val Accuracy: 0.5339110493659973, Time: 29.60 sec\n",
      "Step 87100 - Training Loss: 0.9693130254745483, Val Loss: 1.0741844177246094, Accuracy: 0.5686367750167847, Val Accuracy: 0.5338724851608276, Time: 27.54 sec\n",
      "Step 87200 - Training Loss: 0.931267499923706, Val Loss: 1.0741002559661865, Accuracy: 0.5686375498771667, Val Accuracy: 0.5338340401649475, Time: 26.88 sec\n",
      "Step 87300 - Training Loss: 0.9638612866401672, Val Loss: 1.0740162134170532, Accuracy: 0.5686384439468384, Val Accuracy: 0.5337957143783569, Time: 27.66 sec\n",
      "Step 87400 - Training Loss: 0.9777907133102417, Val Loss: 1.073932409286499, Accuracy: 0.5686392188072205, Val Accuracy: 0.5337574481964111, Time: 28.05 sec\n",
      "Step 87500 - Training Loss: 0.9326497912406921, Val Loss: 1.073848843574524, Accuracy: 0.5686423182487488, Val Accuracy: 0.5337193012237549, Time: 28.92 sec\n",
      "Step 87600 - Training Loss: 0.9648914337158203, Val Loss: 1.0737653970718384, Accuracy: 0.5686447620391846, Val Accuracy: 0.5336812138557434, Time: 28.16 sec\n",
      "Step 87700 - Training Loss: 0.949506938457489, Val Loss: 1.073682188987732, Accuracy: 0.5686491131782532, Val Accuracy: 0.5336431860923767, Time: 26.87 sec\n",
      "Step 87800 - Training Loss: 0.9431780576705933, Val Loss: 1.073599100112915, Accuracy: 0.5686506032943726, Val Accuracy: 0.5336052775382996, Time: 27.60 sec\n",
      "Step 87900 - Training Loss: 0.9496509432792664, Val Loss: 1.0735162496566772, Accuracy: 0.5686537623405457, Val Accuracy: 0.5335674285888672, Time: 26.71 sec\n",
      "Step 88000 - Training Loss: 0.964730441570282, Val Loss: 1.0734336376190186, Accuracy: 0.5686514377593994, Val Accuracy: 0.5335296988487244, Time: 26.64 sec\n",
      "Step 88100 - Training Loss: 0.9789543747901917, Val Loss: 1.0733511447906494, Accuracy: 0.5686519742012024, Val Accuracy: 0.5334920287132263, Time: 26.96 sec\n",
      "Step 88200 - Training Loss: 0.9515833258628845, Val Loss: 1.0732688903808594, Accuracy: 0.5686538219451904, Val Accuracy: 0.5334544777870178, Time: 26.69 sec\n",
      "Step 88300 - Training Loss: 0.9328576922416687, Val Loss: 1.0731867551803589, Accuracy: 0.5686559677124023, Val Accuracy: 0.5334169864654541, Time: 27.36 sec\n",
      "Step 88400 - Training Loss: 0.9794492721557617, Val Loss: 1.0731048583984375, Accuracy: 0.5686571598052979, Val Accuracy: 0.5333795547485352, Time: 27.80 sec\n",
      "Step 88500 - Training Loss: 0.9800654649734497, Val Loss: 1.0730230808258057, Accuracy: 0.5686593651771545, Val Accuracy: 0.5333422422409058, Time: 27.13 sec\n",
      "Step 88600 - Training Loss: 0.9913842678070068, Val Loss: 1.072941541671753, Accuracy: 0.5686575770378113, Val Accuracy: 0.5333049893379211, Time: 26.74 sec\n",
      "Step 88700 - Training Loss: 0.9853528738021851, Val Loss: 1.0728601217269897, Accuracy: 0.5686572790145874, Val Accuracy: 0.5332678556442261, Time: 26.60 sec\n",
      "Step 88800 - Training Loss: 0.9362007975578308, Val Loss: 1.0727789402008057, Accuracy: 0.5686575770378113, Val Accuracy: 0.5332307815551758, Time: 26.48 sec\n",
      "Step 88900 - Training Loss: 0.9349080920219421, Val Loss: 1.0726978778839111, Accuracy: 0.5686566233634949, Val Accuracy: 0.5331937670707703, Time: 26.96 sec\n",
      "Step 89000 - Training Loss: 0.9539289474487305, Val Loss: 1.0726170539855957, Accuracy: 0.5686558485031128, Val Accuracy: 0.5331568717956543, Time: 26.59 sec\n",
      "Step 89100 - Training Loss: 0.9438562989234924, Val Loss: 1.0725364685058594, Accuracy: 0.5686553716659546, Val Accuracy: 0.5331200361251831, Time: 26.99 sec\n",
      "Step 89200 - Training Loss: 0.9550764560699463, Val Loss: 1.0724560022354126, Accuracy: 0.5686551332473755, Val Accuracy: 0.5330833196640015, Time: 27.04 sec\n",
      "Step 89300 - Training Loss: 0.9652538895606995, Val Loss: 1.0723756551742554, Accuracy: 0.5686554312705994, Val Accuracy: 0.5330486297607422, Time: 26.58 sec\n",
      "Step 89400 - Training Loss: 0.9333087801933289, Val Loss: 1.0722955465316772, Accuracy: 0.5686575770378113, Val Accuracy: 0.5330120325088501, Time: 26.79 sec\n",
      "Step 89500 - Training Loss: 0.9475222826004028, Val Loss: 1.0722155570983887, Accuracy: 0.5686591863632202, Val Accuracy: 0.5329754948616028, Time: 26.89 sec\n",
      "Step 89600 - Training Loss: 0.9289127588272095, Val Loss: 1.0721358060836792, Accuracy: 0.5686566233634949, Val Accuracy: 0.532939076423645, Time: 26.77 sec\n",
      "Step 89700 - Training Loss: 0.9498165845870972, Val Loss: 1.0720562934875488, Accuracy: 0.5686558485031128, Val Accuracy: 0.5329027771949768, Time: 26.81 sec\n",
      "Step 89800 - Training Loss: 0.9840373992919922, Val Loss: 1.0719767808914185, Accuracy: 0.5686585307121277, Val Accuracy: 0.5328664779663086, Time: 26.61 sec\n",
      "Step 89900 - Training Loss: 0.9545081853866577, Val Loss: 1.0718976259231567, Accuracy: 0.568661093711853, Val Accuracy: 0.5328302979469299, Time: 27.33 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90000 - Training Loss: 0.9139426350593567, Val Loss: 1.071818470954895, Accuracy: 0.5686619281768799, Val Accuracy: 0.532794177532196, Time: 28.89 sec\n",
      "Step 90100 - Training Loss: 0.983289361000061, Val Loss: 1.071739673614502, Accuracy: 0.5686627626419067, Val Accuracy: 0.5327581763267517, Time: 35.65 sec\n",
      "Step 90200 - Training Loss: 0.9399832487106323, Val Loss: 1.0716608762741089, Accuracy: 0.5686607956886292, Val Accuracy: 0.5327222347259521, Time: 33.56 sec\n",
      "Step 90300 - Training Loss: 0.9586684703826904, Val Loss: 1.071582317352295, Accuracy: 0.5686614513397217, Val Accuracy: 0.5326863527297974, Time: 36.21 sec\n",
      "Step 90400 - Training Loss: 0.9544779658317566, Val Loss: 1.07150399684906, Accuracy: 0.5686647891998291, Val Accuracy: 0.5326505899429321, Time: 34.16 sec\n",
      "Step 90500 - Training Loss: 0.9281837940216064, Val Loss: 1.0714257955551147, Accuracy: 0.5686649680137634, Val Accuracy: 0.5326148867607117, Time: 35.43 sec\n",
      "Step 90600 - Training Loss: 0.913955807685852, Val Loss: 1.071347713470459, Accuracy: 0.5686671733856201, Val Accuracy: 0.532579243183136, Time: 31.17 sec\n",
      "Step 90700 - Training Loss: 0.9230867624282837, Val Loss: 1.0712698698043823, Accuracy: 0.5686690807342529, Val Accuracy: 0.5325436592102051, Time: 32.06 sec\n",
      "Step 90800 - Training Loss: 0.9454882144927979, Val Loss: 1.0711921453475952, Accuracy: 0.5686711072921753, Val Accuracy: 0.5325081944465637, Time: 33.84 sec\n",
      "Step 90900 - Training Loss: 0.9040719866752625, Val Loss: 1.0711146593093872, Accuracy: 0.5686739683151245, Val Accuracy: 0.5324727892875671, Time: 36.68 sec\n",
      "Step 91000 - Training Loss: 0.928902804851532, Val Loss: 1.0710372924804688, Accuracy: 0.5686764121055603, Val Accuracy: 0.5324375033378601, Time: 38.13 sec\n",
      "Step 91100 - Training Loss: 0.9342818856239319, Val Loss: 1.0709601640701294, Accuracy: 0.5686790347099304, Val Accuracy: 0.5324022173881531, Time: 36.11 sec\n",
      "Step 91200 - Training Loss: 0.9596384167671204, Val Loss: 1.0708831548690796, Accuracy: 0.5686831474304199, Val Accuracy: 0.5323670506477356, Time: 35.08 sec\n",
      "Step 91300 - Training Loss: 0.9313399791717529, Val Loss: 1.0708062648773193, Accuracy: 0.5686801671981812, Val Accuracy: 0.5323320031166077, Time: 33.11 sec\n",
      "Step 91400 - Training Loss: 0.9532108902931213, Val Loss: 1.0707296133041382, Accuracy: 0.5686836242675781, Val Accuracy: 0.5322969555854797, Time: 36.03 sec\n",
      "Step 91500 - Training Loss: 0.9811160564422607, Val Loss: 1.0706530809402466, Accuracy: 0.5686866044998169, Val Accuracy: 0.5322620272636414, Time: 37.15 sec\n",
      "Step 91600 - Training Loss: 0.974888026714325, Val Loss: 1.0705766677856445, Accuracy: 0.5686910152435303, Val Accuracy: 0.5322271585464478, Time: 36.58 sec\n",
      "Step 91700 - Training Loss: 0.9694183468818665, Val Loss: 1.0705004930496216, Accuracy: 0.5686936974525452, Val Accuracy: 0.5321923494338989, Time: 36.10 sec\n",
      "Step 91800 - Training Loss: 0.9660850763320923, Val Loss: 1.0704244375228882, Accuracy: 0.5686991810798645, Val Accuracy: 0.5321576595306396, Time: 35.12 sec\n",
      "Step 91900 - Training Loss: 0.926765501499176, Val Loss: 1.0703486204147339, Accuracy: 0.5686988830566406, Val Accuracy: 0.5321230292320251, Time: 35.72 sec\n",
      "Step 92000 - Training Loss: 0.9494643807411194, Val Loss: 1.0702729225158691, Accuracy: 0.56870436668396, Val Accuracy: 0.5320884585380554, Time: 35.53 sec\n",
      "Step 92100 - Training Loss: 0.9974879026412964, Val Loss: 1.070197343826294, Accuracy: 0.5687060356140137, Val Accuracy: 0.5320539474487305, Time: 35.96 sec\n",
      "Step 92200 - Training Loss: 0.9691354632377625, Val Loss: 1.0701220035552979, Accuracy: 0.5687065124511719, Val Accuracy: 0.5320195555686951, Time: 36.72 sec\n",
      "Step 92300 - Training Loss: 0.9092965722084045, Val Loss: 1.0700467824935913, Accuracy: 0.5687077045440674, Val Accuracy: 0.5319852232933044, Time: 36.28 sec\n",
      "Step 92400 - Training Loss: 0.9484535455703735, Val Loss: 1.0699717998504639, Accuracy: 0.5687078237533569, Val Accuracy: 0.5319509506225586, Time: 36.51 sec\n",
      "Step 92500 - Training Loss: 0.9465951919555664, Val Loss: 1.0698968172073364, Accuracy: 0.5687075257301331, Val Accuracy: 0.5319167375564575, Time: 35.53 sec\n",
      "Step 92600 - Training Loss: 0.9395555257797241, Val Loss: 1.069822072982788, Accuracy: 0.568709671497345, Val Accuracy: 0.5318825840950012, Time: 35.65 sec\n",
      "Step 92700 - Training Loss: 0.951116681098938, Val Loss: 1.0697475671768188, Accuracy: 0.5687108039855957, Val Accuracy: 0.5318485498428345, Time: 35.38 sec\n",
      "Step 92800 - Training Loss: 0.9812659025192261, Val Loss: 1.0696731805801392, Accuracy: 0.5687103867530823, Val Accuracy: 0.5318145751953125, Time: 35.44 sec\n",
      "Step 92900 - Training Loss: 0.9088156223297119, Val Loss: 1.069598913192749, Accuracy: 0.5687124133110046, Val Accuracy: 0.5317806601524353, Time: 36.04 sec\n",
      "Step 93000 - Training Loss: 0.9263565540313721, Val Loss: 1.0695247650146484, Accuracy: 0.5687134265899658, Val Accuracy: 0.5317468643188477, Time: 35.56 sec\n",
      "Step 93100 - Training Loss: 0.937585711479187, Val Loss: 1.069450855255127, Accuracy: 0.5687152743339539, Val Accuracy: 0.53171306848526, Time: 35.00 sec\n",
      "Step 93200 - Training Loss: 0.9501715302467346, Val Loss: 1.069377064704895, Accuracy: 0.5687111616134644, Val Accuracy: 0.5316793918609619, Time: 34.69 sec\n",
      "Step 93300 - Training Loss: 0.9486040472984314, Val Loss: 1.0693035125732422, Accuracy: 0.5687106847763062, Val Accuracy: 0.5316457748413086, Time: 35.09 sec\n",
      "Step 93400 - Training Loss: 0.9940142631530762, Val Loss: 1.0692299604415894, Accuracy: 0.568712055683136, Val Accuracy: 0.5316122174263, Time: 34.40 sec\n",
      "Step 93500 - Training Loss: 0.9322558045387268, Val Loss: 1.0691566467285156, Accuracy: 0.5687143206596375, Val Accuracy: 0.5315787196159363, Time: 32.63 sec\n",
      "Step 93600 - Training Loss: 0.9375353455543518, Val Loss: 1.069083571434021, Accuracy: 0.5687175989151001, Val Accuracy: 0.5315453410148621, Time: 29.18 sec\n",
      "Step 93700 - Training Loss: 0.9521183371543884, Val Loss: 1.0690104961395264, Accuracy: 0.5687209963798523, Val Accuracy: 0.5315120220184326, Time: 37.12 sec\n",
      "Step 93800 - Training Loss: 0.9443327188491821, Val Loss: 1.0689376592636108, Accuracy: 0.568721354007721, Val Accuracy: 0.531478762626648, Time: 34.65 sec\n",
      "Step 93900 - Training Loss: 0.9556165933609009, Val Loss: 1.0688649415969849, Accuracy: 0.5687234997749329, Val Accuracy: 0.5314455628395081, Time: 35.48 sec\n",
      "Step 94000 - Training Loss: 0.929398775100708, Val Loss: 1.068792462348938, Accuracy: 0.5687257647514343, Val Accuracy: 0.5314124226570129, Time: 35.57 sec\n",
      "Step 94100 - Training Loss: 0.9322594404220581, Val Loss: 1.0687201023101807, Accuracy: 0.5687262415885925, Val Accuracy: 0.5313793420791626, Time: 35.05 sec\n",
      "Step 94200 - Training Loss: 0.9127402305603027, Val Loss: 1.068647861480713, Accuracy: 0.5687275528907776, Val Accuracy: 0.5313463807106018, Time: 35.66 sec\n",
      "Step 94300 - Training Loss: 0.9265708327293396, Val Loss: 1.0685757398605347, Accuracy: 0.568729817867279, Val Accuracy: 0.5313134789466858, Time: 35.92 sec\n",
      "Step 94400 - Training Loss: 0.9501602649688721, Val Loss: 1.0685038566589355, Accuracy: 0.5687283277511597, Val Accuracy: 0.5312806367874146, Time: 37.34 sec\n",
      "Step 94500 - Training Loss: 0.9115250706672668, Val Loss: 1.0684319734573364, Accuracy: 0.5687292814254761, Val Accuracy: 0.5312478542327881, Time: 35.37 sec\n",
      "Step 94600 - Training Loss: 1.0072640180587769, Val Loss: 1.068360447883606, Accuracy: 0.5687296390533447, Val Accuracy: 0.5312151312828064, Time: 36.01 sec\n",
      "Step 94700 - Training Loss: 0.9632253050804138, Val Loss: 1.0682889223098755, Accuracy: 0.5687329769134521, Val Accuracy: 0.5311824679374695, Time: 34.68 sec\n",
      "Step 94800 - Training Loss: 0.9745897054672241, Val Loss: 1.0682176351547241, Accuracy: 0.5687333345413208, Val Accuracy: 0.5311499238014221, Time: 34.92 sec\n",
      "Step 94900 - Training Loss: 0.9465386867523193, Val Loss: 1.0681463479995728, Accuracy: 0.5687353610992432, Val Accuracy: 0.5311174392700195, Time: 35.24 sec\n",
      "Step 95000 - Training Loss: 0.9437912702560425, Val Loss: 1.0680752992630005, Accuracy: 0.5687403082847595, Val Accuracy: 0.5310849547386169, Time: 34.90 sec\n",
      "Step 95100 - Training Loss: 0.9651591181755066, Val Loss: 1.0680044889450073, Accuracy: 0.5687431693077087, Val Accuracy: 0.5310525894165039, Time: 36.38 sec\n",
      "Step 95200 - Training Loss: 0.9399059414863586, Val Loss: 1.0679336786270142, Accuracy: 0.5687471628189087, Val Accuracy: 0.5310202836990356, Time: 36.47 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 95300 - Training Loss: 0.93226557970047, Val Loss: 1.0678631067276, Accuracy: 0.5687490701675415, Val Accuracy: 0.5309880971908569, Time: 32.93 sec\n",
      "Step 95400 - Training Loss: 0.9325590133666992, Val Loss: 1.0677926540374756, Accuracy: 0.5687493085861206, Val Accuracy: 0.5309559106826782, Time: 33.00 sec\n",
      "Step 95500 - Training Loss: 0.97481769323349, Val Loss: 1.0677224397659302, Accuracy: 0.5687530636787415, Val Accuracy: 0.5309237837791443, Time: 36.39 sec\n",
      "Step 95600 - Training Loss: 0.9582639336585999, Val Loss: 1.0676522254943848, Accuracy: 0.568753182888031, Val Accuracy: 0.5308917760848999, Time: 31.90 sec\n",
      "Step 95700 - Training Loss: 1.0001486539840698, Val Loss: 1.0675822496414185, Accuracy: 0.5687563419342041, Val Accuracy: 0.5308598279953003, Time: 30.29 sec\n",
      "Step 95800 - Training Loss: 0.9457882642745972, Val Loss: 1.0675123929977417, Accuracy: 0.5687575936317444, Val Accuracy: 0.5308278799057007, Time: 29.27 sec\n",
      "Step 95900 - Training Loss: 0.9443349838256836, Val Loss: 1.0674426555633545, Accuracy: 0.5687562227249146, Val Accuracy: 0.5307960510253906, Time: 30.49 sec\n",
      "Step 96000 - Training Loss: 0.8946045637130737, Val Loss: 1.0673730373382568, Accuracy: 0.5687572956085205, Val Accuracy: 0.5307642817497253, Time: 29.39 sec\n",
      "Step 96100 - Training Loss: 0.9545628428459167, Val Loss: 1.0673036575317383, Accuracy: 0.5687576532363892, Val Accuracy: 0.5307325720787048, Time: 29.98 sec\n",
      "Step 96200 - Training Loss: 0.9526631832122803, Val Loss: 1.0672343969345093, Accuracy: 0.5687598586082458, Val Accuracy: 0.5307009816169739, Time: 28.09 sec\n",
      "Step 96300 - Training Loss: 0.9364473223686218, Val Loss: 1.0671651363372803, Accuracy: 0.5687623620033264, Val Accuracy: 0.5306693911552429, Time: 29.57 sec\n",
      "Step 96400 - Training Loss: 1.0087331533432007, Val Loss: 1.06709623336792, Accuracy: 0.5687638521194458, Val Accuracy: 0.5306378602981567, Time: 29.08 sec\n",
      "Step 96500 - Training Loss: 0.9356174468994141, Val Loss: 1.0670273303985596, Accuracy: 0.5687655806541443, Val Accuracy: 0.5306064486503601, Time: 30.59 sec\n",
      "Step 96600 - Training Loss: 0.9377087950706482, Val Loss: 1.0669585466384888, Accuracy: 0.5687629580497742, Val Accuracy: 0.5305750370025635, Time: 31.76 sec\n",
      "Step 96700 - Training Loss: 0.9827476143836975, Val Loss: 1.066890001296997, Accuracy: 0.5687593817710876, Val Accuracy: 0.5305437445640564, Time: 32.04 sec\n",
      "Step 96800 - Training Loss: 0.9467933177947998, Val Loss: 1.066821575164795, Accuracy: 0.5687595009803772, Val Accuracy: 0.5305124521255493, Time: 32.03 sec\n",
      "Step 96900 - Training Loss: 0.9515067934989929, Val Loss: 1.0667532682418823, Accuracy: 0.5687614679336548, Val Accuracy: 0.5304812788963318, Time: 31.27 sec\n",
      "Step 97000 - Training Loss: 0.9504937529563904, Val Loss: 1.0666850805282593, Accuracy: 0.5687631964683533, Val Accuracy: 0.530450165271759, Time: 31.78 sec\n",
      "Step 97100 - Training Loss: 0.9297570586204529, Val Loss: 1.0666171312332153, Accuracy: 0.568764328956604, Val Accuracy: 0.530419111251831, Time: 31.26 sec\n",
      "Step 97200 - Training Loss: 0.9745721220970154, Val Loss: 1.0665491819381714, Accuracy: 0.5687637329101562, Val Accuracy: 0.5303881168365479, Time: 31.16 sec\n",
      "Step 97300 - Training Loss: 0.9575813412666321, Val Loss: 1.0664814710617065, Accuracy: 0.5687648057937622, Val Accuracy: 0.5303571820259094, Time: 31.58 sec\n",
      "Step 97400 - Training Loss: 0.9650887846946716, Val Loss: 1.0664138793945312, Accuracy: 0.5687670111656189, Val Accuracy: 0.5303263068199158, Time: 31.56 sec\n",
      "Step 97500 - Training Loss: 0.9738631248474121, Val Loss: 1.0663464069366455, Accuracy: 0.5687677264213562, Val Accuracy: 0.5302954912185669, Time: 31.53 sec\n",
      "Step 97600 - Training Loss: 0.9730433821678162, Val Loss: 1.0662790536880493, Accuracy: 0.5687674283981323, Val Accuracy: 0.5302647352218628, Time: 32.29 sec\n",
      "Step 97700 - Training Loss: 0.9291556477546692, Val Loss: 1.0662118196487427, Accuracy: 0.5687656402587891, Val Accuracy: 0.5302340388298035, Time: 31.98 sec\n",
      "Step 97800 - Training Loss: 0.9255293011665344, Val Loss: 1.0661448240280151, Accuracy: 0.568764865398407, Val Accuracy: 0.5302034616470337, Time: 30.67 sec\n",
      "Step 97900 - Training Loss: 0.9910985827445984, Val Loss: 1.0660778284072876, Accuracy: 0.5687653422355652, Val Accuracy: 0.5301728844642639, Time: 30.93 sec\n",
      "Step 98000 - Training Loss: 0.9606021046638489, Val Loss: 1.0660110712051392, Accuracy: 0.5687665939331055, Val Accuracy: 0.5301423668861389, Time: 31.79 sec\n",
      "Step 98100 - Training Loss: 0.9683300852775574, Val Loss: 1.0659444332122803, Accuracy: 0.5687654614448547, Val Accuracy: 0.5301119685173035, Time: 31.71 sec\n",
      "Step 98200 - Training Loss: 0.9452420473098755, Val Loss: 1.065877914428711, Accuracy: 0.5687645077705383, Val Accuracy: 0.530081570148468, Time: 31.35 sec\n",
      "Step 98300 - Training Loss: 0.9474745988845825, Val Loss: 1.0658115148544312, Accuracy: 0.5687662363052368, Val Accuracy: 0.5300512313842773, Time: 31.90 sec\n",
      "Step 98400 - Training Loss: 0.9209399223327637, Val Loss: 1.065745234489441, Accuracy: 0.5687623023986816, Val Accuracy: 0.5300210118293762, Time: 31.74 sec\n",
      "Step 98500 - Training Loss: 0.9435815215110779, Val Loss: 1.0656791925430298, Accuracy: 0.5687576532363892, Val Accuracy: 0.5299907922744751, Time: 31.18 sec\n",
      "Step 98600 - Training Loss: 0.9822423458099365, Val Loss: 1.0656131505966187, Accuracy: 0.5687527656555176, Val Accuracy: 0.5299606919288635, Time: 30.84 sec\n",
      "Step 98700 - Training Loss: 0.9497731328010559, Val Loss: 1.0655473470687866, Accuracy: 0.5687485933303833, Val Accuracy: 0.529930591583252, Time: 31.92 sec\n",
      "Step 98800 - Training Loss: 0.9633451700210571, Val Loss: 1.0654815435409546, Accuracy: 0.5687454342842102, Val Accuracy: 0.5299006104469299, Time: 29.45 sec\n",
      "Step 98900 - Training Loss: 0.9801656007766724, Val Loss: 1.0654159784317017, Accuracy: 0.5687395930290222, Val Accuracy: 0.5298706293106079, Time: 28.07 sec\n",
      "Step 99000 - Training Loss: 0.9638254642486572, Val Loss: 1.0653505325317383, Accuracy: 0.5687342286109924, Val Accuracy: 0.5298407673835754, Time: 31.75 sec\n",
      "Step 99100 - Training Loss: 0.9633608460426331, Val Loss: 1.0652852058410645, Accuracy: 0.5687307119369507, Val Accuracy: 0.529810905456543, Time: 32.67 sec\n",
      "Step 99200 - Training Loss: 0.9210354089736938, Val Loss: 1.0652199983596802, Accuracy: 0.5687264800071716, Val Accuracy: 0.5297811627388, Time: 32.84 sec\n",
      "Step 99300 - Training Loss: 0.961561381816864, Val Loss: 1.0651549100875854, Accuracy: 0.5687196254730225, Val Accuracy: 0.5297514200210571, Time: 33.15 sec\n",
      "Step 99400 - Training Loss: 0.9374855756759644, Val Loss: 1.0650899410247803, Accuracy: 0.5687159895896912, Val Accuracy: 0.5297217965126038, Time: 33.29 sec\n",
      "Step 99500 - Training Loss: 0.9356188774108887, Val Loss: 1.0650252103805542, Accuracy: 0.5687123537063599, Val Accuracy: 0.5296921730041504, Time: 33.33 sec\n",
      "Step 99600 - Training Loss: 0.9308801889419556, Val Loss: 1.0649604797363281, Accuracy: 0.5687046647071838, Val Accuracy: 0.5296626687049866, Time: 32.77 sec\n",
      "Step 99700 - Training Loss: 0.9315470457077026, Val Loss: 1.0648959875106812, Accuracy: 0.5686976909637451, Val Accuracy: 0.5296331644058228, Time: 29.54 sec\n",
      "Step 99800 - Training Loss: 0.9707642197608948, Val Loss: 1.0648314952850342, Accuracy: 0.5686931014060974, Val Accuracy: 0.5296037793159485, Time: 29.47 sec\n",
      "Step 99900 - Training Loss: 1.0005967617034912, Val Loss: 1.0647672414779663, Accuracy: 0.5686849355697632, Val Accuracy: 0.5295743942260742, Time: 29.49 sec\n",
      "Step 100000 - Training Loss: 0.913303792476654, Val Loss: 1.064703106880188, Accuracy: 0.5686782598495483, Val Accuracy: 0.5295451283454895, Time: 29.02 sec\n",
      "Step 100100 - Training Loss: 0.9288155436515808, Val Loss: 1.0646389722824097, Accuracy: 0.5686720609664917, Val Accuracy: 0.5295158624649048, Time: 29.45 sec\n",
      "Step 100200 - Training Loss: 1.0020557641983032, Val Loss: 1.0645750761032104, Accuracy: 0.568666398525238, Val Accuracy: 0.5294866561889648, Time: 30.18 sec\n",
      "Step 100300 - Training Loss: 0.9770616888999939, Val Loss: 1.0645112991333008, Accuracy: 0.5686614513397217, Val Accuracy: 0.5294575691223145, Time: 32.25 sec\n",
      "Step 100400 - Training Loss: 0.9457775950431824, Val Loss: 1.0644476413726807, Accuracy: 0.5686573386192322, Val Accuracy: 0.5294284820556641, Time: 34.43 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100500 - Training Loss: 0.9471608996391296, Val Loss: 1.06438410282135, Accuracy: 0.5686531066894531, Val Accuracy: 0.5293994545936584, Time: 33.51 sec\n",
      "Step 100600 - Training Loss: 0.9343366026878357, Val Loss: 1.064320683479309, Accuracy: 0.5686473250389099, Val Accuracy: 0.5293704867362976, Time: 33.17 sec\n",
      "Step 100700 - Training Loss: 0.9439376592636108, Val Loss: 1.0642573833465576, Accuracy: 0.5686417818069458, Val Accuracy: 0.5293416380882263, Time: 34.39 sec\n",
      "Step 100800 - Training Loss: 0.9182612895965576, Val Loss: 1.0641942024230957, Accuracy: 0.5686379671096802, Val Accuracy: 0.529312789440155, Time: 33.92 sec\n",
      "Step 100900 - Training Loss: 0.9563231468200684, Val Loss: 1.064131259918213, Accuracy: 0.5686354637145996, Val Accuracy: 0.5292840003967285, Time: 33.21 sec\n",
      "Step 101000 - Training Loss: 0.9364976286888123, Val Loss: 1.06406831741333, Accuracy: 0.5686317682266235, Val Accuracy: 0.5292552709579468, Time: 33.87 sec\n",
      "Step 101100 - Training Loss: 0.9437606334686279, Val Loss: 1.0640054941177368, Accuracy: 0.5686265826225281, Val Accuracy: 0.5292266011238098, Time: 33.87 sec\n",
      "Step 101200 - Training Loss: 0.9491502046585083, Val Loss: 1.063942790031433, Accuracy: 0.5686214566230774, Val Accuracy: 0.5291979908943176, Time: 33.73 sec\n",
      "Step 101300 - Training Loss: 0.9775954484939575, Val Loss: 1.0638803243637085, Accuracy: 0.5686159729957581, Val Accuracy: 0.5291693806648254, Time: 27.53 sec\n",
      "Step 101400 - Training Loss: 0.9196349382400513, Val Loss: 1.0638178586959839, Accuracy: 0.5686120986938477, Val Accuracy: 0.5291408896446228, Time: 27.71 sec\n",
      "Step 101500 - Training Loss: 0.9524100422859192, Val Loss: 1.0637555122375488, Accuracy: 0.568609893321991, Val Accuracy: 0.5291124582290649, Time: 33.49 sec\n",
      "Step 101600 - Training Loss: 0.9460129141807556, Val Loss: 1.0636934041976929, Accuracy: 0.5686072111129761, Val Accuracy: 0.5290840864181519, Time: 33.65 sec\n",
      "Step 101700 - Training Loss: 0.975952684879303, Val Loss: 1.063631296157837, Accuracy: 0.5686028599739075, Val Accuracy: 0.5290557146072388, Time: 34.61 sec\n",
      "Step 101800 - Training Loss: 0.9286447763442993, Val Loss: 1.06356942653656, Accuracy: 0.5685981512069702, Val Accuracy: 0.5290274620056152, Time: 34.43 sec\n",
      "Step 101900 - Training Loss: 0.9339612722396851, Val Loss: 1.0635075569152832, Accuracy: 0.5685943961143494, Val Accuracy: 0.5289992094039917, Time: 34.00 sec\n",
      "Step 102000 - Training Loss: 0.9224735498428345, Val Loss: 1.0634459257125854, Accuracy: 0.5685897469520569, Val Accuracy: 0.5289710164070129, Time: 33.25 sec\n",
      "Step 102100 - Training Loss: 0.9739046692848206, Val Loss: 1.0633842945098877, Accuracy: 0.5685852766036987, Val Accuracy: 0.5289429426193237, Time: 34.08 sec\n",
      "Step 102200 - Training Loss: 0.9268511533737183, Val Loss: 1.0633227825164795, Accuracy: 0.5685808062553406, Val Accuracy: 0.5289148688316345, Time: 34.03 sec\n",
      "Step 102300 - Training Loss: 0.9384727478027344, Val Loss: 1.0632615089416504, Accuracy: 0.5685794353485107, Val Accuracy: 0.5288868546485901, Time: 33.16 sec\n",
      "Step 102400 - Training Loss: 0.9788892865180969, Val Loss: 1.0632002353668213, Accuracy: 0.5685757398605347, Val Accuracy: 0.5288589000701904, Time: 34.21 sec\n",
      "Step 102500 - Training Loss: 0.9309557676315308, Val Loss: 1.0631392002105713, Accuracy: 0.5685696005821228, Val Accuracy: 0.5288310050964355, Time: 34.01 sec\n",
      "Step 102600 - Training Loss: 0.928077220916748, Val Loss: 1.0630781650543213, Accuracy: 0.568561851978302, Val Accuracy: 0.5288031697273254, Time: 34.74 sec\n",
      "Step 102700 - Training Loss: 0.9256440997123718, Val Loss: 1.0630173683166504, Accuracy: 0.5685554146766663, Val Accuracy: 0.5287753343582153, Time: 29.57 sec\n",
      "Step 102800 - Training Loss: 0.9209920167922974, Val Loss: 1.0629565715789795, Accuracy: 0.568548858165741, Val Accuracy: 0.5287476181983948, Time: 26.17 sec\n",
      "Step 102900 - Training Loss: 0.9301895499229431, Val Loss: 1.0628958940505981, Accuracy: 0.5685445666313171, Val Accuracy: 0.5287199020385742, Time: 27.25 sec\n",
      "Step 103000 - Training Loss: 0.9563579559326172, Val Loss: 1.062835454940796, Accuracy: 0.5685434937477112, Val Accuracy: 0.5286923050880432, Time: 26.98 sec\n",
      "Step 103100 - Training Loss: 0.91685950756073, Val Loss: 1.0627750158309937, Accuracy: 0.5685404539108276, Val Accuracy: 0.5286647081375122, Time: 27.53 sec\n",
      "Step 103200 - Training Loss: 0.9410730600357056, Val Loss: 1.062714695930481, Accuracy: 0.5685385465621948, Val Accuracy: 0.528637170791626, Time: 26.44 sec\n",
      "Step 103300 - Training Loss: 0.9437683820724487, Val Loss: 1.0626546144485474, Accuracy: 0.5685357451438904, Val Accuracy: 0.5286096930503845, Time: 27.06 sec\n",
      "Step 103400 - Training Loss: 0.9353793859481812, Val Loss: 1.0625945329666138, Accuracy: 0.5685327053070068, Val Accuracy: 0.5285822749137878, Time: 27.27 sec\n",
      "Step 103500 - Training Loss: 0.9397353529930115, Val Loss: 1.0625345706939697, Accuracy: 0.5685310959815979, Val Accuracy: 0.5285549163818359, Time: 26.82 sec\n",
      "Step 103600 - Training Loss: 0.9745750427246094, Val Loss: 1.0624747276306152, Accuracy: 0.568527340888977, Val Accuracy: 0.5285276174545288, Time: 26.95 sec\n",
      "Step 103700 - Training Loss: 0.9466423392295837, Val Loss: 1.0624150037765503, Accuracy: 0.5685210824012756, Val Accuracy: 0.5285003185272217, Time: 26.55 sec\n",
      "Step 103800 - Training Loss: 0.9653303027153015, Val Loss: 1.062355399131775, Accuracy: 0.5685145258903503, Val Accuracy: 0.5284731388092041, Time: 26.38 sec\n",
      "Step 103900 - Training Loss: 0.930789053440094, Val Loss: 1.062295913696289, Accuracy: 0.5685103535652161, Val Accuracy: 0.5284459590911865, Time: 26.98 sec\n",
      "Step 104000 - Training Loss: 0.9481245279312134, Val Loss: 1.0622365474700928, Accuracy: 0.5685062408447266, Val Accuracy: 0.5284188389778137, Time: 26.52 sec\n",
      "Step 104100 - Training Loss: 0.9503456354141235, Val Loss: 1.062177300453186, Accuracy: 0.5685019493103027, Val Accuracy: 0.5283917784690857, Time: 25.99 sec\n",
      "Step 104200 - Training Loss: 0.9703611731529236, Val Loss: 1.0621181726455688, Accuracy: 0.5684956908226013, Val Accuracy: 0.5283647775650024, Time: 25.52 sec\n",
      "Step 104300 - Training Loss: 0.9321322441101074, Val Loss: 1.0620591640472412, Accuracy: 0.5684912800788879, Val Accuracy: 0.528337836265564, Time: 26.15 sec\n",
      "Step 104400 - Training Loss: 0.9131035804748535, Val Loss: 1.0620002746582031, Accuracy: 0.5684865117073059, Val Accuracy: 0.5283109545707703, Time: 25.77 sec\n",
      "Step 104500 - Training Loss: 0.9907985329627991, Val Loss: 1.0619415044784546, Accuracy: 0.5684821009635925, Val Accuracy: 0.5282840728759766, Time: 27.10 sec\n",
      "Step 104600 - Training Loss: 0.9508520364761353, Val Loss: 1.061882734298706, Accuracy: 0.5684767365455627, Val Accuracy: 0.5282573103904724, Time: 26.46 sec\n",
      "Step 104700 - Training Loss: 0.94833904504776, Val Loss: 1.0618242025375366, Accuracy: 0.5684713125228882, Val Accuracy: 0.528230607509613, Time: 25.65 sec\n",
      "Step 104800 - Training Loss: 0.9332361817359924, Val Loss: 1.0617656707763672, Accuracy: 0.568465530872345, Val Accuracy: 0.5282039046287537, Time: 25.86 sec\n",
      "Step 104900 - Training Loss: 0.9516981840133667, Val Loss: 1.0617073774337769, Accuracy: 0.5684589743614197, Val Accuracy: 0.5281772613525391, Time: 26.44 sec\n",
      "Step 105000 - Training Loss: 0.9949007630348206, Val Loss: 1.0616490840911865, Accuracy: 0.5684561133384705, Val Accuracy: 0.5281506180763245, Time: 27.36 sec\n",
      "Step 105100 - Training Loss: 0.935082197189331, Val Loss: 1.0615909099578857, Accuracy: 0.5684524774551392, Val Accuracy: 0.5281240940093994, Time: 26.01 sec\n",
      "Step 105200 - Training Loss: 0.9633533358573914, Val Loss: 1.061532974243164, Accuracy: 0.5684476494789124, Val Accuracy: 0.5280975699424744, Time: 26.18 sec\n",
      "Step 105300 - Training Loss: 0.9464127421379089, Val Loss: 1.0614750385284424, Accuracy: 0.5684452056884766, Val Accuracy: 0.5280711650848389, Time: 26.55 sec\n",
      "Step 105400 - Training Loss: 0.980986475944519, Val Loss: 1.0614172220230103, Accuracy: 0.5684404373168945, Val Accuracy: 0.5280447602272034, Time: 26.13 sec\n",
      "Step 105500 - Training Loss: 0.9685059189796448, Val Loss: 1.0613595247268677, Accuracy: 0.5684377551078796, Val Accuracy: 0.5280184149742126, Time: 26.24 sec\n",
      "Step 105600 - Training Loss: 0.9596661329269409, Val Loss: 1.061301827430725, Accuracy: 0.5684331655502319, Val Accuracy: 0.5279920697212219, Time: 25.65 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 105700 - Training Loss: 0.9798140525817871, Val Loss: 1.0612443685531616, Accuracy: 0.5684280395507812, Val Accuracy: 0.5279658436775208, Time: 27.16 sec\n",
      "Step 105800 - Training Loss: 0.9612842798233032, Val Loss: 1.0611870288848877, Accuracy: 0.5684220194816589, Val Accuracy: 0.5279396176338196, Time: 26.81 sec\n",
      "Step 105900 - Training Loss: 0.9417292475700378, Val Loss: 1.0611296892166138, Accuracy: 0.5684191584587097, Val Accuracy: 0.527913510799408, Time: 28.29 sec\n",
      "Step 106000 - Training Loss: 0.9604933261871338, Val Loss: 1.061072587966919, Accuracy: 0.5684152245521545, Val Accuracy: 0.5278874039649963, Time: 26.91 sec\n",
      "Step 106100 - Training Loss: 0.9601418972015381, Val Loss: 1.0610154867172241, Accuracy: 0.5684112906455994, Val Accuracy: 0.5278613567352295, Time: 27.37 sec\n",
      "Step 106200 - Training Loss: 0.9098355174064636, Val Loss: 1.0609585046768188, Accuracy: 0.5684082508087158, Val Accuracy: 0.5278353095054626, Time: 28.09 sec\n",
      "Step 106300 - Training Loss: 0.9472236037254333, Val Loss: 1.0609017610549927, Accuracy: 0.5684040188789368, Val Accuracy: 0.5278093814849854, Time: 28.36 sec\n",
      "Step 106400 - Training Loss: 0.9343591928482056, Val Loss: 1.0608450174331665, Accuracy: 0.5683997273445129, Val Accuracy: 0.5277834534645081, Time: 29.16 sec\n",
      "Step 106500 - Training Loss: 0.9476655721664429, Val Loss: 1.0607883930206299, Accuracy: 0.5683946013450623, Val Accuracy: 0.5277575850486755, Time: 28.32 sec\n",
      "Step 106600 - Training Loss: 0.9105019569396973, Val Loss: 1.0607317686080933, Accuracy: 0.5683895945549011, Val Accuracy: 0.5277317762374878, Time: 25.59 sec\n",
      "Step 106700 - Training Loss: 0.9557194113731384, Val Loss: 1.0606753826141357, Accuracy: 0.5683848857879639, Val Accuracy: 0.5277060270309448, Time: 26.00 sec\n",
      "Step 106800 - Training Loss: 0.9353257417678833, Val Loss: 1.0606191158294678, Accuracy: 0.568381130695343, Val Accuracy: 0.5276802778244019, Time: 26.63 sec\n",
      "Step 106900 - Training Loss: 0.9899712800979614, Val Loss: 1.0605628490447998, Accuracy: 0.5683757662773132, Val Accuracy: 0.5276546478271484, Time: 25.91 sec\n",
      "Step 107000 - Training Loss: 0.9273238182067871, Val Loss: 1.0605067014694214, Accuracy: 0.5683728456497192, Val Accuracy: 0.527629017829895, Time: 27.20 sec\n",
      "Step 107100 - Training Loss: 0.9133227467536926, Val Loss: 1.0604506731033325, Accuracy: 0.5683688521385193, Val Accuracy: 0.5276034474372864, Time: 29.21 sec\n",
      "Step 107200 - Training Loss: 0.9580962657928467, Val Loss: 1.0603948831558228, Accuracy: 0.5683644413948059, Val Accuracy: 0.5275778770446777, Time: 28.32 sec\n",
      "Step 107300 - Training Loss: 0.9359120726585388, Val Loss: 1.0603389739990234, Accuracy: 0.5683572292327881, Val Accuracy: 0.5275524258613586, Time: 27.38 sec\n",
      "Step 107400 - Training Loss: 0.9534412026405334, Val Loss: 1.0602833032608032, Accuracy: 0.5683521628379822, Val Accuracy: 0.5275269746780396, Time: 25.78 sec\n",
      "Step 107500 - Training Loss: 0.9448952674865723, Val Loss: 1.0602277517318726, Accuracy: 0.5683473944664001, Val Accuracy: 0.5275015830993652, Time: 25.85 sec\n",
      "Step 107600 - Training Loss: 0.9739910364151001, Val Loss: 1.060172200202942, Accuracy: 0.5683429837226868, Val Accuracy: 0.5274762511253357, Time: 26.21 sec\n",
      "Step 107700 - Training Loss: 0.9966095685958862, Val Loss: 1.0601168870925903, Accuracy: 0.5683373212814331, Val Accuracy: 0.5274510383605957, Time: 26.05 sec\n",
      "Step 107800 - Training Loss: 0.9291412830352783, Val Loss: 1.0600615739822388, Accuracy: 0.5683319568634033, Val Accuracy: 0.5274295806884766, Time: 25.71 sec\n",
      "Step 107900 - Training Loss: 0.9830663800239563, Val Loss: 1.0600063800811768, Accuracy: 0.5683275461196899, Val Accuracy: 0.5274043679237366, Time: 25.47 sec\n",
      "Step 108000 - Training Loss: 0.9354654550552368, Val Loss: 1.0599513053894043, Accuracy: 0.5683239102363586, Val Accuracy: 0.5273792147636414, Time: 26.20 sec\n",
      "Step 108100 - Training Loss: 0.9704464673995972, Val Loss: 1.0598963499069214, Accuracy: 0.5683208107948303, Val Accuracy: 0.5273540616035461, Time: 25.92 sec\n",
      "Step 108200 - Training Loss: 0.9279756546020508, Val Loss: 1.0598413944244385, Accuracy: 0.5683169960975647, Val Accuracy: 0.5273290276527405, Time: 28.24 sec\n",
      "Step 108300 - Training Loss: 0.9486154317855835, Val Loss: 1.0597866773605347, Accuracy: 0.5683146119117737, Val Accuracy: 0.5273039937019348, Time: 29.42 sec\n",
      "Step 108400 - Training Loss: 0.9043026566505432, Val Loss: 1.0597319602966309, Accuracy: 0.5683104991912842, Val Accuracy: 0.5272790193557739, Time: 27.83 sec\n",
      "Step 108500 - Training Loss: 0.970128059387207, Val Loss: 1.0596773624420166, Accuracy: 0.5683034062385559, Val Accuracy: 0.5272541046142578, Time: 27.85 sec\n",
      "Step 108600 - Training Loss: 0.9293921589851379, Val Loss: 1.059622883796692, Accuracy: 0.5682994723320007, Val Accuracy: 0.5272292494773865, Time: 28.52 sec\n",
      "Step 108700 - Training Loss: 1.0048065185546875, Val Loss: 1.0595685243606567, Accuracy: 0.5682963132858276, Val Accuracy: 0.5272043943405151, Time: 26.30 sec\n",
      "Step 108800 - Training Loss: 0.9630176424980164, Val Loss: 1.0595141649246216, Accuracy: 0.5682913064956665, Val Accuracy: 0.5271795988082886, Time: 26.35 sec\n",
      "Step 108900 - Training Loss: 0.9372371435165405, Val Loss: 1.0594600439071655, Accuracy: 0.5682858824729919, Val Accuracy: 0.5271548628807068, Time: 26.11 sec\n",
      "Step 109000 - Training Loss: 0.927453875541687, Val Loss: 1.0594059228897095, Accuracy: 0.5682826638221741, Val Accuracy: 0.527130126953125, Time: 25.75 sec\n",
      "Step 109100 - Training Loss: 0.960599422454834, Val Loss: 1.059351921081543, Accuracy: 0.568279504776001, Val Accuracy: 0.5271055102348328, Time: 26.04 sec\n",
      "Step 109200 - Training Loss: 0.9302707314491272, Val Loss: 1.059298038482666, Accuracy: 0.56827312707901, Val Accuracy: 0.5270808935165405, Time: 25.88 sec\n",
      "Step 109300 - Training Loss: 0.9658814668655396, Val Loss: 1.0592442750930786, Accuracy: 0.5682687163352966, Val Accuracy: 0.5270563364028931, Time: 25.73 sec\n",
      "Step 109400 - Training Loss: 0.9534173607826233, Val Loss: 1.0591906309127808, Accuracy: 0.5682649612426758, Val Accuracy: 0.5270317792892456, Time: 25.60 sec\n",
      "Step 109500 - Training Loss: 0.9096353054046631, Val Loss: 1.059136986732483, Accuracy: 0.5682616829872131, Val Accuracy: 0.5270072817802429, Time: 25.74 sec\n",
      "Step 109600 - Training Loss: 0.9157585501670837, Val Loss: 1.0590834617614746, Accuracy: 0.5682565569877625, Val Accuracy: 0.5269829034805298, Time: 25.93 sec\n",
      "Step 109700 - Training Loss: 0.9593813419342041, Val Loss: 1.0590300559997559, Accuracy: 0.5682542324066162, Val Accuracy: 0.5269584655761719, Time: 26.62 sec\n",
      "Step 109800 - Training Loss: 0.9180240631103516, Val Loss: 1.0589767694473267, Accuracy: 0.5682519674301147, Val Accuracy: 0.5269341468811035, Time: 28.18 sec\n",
      "Step 109900 - Training Loss: 0.9473762512207031, Val Loss: 1.058923602104187, Accuracy: 0.5682490468025208, Val Accuracy: 0.5269104242324829, Time: 26.47 sec\n",
      "Step 110000 - Training Loss: 0.9538108110427856, Val Loss: 1.0588704347610474, Accuracy: 0.5682443380355835, Val Accuracy: 0.5268861651420593, Time: 26.61 sec\n",
      "Step 110100 - Training Loss: 0.9576801657676697, Val Loss: 1.0588173866271973, Accuracy: 0.5682387948036194, Val Accuracy: 0.5268638730049133, Time: 26.45 sec\n",
      "Step 110200 - Training Loss: 0.9342499375343323, Val Loss: 1.0587644577026367, Accuracy: 0.5682359337806702, Val Accuracy: 0.5268396735191345, Time: 26.63 sec\n",
      "Step 110300 - Training Loss: 0.9717574119567871, Val Loss: 1.0587116479873657, Accuracy: 0.5682307481765747, Val Accuracy: 0.5268155932426453, Time: 27.17 sec\n",
      "Step 110400 - Training Loss: 0.9339876770973206, Val Loss: 1.0586589574813843, Accuracy: 0.5682278871536255, Val Accuracy: 0.5267914533615112, Time: 27.92 sec\n",
      "Step 110500 - Training Loss: 0.9474018812179565, Val Loss: 1.0586062669754028, Accuracy: 0.568223237991333, Val Accuracy: 0.5267674326896667, Time: 27.15 sec\n",
      "Step 110600 - Training Loss: 0.9374309778213501, Val Loss: 1.058553695678711, Accuracy: 0.5682193040847778, Val Accuracy: 0.5267434120178223, Time: 26.52 sec\n",
      "Step 110700 - Training Loss: 0.9840695858001709, Val Loss: 1.0585012435913086, Accuracy: 0.5682157278060913, Val Accuracy: 0.5267195105552673, Time: 26.63 sec\n",
      "Step 110800 - Training Loss: 0.9531605243682861, Val Loss: 1.0584489107131958, Accuracy: 0.5682106018066406, Val Accuracy: 0.5266955494880676, Time: 27.57 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 110900 - Training Loss: 0.9698681831359863, Val Loss: 1.0583966970443726, Accuracy: 0.568209171295166, Val Accuracy: 0.5266717076301575, Time: 26.45 sec\n",
      "Step 111000 - Training Loss: 0.9851560592651367, Val Loss: 1.0583444833755493, Accuracy: 0.5682095885276794, Val Accuracy: 0.5266478657722473, Time: 25.19 sec\n",
      "Step 111100 - Training Loss: 0.9181815981864929, Val Loss: 1.0582923889160156, Accuracy: 0.5682066679000854, Val Accuracy: 0.5266240835189819, Time: 25.61 sec\n",
      "Step 111200 - Training Loss: 0.9684073328971863, Val Loss: 1.0582404136657715, Accuracy: 0.5682010650634766, Val Accuracy: 0.5266003608703613, Time: 25.57 sec\n",
      "Step 111300 - Training Loss: 0.9719452857971191, Val Loss: 1.058188557624817, Accuracy: 0.5681975483894348, Val Accuracy: 0.5265766382217407, Time: 25.67 sec\n",
      "Step 111400 - Training Loss: 0.9298199415206909, Val Loss: 1.0581367015838623, Accuracy: 0.5681946873664856, Val Accuracy: 0.5265529751777649, Time: 25.39 sec\n",
      "Step 111500 - Training Loss: 0.9474624395370483, Val Loss: 1.0580850839614868, Accuracy: 0.5681926608085632, Val Accuracy: 0.5265293717384338, Time: 25.30 sec\n",
      "Step 111600 - Training Loss: 0.9293215870857239, Val Loss: 1.0580334663391113, Accuracy: 0.5681878924369812, Val Accuracy: 0.5265057682991028, Time: 25.60 sec\n",
      "Step 111700 - Training Loss: 0.9211958050727844, Val Loss: 1.0579818487167358, Accuracy: 0.5681841969490051, Val Accuracy: 0.5264822840690613, Time: 25.81 sec\n",
      "Step 111800 - Training Loss: 0.9435163140296936, Val Loss: 1.0579304695129395, Accuracy: 0.5681787729263306, Val Accuracy: 0.526458740234375, Time: 25.97 sec\n",
      "Step 111900 - Training Loss: 0.9415950179100037, Val Loss: 1.057879090309143, Accuracy: 0.5682299137115479, Val Accuracy: 0.5264353156089783, Time: 25.38 sec\n",
      "Step 112000 - Training Loss: 0.9664402604103088, Val Loss: 1.0578278303146362, Accuracy: 0.5683267712593079, Val Accuracy: 0.5264119505882263, Time: 25.68 sec\n",
      "Step 112100 - Training Loss: 0.9636034965515137, Val Loss: 1.057776689529419, Accuracy: 0.5684249401092529, Val Accuracy: 0.5263887643814087, Time: 25.82 sec\n",
      "Step 112200 - Training Loss: 0.9329670071601868, Val Loss: 1.0577256679534912, Accuracy: 0.5685208439826965, Val Accuracy: 0.5263654589653015, Time: 25.82 sec\n",
      "Step 112300 - Training Loss: 0.9851081371307373, Val Loss: 1.0576746463775635, Accuracy: 0.5686161518096924, Val Accuracy: 0.5263421535491943, Time: 25.32 sec\n",
      "Step 112400 - Training Loss: 0.9738853573799133, Val Loss: 1.0576237440109253, Accuracy: 0.5687114000320435, Val Accuracy: 0.5263189077377319, Time: 25.69 sec\n",
      "Step 112500 - Training Loss: 0.9608229994773865, Val Loss: 1.0575729608535767, Accuracy: 0.5688069462776184, Val Accuracy: 0.5262957215309143, Time: 25.43 sec\n",
      "Step 112600 - Training Loss: 0.9620296359062195, Val Loss: 1.0575222969055176, Accuracy: 0.5689033269882202, Val Accuracy: 0.5262725949287415, Time: 25.79 sec\n",
      "Step 112700 - Training Loss: 1.0225082635879517, Val Loss: 1.0574716329574585, Accuracy: 0.5690026879310608, Val Accuracy: 0.5262494683265686, Time: 25.94 sec\n",
      "Step 112800 - Training Loss: 0.9745240807533264, Val Loss: 1.057421088218689, Accuracy: 0.5690980553627014, Val Accuracy: 0.5262263417243958, Time: 25.40 sec\n",
      "Step 112900 - Training Loss: 0.9687110781669617, Val Loss: 1.057370662689209, Accuracy: 0.5691908001899719, Val Accuracy: 0.5262033343315125, Time: 26.13 sec\n",
      "Step 113000 - Training Loss: 0.9271553754806519, Val Loss: 1.0573203563690186, Accuracy: 0.569286048412323, Val Accuracy: 0.5261803269386292, Time: 25.76 sec\n",
      "Step 113100 - Training Loss: 0.9304937124252319, Val Loss: 1.0572700500488281, Accuracy: 0.5693826675415039, Val Accuracy: 0.5261573791503906, Time: 25.48 sec\n",
      "Step 113200 - Training Loss: 0.9647080302238464, Val Loss: 1.0572198629379272, Accuracy: 0.5694843530654907, Val Accuracy: 0.5261344313621521, Time: 25.63 sec\n",
      "Step 113300 - Training Loss: 0.9498987793922424, Val Loss: 1.057169795036316, Accuracy: 0.5695827603340149, Val Accuracy: 0.5261116027832031, Time: 25.45 sec\n",
      "Step 113400 - Training Loss: 0.9413183927536011, Val Loss: 1.0571197271347046, Accuracy: 0.5696806907653809, Val Accuracy: 0.5260887145996094, Time: 25.71 sec\n",
      "Step 113500 - Training Loss: 0.9497930407524109, Val Loss: 1.0570698976516724, Accuracy: 0.5697757601737976, Val Accuracy: 0.5260659456253052, Time: 25.56 sec\n",
      "Step 113600 - Training Loss: 0.936570405960083, Val Loss: 1.0570200681686401, Accuracy: 0.5698718428611755, Val Accuracy: 0.526043176651001, Time: 26.09 sec\n",
      "Step 113700 - Training Loss: 0.9244044423103333, Val Loss: 1.056970238685608, Accuracy: 0.569966733455658, Val Accuracy: 0.5260204672813416, Time: 25.65 sec\n",
      "Step 113800 - Training Loss: 0.9476640820503235, Val Loss: 1.0569206476211548, Accuracy: 0.570061206817627, Val Accuracy: 0.5259977579116821, Time: 25.45 sec\n",
      "Step 113900 - Training Loss: 0.9297895431518555, Val Loss: 1.0568710565567017, Accuracy: 0.5701566934585571, Val Accuracy: 0.5259751677513123, Time: 25.77 sec\n",
      "Step 114000 - Training Loss: 1.0029276609420776, Val Loss: 1.056821584701538, Accuracy: 0.5702524781227112, Val Accuracy: 0.5259525179862976, Time: 25.56 sec\n",
      "Step 114100 - Training Loss: 0.9702308773994446, Val Loss: 1.056772232055664, Accuracy: 0.570346474647522, Val Accuracy: 0.5259299874305725, Time: 25.43 sec\n",
      "Step 114200 - Training Loss: 0.9250548481941223, Val Loss: 1.05672287940979, Accuracy: 0.5704437494277954, Val Accuracy: 0.5259074568748474, Time: 25.82 sec\n",
      "Step 114300 - Training Loss: 0.9631537795066833, Val Loss: 1.0566736459732056, Accuracy: 0.5705370903015137, Val Accuracy: 0.5258849859237671, Time: 25.65 sec\n",
      "Step 114400 - Training Loss: 0.9599171876907349, Val Loss: 1.0566245317459106, Accuracy: 0.5706319212913513, Val Accuracy: 0.5258625149726868, Time: 25.45 sec\n",
      "Step 114500 - Training Loss: 0.9304255843162537, Val Loss: 1.0565754175186157, Accuracy: 0.5707249045372009, Val Accuracy: 0.5258401036262512, Time: 25.70 sec\n",
      "Step 114600 - Training Loss: 0.9649142026901245, Val Loss: 1.0565264225006104, Accuracy: 0.570817768573761, Val Accuracy: 0.5258177518844604, Time: 25.41 sec\n",
      "Step 114700 - Training Loss: 0.9415271878242493, Val Loss: 1.0564775466918945, Accuracy: 0.5709121227264404, Val Accuracy: 0.5257954597473145, Time: 26.07 sec\n",
      "Step 114800 - Training Loss: 0.940696120262146, Val Loss: 1.0564287900924683, Accuracy: 0.5710042119026184, Val Accuracy: 0.5257731676101685, Time: 25.71 sec\n",
      "Step 114900 - Training Loss: 0.9486175179481506, Val Loss: 1.056380033493042, Accuracy: 0.5710970163345337, Val Accuracy: 0.5257522463798523, Time: 25.67 sec\n",
      "Step 115000 - Training Loss: 0.952118992805481, Val Loss: 1.0563313961029053, Accuracy: 0.571190595626831, Val Accuracy: 0.5257300138473511, Time: 25.48 sec\n",
      "Step 115100 - Training Loss: 0.9552983641624451, Val Loss: 1.056282877922058, Accuracy: 0.5712822079658508, Val Accuracy: 0.5257079005241394, Time: 25.56 sec\n",
      "Step 115200 - Training Loss: 0.969536304473877, Val Loss: 1.0562344789505005, Accuracy: 0.5713755488395691, Val Accuracy: 0.5256857872009277, Time: 25.75 sec\n",
      "Step 115300 - Training Loss: 0.9856971502304077, Val Loss: 1.0561860799789429, Accuracy: 0.5714685916900635, Val Accuracy: 0.5256636738777161, Time: 25.49 sec\n",
      "Step 115400 - Training Loss: 0.9718813896179199, Val Loss: 1.0561378002166748, Accuracy: 0.5715609788894653, Val Accuracy: 0.5256416201591492, Time: 25.50 sec\n",
      "Step 115500 - Training Loss: 0.9709198474884033, Val Loss: 1.0560895204544067, Accuracy: 0.5716536045074463, Val Accuracy: 0.5256195664405823, Time: 25.48 sec\n",
      "Step 115600 - Training Loss: 0.9735079407691956, Val Loss: 1.0560413599014282, Accuracy: 0.5717436671257019, Val Accuracy: 0.5255975723266602, Time: 25.32 sec\n",
      "Step 115700 - Training Loss: 0.9302879571914673, Val Loss: 1.0559933185577393, Accuracy: 0.5718345642089844, Val Accuracy: 0.5255756378173828, Time: 25.60 sec\n",
      "Step 115800 - Training Loss: 0.9335689544677734, Val Loss: 1.0559453964233398, Accuracy: 0.571925699710846, Val Accuracy: 0.5255537629127502, Time: 25.72 sec\n",
      "Step 115900 - Training Loss: 0.9467148184776306, Val Loss: 1.0558974742889404, Accuracy: 0.5720183253288269, Val Accuracy: 0.5255318880081177, Time: 26.62 sec\n",
      "Step 116000 - Training Loss: 1.0173202753067017, Val Loss: 1.0558496713638306, Accuracy: 0.5721107125282288, Val Accuracy: 0.5255100131034851, Time: 25.54 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 116100 - Training Loss: 0.9862312078475952, Val Loss: 1.0558019876480103, Accuracy: 0.5722011923789978, Val Accuracy: 0.5254882574081421, Time: 25.85 sec\n",
      "Step 116200 - Training Loss: 0.9688529372215271, Val Loss: 1.05575430393219, Accuracy: 0.5722941160202026, Val Accuracy: 0.5254665017127991, Time: 25.18 sec\n",
      "Step 116300 - Training Loss: 1.0132619142532349, Val Loss: 1.0557067394256592, Accuracy: 0.5723860263824463, Val Accuracy: 0.525444746017456, Time: 25.89 sec\n",
      "Step 116400 - Training Loss: 0.9087849259376526, Val Loss: 1.055659294128418, Accuracy: 0.5724772810935974, Val Accuracy: 0.5254230499267578, Time: 25.55 sec\n",
      "Step 116500 - Training Loss: 0.9473426342010498, Val Loss: 1.0556119680404663, Accuracy: 0.5725684762001038, Val Accuracy: 0.5254014134407043, Time: 25.48 sec\n",
      "Step 116600 - Training Loss: 0.9466201066970825, Val Loss: 1.0555646419525146, Accuracy: 0.5726624727249146, Val Accuracy: 0.5253798365592957, Time: 25.44 sec\n",
      "Step 116700 - Training Loss: 0.9857062697410583, Val Loss: 1.055517315864563, Accuracy: 0.5727547407150269, Val Accuracy: 0.525358259677887, Time: 26.08 sec\n",
      "Step 116800 - Training Loss: 0.9588898420333862, Val Loss: 1.0554702281951904, Accuracy: 0.5728472471237183, Val Accuracy: 0.5253366827964783, Time: 25.33 sec\n",
      "Step 116900 - Training Loss: 0.9832834601402283, Val Loss: 1.0554231405258179, Accuracy: 0.5729365348815918, Val Accuracy: 0.5253151655197144, Time: 25.90 sec\n",
      "Step 117000 - Training Loss: 0.9636419415473938, Val Loss: 1.0553761720657349, Accuracy: 0.5730283260345459, Val Accuracy: 0.5252937078475952, Time: 25.70 sec\n",
      "Step 117100 - Training Loss: 0.9576210379600525, Val Loss: 1.0553292036056519, Accuracy: 0.5731170773506165, Val Accuracy: 0.525272786617279, Time: 25.48 sec\n",
      "Step 117200 - Training Loss: 0.959581732749939, Val Loss: 1.0552823543548584, Accuracy: 0.5732061862945557, Val Accuracy: 0.5252513885498047, Time: 25.86 sec\n",
      "Step 117300 - Training Loss: 0.9520843029022217, Val Loss: 1.0552356243133545, Accuracy: 0.5732932090759277, Val Accuracy: 0.5252299904823303, Time: 25.55 sec\n",
      "Step 117400 - Training Loss: 0.9459240436553955, Val Loss: 1.0551888942718506, Accuracy: 0.5733843445777893, Val Accuracy: 0.5252087116241455, Time: 25.51 sec\n",
      "Step 117500 - Training Loss: 0.924225926399231, Val Loss: 1.0551424026489258, Accuracy: 0.5734739303588867, Val Accuracy: 0.5251874327659607, Time: 25.23 sec\n",
      "Step 117600 - Training Loss: 0.9816096425056458, Val Loss: 1.0550957918167114, Accuracy: 0.5735630393028259, Val Accuracy: 0.5251661539077759, Time: 25.71 sec\n",
      "Step 117700 - Training Loss: 0.9379656910896301, Val Loss: 1.0550494194030762, Accuracy: 0.5736510753631592, Val Accuracy: 0.5251450538635254, Time: 25.86 sec\n",
      "Step 117800 - Training Loss: 0.9532003402709961, Val Loss: 1.055003046989441, Accuracy: 0.5737407207489014, Val Accuracy: 0.5251238346099854, Time: 25.39 sec\n",
      "Step 117900 - Training Loss: 0.9279505610466003, Val Loss: 1.0549567937850952, Accuracy: 0.5738299489021301, Val Accuracy: 0.5251027345657349, Time: 25.97 sec\n",
      "Step 118000 - Training Loss: 0.9134547710418701, Val Loss: 1.0549105405807495, Accuracy: 0.5739192366600037, Val Accuracy: 0.5250816345214844, Time: 25.40 sec\n",
      "Step 118100 - Training Loss: 0.9494990110397339, Val Loss: 1.0548644065856934, Accuracy: 0.574006974697113, Val Accuracy: 0.5250605344772339, Time: 26.13 sec\n",
      "Step 118200 - Training Loss: 0.9451538920402527, Val Loss: 1.0548183917999268, Accuracy: 0.5740966796875, Val Accuracy: 0.5250394940376282, Time: 25.61 sec\n",
      "Step 118300 - Training Loss: 0.9801213145256042, Val Loss: 1.0547723770141602, Accuracy: 0.5741886496543884, Val Accuracy: 0.5250185132026672, Time: 26.08 sec\n",
      "Step 118400 - Training Loss: 0.9832454323768616, Val Loss: 1.054726481437683, Accuracy: 0.5742776393890381, Val Accuracy: 0.5249975323677063, Time: 25.62 sec\n",
      "Step 118500 - Training Loss: 0.9635902047157288, Val Loss: 1.0546807050704956, Accuracy: 0.5743703246116638, Val Accuracy: 0.5249766111373901, Time: 25.11 sec\n",
      "Step 118600 - Training Loss: 0.9247322678565979, Val Loss: 1.054634928703308, Accuracy: 0.5744634866714478, Val Accuracy: 0.524955689907074, Time: 25.64 sec\n",
      "Step 118700 - Training Loss: 0.957891583442688, Val Loss: 1.0545892715454102, Accuracy: 0.5745532512664795, Val Accuracy: 0.5249348282814026, Time: 25.29 sec\n",
      "Step 118800 - Training Loss: 0.9556784629821777, Val Loss: 1.0545436143875122, Accuracy: 0.5746435523033142, Val Accuracy: 0.524914026260376, Time: 25.31 sec\n",
      "Step 118900 - Training Loss: 0.915802538394928, Val Loss: 1.0544980764389038, Accuracy: 0.5747318267822266, Val Accuracy: 0.5248932242393494, Time: 25.54 sec\n",
      "Step 119000 - Training Loss: 0.9493849873542786, Val Loss: 1.054452657699585, Accuracy: 0.574819803237915, Val Accuracy: 0.5248724818229675, Time: 25.59 sec\n",
      "Step 119100 - Training Loss: 0.9274000525474548, Val Loss: 1.0544073581695557, Accuracy: 0.574909508228302, Val Accuracy: 0.5248517394065857, Time: 25.88 sec\n",
      "Step 119200 - Training Loss: 0.9500142335891724, Val Loss: 1.0543620586395264, Accuracy: 0.5749969482421875, Val Accuracy: 0.5248310565948486, Time: 25.63 sec\n",
      "Step 119300 - Training Loss: 0.9527961611747742, Val Loss: 1.0543168783187866, Accuracy: 0.5750851035118103, Val Accuracy: 0.5248104333877563, Time: 25.27 sec\n",
      "Step 119400 - Training Loss: 0.9470885396003723, Val Loss: 1.0542716979980469, Accuracy: 0.5751732587814331, Val Accuracy: 0.5247898101806641, Time: 25.60 sec\n",
      "Step 119500 - Training Loss: 0.9271223545074463, Val Loss: 1.0542266368865967, Accuracy: 0.5752606987953186, Val Accuracy: 0.5247692465782166, Time: 25.36 sec\n",
      "Step 119600 - Training Loss: 0.9468961954116821, Val Loss: 1.0541815757751465, Accuracy: 0.5753477215766907, Val Accuracy: 0.524748682975769, Time: 25.43 sec\n",
      "Step 119700 - Training Loss: 0.9518935084342957, Val Loss: 1.0541367530822754, Accuracy: 0.5754354596138, Val Accuracy: 0.5247281789779663, Time: 25.73 sec\n",
      "Step 119800 - Training Loss: 0.9339024424552917, Val Loss: 1.0540919303894043, Accuracy: 0.5755285024642944, Val Accuracy: 0.5247076749801636, Time: 25.84 sec\n",
      "Step 119900 - Training Loss: 0.9620763063430786, Val Loss: 1.0540471076965332, Accuracy: 0.5756140351295471, Val Accuracy: 0.5246872305870056, Time: 25.53 sec\n",
      "Step 120000 - Training Loss: 0.9909984469413757, Val Loss: 1.0540024042129517, Accuracy: 0.5757001638412476, Val Accuracy: 0.5246667861938477, Time: 25.90 sec\n",
      "Step 120100 - Training Loss: 0.9257382154464722, Val Loss: 1.0539578199386597, Accuracy: 0.5757884979248047, Val Accuracy: 0.5246464610099792, Time: 25.74 sec\n",
      "Step 120200 - Training Loss: 0.9831695556640625, Val Loss: 1.0539132356643677, Accuracy: 0.5758786201477051, Val Accuracy: 0.5246260762214661, Time: 25.43 sec\n",
      "Step 120300 - Training Loss: 0.9381090402603149, Val Loss: 1.0538687705993652, Accuracy: 0.575965166091919, Val Accuracy: 0.5246057510375977, Time: 25.95 sec\n",
      "Step 120400 - Training Loss: 0.9455389380455017, Val Loss: 1.0538244247436523, Accuracy: 0.5760518908500671, Val Accuracy: 0.524585485458374, Time: 25.84 sec\n",
      "Step 120500 - Training Loss: 0.9799090623855591, Val Loss: 1.0537800788879395, Accuracy: 0.5761374235153198, Val Accuracy: 0.5245652198791504, Time: 25.58 sec\n",
      "Step 120600 - Training Loss: 0.987191379070282, Val Loss: 1.0537358522415161, Accuracy: 0.5762226581573486, Val Accuracy: 0.5245450139045715, Time: 25.48 sec\n",
      "Step 120700 - Training Loss: 0.9351754188537598, Val Loss: 1.0536916255950928, Accuracy: 0.5763076543807983, Val Accuracy: 0.5245248675346375, Time: 25.76 sec\n",
      "Step 120800 - Training Loss: 0.9459812641143799, Val Loss: 1.053647518157959, Accuracy: 0.5763930082321167, Val Accuracy: 0.5245047211647034, Time: 25.87 sec\n",
      "Step 120900 - Training Loss: 0.9326426386833191, Val Loss: 1.0536035299301147, Accuracy: 0.5764814615249634, Val Accuracy: 0.5244845747947693, Time: 25.70 sec\n",
      "Step 121000 - Training Loss: 0.9776608943939209, Val Loss: 1.0535595417022705, Accuracy: 0.5765659213066101, Val Accuracy: 0.52446448802948, Time: 25.61 sec\n",
      "Step 121100 - Training Loss: 0.9332597851753235, Val Loss: 1.0535156726837158, Accuracy: 0.576650857925415, Val Accuracy: 0.5244444608688354, Time: 25.86 sec\n",
      "Step 121200 - Training Loss: 0.9130992293357849, Val Loss: 1.0534718036651611, Accuracy: 0.5767369866371155, Val Accuracy: 0.5244244337081909, Time: 26.12 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 121300 - Training Loss: 0.9403380751609802, Val Loss: 1.053428053855896, Accuracy: 0.5768248438835144, Val Accuracy: 0.5244044661521912, Time: 25.65 sec\n",
      "Step 121400 - Training Loss: 0.9397637248039246, Val Loss: 1.0533844232559204, Accuracy: 0.5769128203392029, Val Accuracy: 0.5243844985961914, Time: 25.76 sec\n",
      "Step 121500 - Training Loss: 0.9644781351089478, Val Loss: 1.0533407926559448, Accuracy: 0.5769971013069153, Val Accuracy: 0.5243645906448364, Time: 26.06 sec\n",
      "Step 121600 - Training Loss: 0.9642860293388367, Val Loss: 1.0532972812652588, Accuracy: 0.5770832896232605, Val Accuracy: 0.5243447422981262, Time: 25.81 sec\n",
      "Step 121700 - Training Loss: 1.0053508281707764, Val Loss: 1.0532537698745728, Accuracy: 0.5771710872650146, Val Accuracy: 0.524324893951416, Time: 25.85 sec\n",
      "Step 121800 - Training Loss: 1.0054371356964111, Val Loss: 1.0532103776931763, Accuracy: 0.5772567987442017, Val Accuracy: 0.5243050456047058, Time: 25.99 sec\n",
      "Step 121900 - Training Loss: 0.9472466111183167, Val Loss: 1.0531671047210693, Accuracy: 0.5773417949676514, Val Accuracy: 0.5242852568626404, Time: 26.00 sec\n",
      "Step 122000 - Training Loss: 0.9138245582580566, Val Loss: 1.0531238317489624, Accuracy: 0.5774272680282593, Val Accuracy: 0.5242655277252197, Time: 25.67 sec\n",
      "Step 122100 - Training Loss: 0.9307112097740173, Val Loss: 1.053080677986145, Accuracy: 0.5775116086006165, Val Accuracy: 0.5242457985877991, Time: 26.14 sec\n",
      "Step 122200 - Training Loss: 0.9574880003929138, Val Loss: 1.0530375242233276, Accuracy: 0.5775962471961975, Val Accuracy: 0.5242260694503784, Time: 26.30 sec\n",
      "Step 122300 - Training Loss: 0.9458162784576416, Val Loss: 1.0529944896697998, Accuracy: 0.5776804089546204, Val Accuracy: 0.5242064595222473, Time: 26.00 sec\n",
      "Step 122400 - Training Loss: 0.9410228729248047, Val Loss: 1.0529515743255615, Accuracy: 0.5777633190155029, Val Accuracy: 0.5241867899894714, Time: 25.93 sec\n",
      "Step 122500 - Training Loss: 0.9629796147346497, Val Loss: 1.0529086589813232, Accuracy: 0.5778476595878601, Val Accuracy: 0.5241672396659851, Time: 25.66 sec\n",
      "Step 122600 - Training Loss: 0.950654923915863, Val Loss: 1.0528658628463745, Accuracy: 0.5779343247413635, Val Accuracy: 0.524147629737854, Time: 25.74 sec\n",
      "Step 122700 - Training Loss: 0.9460282325744629, Val Loss: 1.0528230667114258, Accuracy: 0.5780195593833923, Val Accuracy: 0.5241281390190125, Time: 25.62 sec\n",
      "Step 122800 - Training Loss: 0.926567792892456, Val Loss: 1.0527803897857666, Accuracy: 0.5781025290489197, Val Accuracy: 0.5241086483001709, Time: 25.85 sec\n",
      "Step 122900 - Training Loss: 0.9403284788131714, Val Loss: 1.0527377128601074, Accuracy: 0.5781847834587097, Val Accuracy: 0.5240891575813293, Time: 25.93 sec\n",
      "Step 123000 - Training Loss: 0.9857635498046875, Val Loss: 1.0526951551437378, Accuracy: 0.5782677531242371, Val Accuracy: 0.5240697264671326, Time: 25.91 sec\n",
      "Step 123100 - Training Loss: 0.9260925054550171, Val Loss: 1.0526527166366577, Accuracy: 0.5783516764640808, Val Accuracy: 0.5240502953529358, Time: 25.37 sec\n",
      "Step 123200 - Training Loss: 0.9095693230628967, Val Loss: 1.0526102781295776, Accuracy: 0.5784350037574768, Val Accuracy: 0.5240309238433838, Time: 25.36 sec\n",
      "Step 123300 - Training Loss: 0.9466807842254639, Val Loss: 1.052567958831787, Accuracy: 0.5785189867019653, Val Accuracy: 0.5240116119384766, Time: 26.43 sec\n",
      "Step 123400 - Training Loss: 0.9211879372596741, Val Loss: 1.0525256395339966, Accuracy: 0.5786013603210449, Val Accuracy: 0.5239923000335693, Time: 25.38 sec\n",
      "Step 123500 - Training Loss: 0.9457206726074219, Val Loss: 1.0524834394454956, Accuracy: 0.578683614730835, Val Accuracy: 0.5239729881286621, Time: 25.50 sec\n",
      "Step 123600 - Training Loss: 0.9254295825958252, Val Loss: 1.0524413585662842, Accuracy: 0.578766942024231, Val Accuracy: 0.5239538550376892, Time: 25.17 sec\n",
      "Step 123700 - Training Loss: 0.9192228317260742, Val Loss: 1.0523992776870728, Accuracy: 0.5788503885269165, Val Accuracy: 0.5239346027374268, Time: 25.47 sec\n",
      "Step 123800 - Training Loss: 0.9448091983795166, Val Loss: 1.0523571968078613, Accuracy: 0.5789310932159424, Val Accuracy: 0.5239154100418091, Time: 25.31 sec\n",
      "Step 123900 - Training Loss: 0.9286890625953674, Val Loss: 1.0523152351379395, Accuracy: 0.5790176391601562, Val Accuracy: 0.5238962769508362, Time: 25.94 sec\n",
      "Step 124000 - Training Loss: 0.9567214846611023, Val Loss: 1.0522733926773071, Accuracy: 0.5791015028953552, Val Accuracy: 0.5238771438598633, Time: 25.20 sec\n",
      "Step 124100 - Training Loss: 0.971426248550415, Val Loss: 1.0522315502166748, Accuracy: 0.5791842937469482, Val Accuracy: 0.5238580703735352, Time: 25.85 sec\n",
      "Step 124200 - Training Loss: 0.9675032496452332, Val Loss: 1.052189826965332, Accuracy: 0.5792689323425293, Val Accuracy: 0.523838996887207, Time: 26.09 sec\n",
      "Step 124300 - Training Loss: 0.9670741558074951, Val Loss: 1.0521482229232788, Accuracy: 0.5793480277061462, Val Accuracy: 0.5238199234008789, Time: 25.48 sec\n",
      "Step 124400 - Training Loss: 0.9503172039985657, Val Loss: 1.0521066188812256, Accuracy: 0.5794298648834229, Val Accuracy: 0.5238009095191956, Time: 25.67 sec\n",
      "Step 124500 - Training Loss: 0.9622469544410706, Val Loss: 1.0520650148391724, Accuracy: 0.5795109272003174, Val Accuracy: 0.523781955242157, Time: 25.67 sec\n",
      "Step 124600 - Training Loss: 0.9340459704399109, Val Loss: 1.0520235300064087, Accuracy: 0.5795917510986328, Val Accuracy: 0.5237630009651184, Time: 25.60 sec\n",
      "Step 124700 - Training Loss: 0.9523744583129883, Val Loss: 1.0519821643829346, Accuracy: 0.579673171043396, Val Accuracy: 0.5237441062927246, Time: 26.09 sec\n",
      "Step 124800 - Training Loss: 0.9683006405830383, Val Loss: 1.0519407987594604, Accuracy: 0.5797544121742249, Val Accuracy: 0.5237252116203308, Time: 25.79 sec\n",
      "Step 124900 - Training Loss: 1.006475806236267, Val Loss: 1.0518995523452759, Accuracy: 0.5798345804214478, Val Accuracy: 0.5237063765525818, Time: 26.57 sec\n",
      "Step 125000 - Training Loss: 0.9520309567451477, Val Loss: 1.0518583059310913, Accuracy: 0.5799157619476318, Val Accuracy: 0.5236875414848328, Time: 25.53 sec\n",
      "Step 125100 - Training Loss: 0.9611760973930359, Val Loss: 1.0518171787261963, Accuracy: 0.5799983739852905, Val Accuracy: 0.5236687660217285, Time: 25.65 sec\n",
      "Step 125200 - Training Loss: 0.9064832329750061, Val Loss: 1.0517760515213013, Accuracy: 0.5800802111625671, Val Accuracy: 0.5236499905586243, Time: 26.00 sec\n",
      "Step 125300 - Training Loss: 0.9722639918327332, Val Loss: 1.0517350435256958, Accuracy: 0.5801609754562378, Val Accuracy: 0.52363121509552, Time: 25.71 sec\n",
      "Step 125400 - Training Loss: 0.9439565539360046, Val Loss: 1.0516941547393799, Accuracy: 0.5802394151687622, Val Accuracy: 0.5236125588417053, Time: 25.75 sec\n",
      "Step 125500 - Training Loss: 0.9057661890983582, Val Loss: 1.051653265953064, Accuracy: 0.5803212523460388, Val Accuracy: 0.5235938429832458, Time: 25.87 sec\n",
      "Step 125600 - Training Loss: 0.9941772222518921, Val Loss: 1.051612377166748, Accuracy: 0.5804039239883423, Val Accuracy: 0.5235751867294312, Time: 25.25 sec\n",
      "Step 125700 - Training Loss: 0.9369214773178101, Val Loss: 1.0515716075897217, Accuracy: 0.580485999584198, Val Accuracy: 0.5235565900802612, Time: 26.05 sec\n",
      "Step 125800 - Training Loss: 0.9720489978790283, Val Loss: 1.0515309572219849, Accuracy: 0.5805675387382507, Val Accuracy: 0.5235379934310913, Time: 25.59 sec\n",
      "Step 125900 - Training Loss: 0.9166787266731262, Val Loss: 1.051490306854248, Accuracy: 0.580652117729187, Val Accuracy: 0.5235194563865662, Time: 25.56 sec\n",
      "Step 126000 - Training Loss: 0.9485967755317688, Val Loss: 1.0514497756958008, Accuracy: 0.5807393193244934, Val Accuracy: 0.523500919342041, Time: 25.90 sec\n",
      "Step 126100 - Training Loss: 0.9596681594848633, Val Loss: 1.0514092445373535, Accuracy: 0.5808209776878357, Val Accuracy: 0.5234824419021606, Time: 26.18 sec\n",
      "Step 126200 - Training Loss: 0.961419403553009, Val Loss: 1.0513688325881958, Accuracy: 0.580899715423584, Val Accuracy: 0.5234639644622803, Time: 26.21 sec\n",
      "Step 126300 - Training Loss: 0.9373076558113098, Val Loss: 1.051328420639038, Accuracy: 0.5809805989265442, Val Accuracy: 0.5234454870223999, Time: 25.59 sec\n",
      "Step 126400 - Training Loss: 0.938679039478302, Val Loss: 1.05128812789917, Accuracy: 0.5810600519180298, Val Accuracy: 0.5234271287918091, Time: 25.60 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 126500 - Training Loss: 0.9534285068511963, Val Loss: 1.0512479543685913, Accuracy: 0.5811406373977661, Val Accuracy: 0.5234087109565735, Time: 25.63 sec\n",
      "Step 126600 - Training Loss: 0.9560902118682861, Val Loss: 1.0512077808380127, Accuracy: 0.581219494342804, Val Accuracy: 0.5233903527259827, Time: 25.45 sec\n",
      "Step 126700 - Training Loss: 0.946963906288147, Val Loss: 1.051167607307434, Accuracy: 0.5812996625900269, Val Accuracy: 0.5233720541000366, Time: 25.89 sec\n",
      "Step 126800 - Training Loss: 0.9097938537597656, Val Loss: 1.051127552986145, Accuracy: 0.5813781023025513, Val Accuracy: 0.5233537554740906, Time: 25.73 sec\n",
      "Step 126900 - Training Loss: 0.9454545378684998, Val Loss: 1.051087498664856, Accuracy: 0.5814604163169861, Val Accuracy: 0.5233354568481445, Time: 25.20 sec\n",
      "Step 127000 - Training Loss: 0.9169841408729553, Val Loss: 1.0510475635528564, Accuracy: 0.5815423130989075, Val Accuracy: 0.5233172178268433, Time: 26.10 sec\n",
      "Step 127100 - Training Loss: 0.9447017908096313, Val Loss: 1.0510077476501465, Accuracy: 0.5816205143928528, Val Accuracy: 0.5232990384101868, Time: 25.57 sec\n",
      "Step 127200 - Training Loss: 0.9468578100204468, Val Loss: 1.0509679317474365, Accuracy: 0.5817009210586548, Val Accuracy: 0.5232808589935303, Time: 26.10 sec\n",
      "Step 127300 - Training Loss: 0.92845219373703, Val Loss: 1.0509282350540161, Accuracy: 0.5817837119102478, Val Accuracy: 0.5232626795768738, Time: 25.54 sec\n",
      "Step 127400 - Training Loss: 0.9521570205688477, Val Loss: 1.0508885383605957, Accuracy: 0.5818644165992737, Val Accuracy: 0.5232445597648621, Time: 25.32 sec\n",
      "Step 127500 - Training Loss: 0.9270600080490112, Val Loss: 1.0508488416671753, Accuracy: 0.5819481015205383, Val Accuracy: 0.5232264399528503, Time: 25.20 sec\n",
      "Step 127600 - Training Loss: 0.9696954488754272, Val Loss: 1.0508092641830444, Accuracy: 0.582027018070221, Val Accuracy: 0.5232083797454834, Time: 25.64 sec\n",
      "Step 127700 - Training Loss: 0.9585157632827759, Val Loss: 1.0507698059082031, Accuracy: 0.5821091532707214, Val Accuracy: 0.5231903195381165, Time: 25.87 sec\n",
      "Step 127800 - Training Loss: 0.9712908267974854, Val Loss: 1.0507303476333618, Accuracy: 0.5821893215179443, Val Accuracy: 0.5231723189353943, Time: 25.80 sec\n",
      "Step 127900 - Training Loss: 0.9183838963508606, Val Loss: 1.05069100856781, Accuracy: 0.5822700262069702, Val Accuracy: 0.5231543183326721, Time: 25.59 sec\n",
      "Step 128000 - Training Loss: 0.9291682839393616, Val Loss: 1.0506516695022583, Accuracy: 0.5823487043380737, Val Accuracy: 0.5231363773345947, Time: 25.73 sec\n",
      "Step 128100 - Training Loss: 0.9472908973693848, Val Loss: 1.050612449645996, Accuracy: 0.5824267864227295, Val Accuracy: 0.5231184363365173, Time: 25.51 sec\n",
      "Step 128200 - Training Loss: 0.916343092918396, Val Loss: 1.0505732297897339, Accuracy: 0.5825042128562927, Val Accuracy: 0.5231005549430847, Time: 25.62 sec\n",
      "Step 128300 - Training Loss: 0.9526780247688293, Val Loss: 1.0505341291427612, Accuracy: 0.5825823545455933, Val Accuracy: 0.5230826735496521, Time: 25.51 sec\n",
      "Step 128400 - Training Loss: 0.9601863622665405, Val Loss: 1.0504950284957886, Accuracy: 0.5826614499092102, Val Accuracy: 0.5230648517608643, Time: 26.38 sec\n",
      "Step 128500 - Training Loss: 0.9697349667549133, Val Loss: 1.0504560470581055, Accuracy: 0.5827387571334839, Val Accuracy: 0.5230470299720764, Time: 25.57 sec\n",
      "Step 128600 - Training Loss: 0.9644885063171387, Val Loss: 1.0504170656204224, Accuracy: 0.5828186273574829, Val Accuracy: 0.5230292081832886, Time: 25.65 sec\n",
      "Step 128700 - Training Loss: 0.9334267377853394, Val Loss: 1.0503782033920288, Accuracy: 0.5828951597213745, Val Accuracy: 0.5230114459991455, Time: 25.80 sec\n",
      "Step 128800 - Training Loss: 0.914654016494751, Val Loss: 1.0503393411636353, Accuracy: 0.5829721093177795, Val Accuracy: 0.5229936838150024, Time: 25.84 sec\n",
      "Step 128900 - Training Loss: 0.9288497567176819, Val Loss: 1.0503005981445312, Accuracy: 0.583048939704895, Val Accuracy: 0.5229759812355042, Time: 25.83 sec\n",
      "Step 129000 - Training Loss: 0.964672863483429, Val Loss: 1.0502618551254272, Accuracy: 0.5831266045570374, Val Accuracy: 0.5229583382606506, Time: 25.34 sec\n",
      "Step 129100 - Training Loss: 0.9732134342193604, Val Loss: 1.0502232313156128, Accuracy: 0.5832070112228394, Val Accuracy: 0.5229406356811523, Time: 26.04 sec\n",
      "Step 129200 - Training Loss: 0.9375128746032715, Val Loss: 1.0501846075057983, Accuracy: 0.583287239074707, Val Accuracy: 0.5229230523109436, Time: 25.76 sec\n",
      "Step 129300 - Training Loss: 0.9415391087532043, Val Loss: 1.0501461029052734, Accuracy: 0.5833648443222046, Val Accuracy: 0.5229054093360901, Time: 26.00 sec\n",
      "Step 129400 - Training Loss: 1.002143383026123, Val Loss: 1.0501075983047485, Accuracy: 0.5834429860115051, Val Accuracy: 0.5228878855705261, Time: 25.89 sec\n",
      "Step 129500 - Training Loss: 0.9986783266067505, Val Loss: 1.0500692129135132, Accuracy: 0.5835254788398743, Val Accuracy: 0.5228703022003174, Time: 25.52 sec\n",
      "Step 129600 - Training Loss: 0.9101167321205139, Val Loss: 1.0500308275222778, Accuracy: 0.5836017727851868, Val Accuracy: 0.5228527784347534, Time: 25.51 sec\n",
      "Step 129700 - Training Loss: 0.9022951722145081, Val Loss: 1.049992561340332, Accuracy: 0.5836792588233948, Val Accuracy: 0.5228353142738342, Time: 25.75 sec\n",
      "Step 129800 - Training Loss: 0.9517211318016052, Val Loss: 1.0499542951583862, Accuracy: 0.5837551951408386, Val Accuracy: 0.522817850112915, Time: 25.40 sec\n",
      "Step 129900 - Training Loss: 0.9582722783088684, Val Loss: 1.04991614818573, Accuracy: 0.5838345289230347, Val Accuracy: 0.5228003859519958, Time: 25.38 sec\n",
      "Step 130000 - Training Loss: 0.9836528301239014, Val Loss: 1.0498780012130737, Accuracy: 0.5839091539382935, Val Accuracy: 0.5227829813957214, Time: 25.47 sec\n",
      "Step 130100 - Training Loss: 0.9327055215835571, Val Loss: 1.049839973449707, Accuracy: 0.5839855074882507, Val Accuracy: 0.522765576839447, Time: 25.45 sec\n",
      "Step 130200 - Training Loss: 1.0000606775283813, Val Loss: 1.0498019456863403, Accuracy: 0.584060788154602, Val Accuracy: 0.5227482318878174, Time: 25.76 sec\n",
      "Step 130300 - Training Loss: 0.9470122456550598, Val Loss: 1.0497639179229736, Accuracy: 0.5841367840766907, Val Accuracy: 0.5227308869361877, Time: 25.45 sec\n",
      "Step 130400 - Training Loss: 0.9465578198432922, Val Loss: 1.049726128578186, Accuracy: 0.5842114686965942, Val Accuracy: 0.5227136015892029, Time: 25.38 sec\n",
      "Step 130500 - Training Loss: 0.9104778170585632, Val Loss: 1.0496882200241089, Accuracy: 0.5842891931533813, Val Accuracy: 0.522696316242218, Time: 25.39 sec\n",
      "Step 130600 - Training Loss: 1.004348874092102, Val Loss: 1.0496504306793213, Accuracy: 0.5843636393547058, Val Accuracy: 0.5226790308952332, Time: 25.56 sec\n",
      "Step 130700 - Training Loss: 0.9500681757926941, Val Loss: 1.0496127605438232, Accuracy: 0.5844394564628601, Val Accuracy: 0.5226618051528931, Time: 26.49 sec\n",
      "Step 130800 - Training Loss: 0.9180234670639038, Val Loss: 1.0495750904083252, Accuracy: 0.5845154523849487, Val Accuracy: 0.5226446390151978, Time: 27.02 sec\n",
      "Step 130900 - Training Loss: 0.9451651573181152, Val Loss: 1.0495374202728271, Accuracy: 0.5845907330513, Val Accuracy: 0.5226274132728577, Time: 26.08 sec\n",
      "Step 131000 - Training Loss: 0.9511076211929321, Val Loss: 1.0494999885559082, Accuracy: 0.5846657752990723, Val Accuracy: 0.5226103067398071, Time: 25.77 sec\n",
      "Step 131100 - Training Loss: 0.9271593689918518, Val Loss: 1.0494624376296997, Accuracy: 0.5847393870353699, Val Accuracy: 0.5225931406021118, Time: 25.84 sec\n",
      "Step 131200 - Training Loss: 0.9809736013412476, Val Loss: 1.0494250059127808, Accuracy: 0.5848143696784973, Val Accuracy: 0.5225760340690613, Time: 25.79 sec\n",
      "Step 131300 - Training Loss: 0.9431433081626892, Val Loss: 1.0493875741958618, Accuracy: 0.5848917961120605, Val Accuracy: 0.5225589871406555, Time: 25.49 sec\n",
      "Step 131400 - Training Loss: 0.9266314506530762, Val Loss: 1.0493502616882324, Accuracy: 0.5849674940109253, Val Accuracy: 0.5225419402122498, Time: 25.87 sec\n",
      "Step 131500 - Training Loss: 0.9560492634773254, Val Loss: 1.0493130683898926, Accuracy: 0.5850417017936707, Val Accuracy: 0.522524893283844, Time: 25.63 sec\n",
      "Step 131600 - Training Loss: 0.9470247030258179, Val Loss: 1.0492758750915527, Accuracy: 0.5851148962974548, Val Accuracy: 0.522507905960083, Time: 25.69 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 131700 - Training Loss: 0.9582850933074951, Val Loss: 1.049238681793213, Accuracy: 0.5851888656616211, Val Accuracy: 0.5224909782409668, Time: 26.01 sec\n",
      "Step 131800 - Training Loss: 0.9499944448471069, Val Loss: 1.0492016077041626, Accuracy: 0.5852647423744202, Val Accuracy: 0.5224739909172058, Time: 25.48 sec\n",
      "Step 131900 - Training Loss: 0.9690461754798889, Val Loss: 1.0491645336151123, Accuracy: 0.5853405594825745, Val Accuracy: 0.5224570631980896, Time: 25.36 sec\n",
      "Step 132000 - Training Loss: 0.970564067363739, Val Loss: 1.0491275787353516, Accuracy: 0.5854150056838989, Val Accuracy: 0.5224401950836182, Time: 25.78 sec\n",
      "Step 132100 - Training Loss: 0.9473444819450378, Val Loss: 1.0490906238555908, Accuracy: 0.5854871869087219, Val Accuracy: 0.5224233269691467, Time: 25.43 sec\n",
      "Step 132200 - Training Loss: 0.9362727999687195, Val Loss: 1.0490537881851196, Accuracy: 0.5855615139007568, Val Accuracy: 0.5224064588546753, Time: 25.70 sec\n",
      "Step 132300 - Training Loss: 0.9128333926200867, Val Loss: 1.0490169525146484, Accuracy: 0.5856362581253052, Val Accuracy: 0.5223896503448486, Time: 25.66 sec\n",
      "Step 132400 - Training Loss: 0.9497161507606506, Val Loss: 1.0489802360534668, Accuracy: 0.5857091546058655, Val Accuracy: 0.5223729014396667, Time: 25.39 sec\n",
      "Step 132500 - Training Loss: 0.9618579745292664, Val Loss: 1.0489435195922852, Accuracy: 0.5857826471328735, Val Accuracy: 0.5223560929298401, Time: 25.72 sec\n",
      "Step 132600 - Training Loss: 0.9504393935203552, Val Loss: 1.0489068031311035, Accuracy: 0.5858568549156189, Val Accuracy: 0.5223393440246582, Time: 25.54 sec\n",
      "Step 132700 - Training Loss: 0.9348610639572144, Val Loss: 1.0488702058792114, Accuracy: 0.5859315395355225, Val Accuracy: 0.5223226547241211, Time: 25.49 sec\n",
      "Step 132800 - Training Loss: 0.9211076498031616, Val Loss: 1.0488337278366089, Accuracy: 0.5860052108764648, Val Accuracy: 0.522305965423584, Time: 26.15 sec\n",
      "Step 132900 - Training Loss: 0.948779821395874, Val Loss: 1.0487972497940063, Accuracy: 0.5860777497291565, Val Accuracy: 0.5222892761230469, Time: 25.77 sec\n",
      "Step 133000 - Training Loss: 0.978886604309082, Val Loss: 1.0487607717514038, Accuracy: 0.5861522555351257, Val Accuracy: 0.5222726464271545, Time: 25.86 sec\n",
      "Step 133100 - Training Loss: 0.969038188457489, Val Loss: 1.0487244129180908, Accuracy: 0.5862246751785278, Val Accuracy: 0.5222560167312622, Time: 25.87 sec\n",
      "Step 133200 - Training Loss: 0.9385532736778259, Val Loss: 1.0486880540847778, Accuracy: 0.5862974524497986, Val Accuracy: 0.5222394466400146, Time: 25.94 sec\n",
      "Step 133300 - Training Loss: 1.0091300010681152, Val Loss: 1.0486518144607544, Accuracy: 0.5863704085350037, Val Accuracy: 0.5222228765487671, Time: 25.80 sec\n",
      "Step 133400 - Training Loss: 0.9360336661338806, Val Loss: 1.048615574836731, Accuracy: 0.5864443778991699, Val Accuracy: 0.5222063064575195, Time: 25.71 sec\n",
      "Step 133500 - Training Loss: 0.9273545742034912, Val Loss: 1.048579454421997, Accuracy: 0.5865167379379272, Val Accuracy: 0.5221897959709167, Time: 26.09 sec\n",
      "Step 133600 - Training Loss: 0.9277225136756897, Val Loss: 1.0485433340072632, Accuracy: 0.5865904092788696, Val Accuracy: 0.5221733450889587, Time: 25.41 sec\n",
      "Step 133700 - Training Loss: 0.9888210892677307, Val Loss: 1.0485072135925293, Accuracy: 0.5866627097129822, Val Accuracy: 0.522156834602356, Time: 26.78 sec\n",
      "Step 133800 - Training Loss: 0.9248225092887878, Val Loss: 1.048471212387085, Accuracy: 0.5867339372634888, Val Accuracy: 0.522140383720398, Time: 25.52 sec\n",
      "Step 133900 - Training Loss: 0.9730252623558044, Val Loss: 1.0484353303909302, Accuracy: 0.5868068933486938, Val Accuracy: 0.5221239924430847, Time: 25.96 sec\n",
      "Step 134000 - Training Loss: 0.9248437285423279, Val Loss: 1.0483993291854858, Accuracy: 0.5868796706199646, Val Accuracy: 0.5221076011657715, Time: 25.98 sec\n",
      "Step 134100 - Training Loss: 0.9903486967086792, Val Loss: 1.0483635663986206, Accuracy: 0.5869516134262085, Val Accuracy: 0.5220912098884583, Time: 25.53 sec\n",
      "Step 134200 - Training Loss: 0.9436236619949341, Val Loss: 1.0483278036117554, Accuracy: 0.5870236754417419, Val Accuracy: 0.5220748782157898, Time: 25.92 sec\n",
      "Step 134300 - Training Loss: 0.9236498475074768, Val Loss: 1.0482920408248901, Accuracy: 0.5870944261550903, Val Accuracy: 0.5220585465431213, Time: 25.83 sec\n",
      "Step 134400 - Training Loss: 0.959568440914154, Val Loss: 1.048256278038025, Accuracy: 0.5871661305427551, Val Accuracy: 0.5220422148704529, Time: 25.59 sec\n",
      "Step 134500 - Training Loss: 0.9409131407737732, Val Loss: 1.0482207536697388, Accuracy: 0.5872377157211304, Val Accuracy: 0.5220259428024292, Time: 26.17 sec\n",
      "Step 134600 - Training Loss: 0.9743005633354187, Val Loss: 1.048185110092163, Accuracy: 0.5873090624809265, Val Accuracy: 0.5220097303390503, Time: 25.57 sec\n",
      "Step 134700 - Training Loss: 0.9131763577461243, Val Loss: 1.048149585723877, Accuracy: 0.587381899356842, Val Accuracy: 0.5219935178756714, Time: 26.22 sec\n",
      "Step 134800 - Training Loss: 0.9290995597839355, Val Loss: 1.0481141805648804, Accuracy: 0.5874529480934143, Val Accuracy: 0.5219773054122925, Time: 26.15 sec\n",
      "Step 134900 - Training Loss: 0.9504006505012512, Val Loss: 1.0480786561965942, Accuracy: 0.5875251293182373, Val Accuracy: 0.5219610929489136, Time: 25.60 sec\n",
      "Step 135000 - Training Loss: 0.9976420998573303, Val Loss: 1.0480433702468872, Accuracy: 0.5875968337059021, Val Accuracy: 0.5219449400901794, Time: 25.66 sec\n",
      "Step 135100 - Training Loss: 0.9581092000007629, Val Loss: 1.0480079650878906, Accuracy: 0.5876688361167908, Val Accuracy: 0.5219288468360901, Time: 26.06 sec\n",
      "Step 135200 - Training Loss: 0.9455968737602234, Val Loss: 1.0479727983474731, Accuracy: 0.5877405405044556, Val Accuracy: 0.521912693977356, Time: 26.21 sec\n",
      "Step 135300 - Training Loss: 0.9382927417755127, Val Loss: 1.0479375123977661, Accuracy: 0.5878114104270935, Val Accuracy: 0.5218966007232666, Time: 25.82 sec\n",
      "Step 135400 - Training Loss: 0.9401509165763855, Val Loss: 1.0479023456573486, Accuracy: 0.5878826379776001, Val Accuracy: 0.521880567073822, Time: 26.16 sec\n",
      "Step 135500 - Training Loss: 0.9375328421592712, Val Loss: 1.0478672981262207, Accuracy: 0.5879517197608948, Val Accuracy: 0.5218645334243774, Time: 26.37 sec\n",
      "Step 135600 - Training Loss: 0.932080864906311, Val Loss: 1.0478322505950928, Accuracy: 0.5880244970321655, Val Accuracy: 0.5218484997749329, Time: 26.67 sec\n",
      "Step 135700 - Training Loss: 0.958795964717865, Val Loss: 1.0477972030639648, Accuracy: 0.5880956649780273, Val Accuracy: 0.5218325257301331, Time: 25.89 sec\n",
      "Step 135800 - Training Loss: 0.9635663032531738, Val Loss: 1.0477622747421265, Accuracy: 0.5881658792495728, Val Accuracy: 0.5218165516853333, Time: 26.07 sec\n",
      "Step 135900 - Training Loss: 0.9871242642402649, Val Loss: 1.047727346420288, Accuracy: 0.5882355570793152, Val Accuracy: 0.5218006372451782, Time: 25.86 sec\n",
      "Step 136000 - Training Loss: 0.9710808992385864, Val Loss: 1.0476925373077393, Accuracy: 0.5883061289787292, Val Accuracy: 0.5217846632003784, Time: 25.68 sec\n",
      "Step 136100 - Training Loss: 0.9112786054611206, Val Loss: 1.0476577281951904, Accuracy: 0.5883752107620239, Val Accuracy: 0.5217688083648682, Time: 25.97 sec\n",
      "Step 136200 - Training Loss: 0.9479551315307617, Val Loss: 1.0476229190826416, Accuracy: 0.588446855545044, Val Accuracy: 0.5217528939247131, Time: 25.75 sec\n",
      "Step 136300 - Training Loss: 0.9560582637786865, Val Loss: 1.0475882291793823, Accuracy: 0.5885175466537476, Val Accuracy: 0.5217370390892029, Time: 25.79 sec\n",
      "Step 136400 - Training Loss: 0.971505343914032, Val Loss: 1.047553539276123, Accuracy: 0.5885879993438721, Val Accuracy: 0.5217212438583374, Time: 25.46 sec\n",
      "Step 136500 - Training Loss: 0.9774855375289917, Val Loss: 1.0475189685821533, Accuracy: 0.5886606574058533, Val Accuracy: 0.5217054486274719, Time: 25.71 sec\n",
      "Step 136600 - Training Loss: 0.9257012009620667, Val Loss: 1.0474843978881836, Accuracy: 0.5887308716773987, Val Accuracy: 0.5216896533966064, Time: 26.43 sec\n",
      "Step 136700 - Training Loss: 0.9422963261604309, Val Loss: 1.0474499464035034, Accuracy: 0.5888001322746277, Val Accuracy: 0.5216739177703857, Time: 26.34 sec\n",
      "Step 136800 - Training Loss: 0.9444609880447388, Val Loss: 1.0474154949188232, Accuracy: 0.5888684988021851, Val Accuracy: 0.521658182144165, Time: 25.93 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 136900 - Training Loss: 0.9457520842552185, Val Loss: 1.047381043434143, Accuracy: 0.5889376401901245, Val Accuracy: 0.5216424465179443, Time: 25.97 sec\n",
      "Step 137000 - Training Loss: 0.9272998571395874, Val Loss: 1.0473467111587524, Accuracy: 0.5890074372291565, Val Accuracy: 0.5216267704963684, Time: 25.98 sec\n",
      "Step 137100 - Training Loss: 0.9171814918518066, Val Loss: 1.0473123788833618, Accuracy: 0.5890772342681885, Val Accuracy: 0.5216110944747925, Time: 25.99 sec\n",
      "Step 137200 - Training Loss: 0.9305802583694458, Val Loss: 1.0472781658172607, Accuracy: 0.5891467928886414, Val Accuracy: 0.5215954184532166, Time: 25.34 sec\n",
      "Step 137300 - Training Loss: 0.9704833626747131, Val Loss: 1.0472439527511597, Accuracy: 0.5892158150672913, Val Accuracy: 0.5215798020362854, Time: 25.52 sec\n",
      "Step 137400 - Training Loss: 0.9548941850662231, Val Loss: 1.0472098588943481, Accuracy: 0.5892871618270874, Val Accuracy: 0.521564245223999, Time: 25.43 sec\n",
      "Step 137500 - Training Loss: 0.9669671058654785, Val Loss: 1.0471757650375366, Accuracy: 0.5893599987030029, Val Accuracy: 0.5215486288070679, Time: 25.99 sec\n",
      "Step 137600 - Training Loss: 0.9136823415756226, Val Loss: 1.047141671180725, Accuracy: 0.589430034160614, Val Accuracy: 0.5215330719947815, Time: 25.38 sec\n",
      "Step 137700 - Training Loss: 0.9889739751815796, Val Loss: 1.0471076965332031, Accuracy: 0.5894991159439087, Val Accuracy: 0.5215175747871399, Time: 26.18 sec\n",
      "Step 137800 - Training Loss: 0.9533770084381104, Val Loss: 1.0470737218856812, Accuracy: 0.5895676016807556, Val Accuracy: 0.5215020179748535, Time: 25.97 sec\n",
      "Step 137900 - Training Loss: 0.9438865780830383, Val Loss: 1.0470397472381592, Accuracy: 0.5896368622779846, Val Accuracy: 0.5214865803718567, Time: 25.90 sec\n",
      "Step 138000 - Training Loss: 0.9726148247718811, Val Loss: 1.0470058917999268, Accuracy: 0.5897061824798584, Val Accuracy: 0.5214710831642151, Time: 25.93 sec\n",
      "Step 138100 - Training Loss: 0.960429310798645, Val Loss: 1.0469721555709839, Accuracy: 0.5897737145423889, Val Accuracy: 0.5214556455612183, Time: 25.71 sec\n",
      "Step 138200 - Training Loss: 0.9402025938034058, Val Loss: 1.0469383001327515, Accuracy: 0.5898418426513672, Val Accuracy: 0.5214402079582214, Time: 25.51 sec\n",
      "Step 138300 - Training Loss: 0.9461847543716431, Val Loss: 1.0469046831130981, Accuracy: 0.5899109840393066, Val Accuracy: 0.5214248299598694, Time: 26.09 sec\n",
      "Step 138400 - Training Loss: 0.9651238918304443, Val Loss: 1.0468709468841553, Accuracy: 0.5899784564971924, Val Accuracy: 0.5214094519615173, Time: 25.97 sec\n",
      "Step 138500 - Training Loss: 0.9117134809494019, Val Loss: 1.046837329864502, Accuracy: 0.5900475978851318, Val Accuracy: 0.5213940739631653, Time: 26.16 sec\n",
      "Step 138600 - Training Loss: 0.9618206024169922, Val Loss: 1.0468038320541382, Accuracy: 0.5901159048080444, Val Accuracy: 0.521378755569458, Time: 26.32 sec\n",
      "Step 138700 - Training Loss: 0.9569073915481567, Val Loss: 1.0467703342437744, Accuracy: 0.5901839137077332, Val Accuracy: 0.5213634371757507, Time: 26.00 sec\n",
      "Step 138800 - Training Loss: 0.9407727718353271, Val Loss: 1.0467368364334106, Accuracy: 0.5902511477470398, Val Accuracy: 0.5213481783866882, Time: 25.63 sec\n",
      "Step 138900 - Training Loss: 0.9737337231636047, Val Loss: 1.0467033386230469, Accuracy: 0.5903200507164001, Val Accuracy: 0.5213329195976257, Time: 26.09 sec\n",
      "Step 139000 - Training Loss: 0.9545985460281372, Val Loss: 1.0466699600219727, Accuracy: 0.5903878211975098, Val Accuracy: 0.5213176608085632, Time: 26.08 sec\n",
      "Step 139100 - Training Loss: 0.9637554287910461, Val Loss: 1.046636700630188, Accuracy: 0.5904605984687805, Val Accuracy: 0.5213024020195007, Time: 25.87 sec\n",
      "Step 139200 - Training Loss: 0.9298872351646423, Val Loss: 1.0466034412384033, Accuracy: 0.5905337929725647, Val Accuracy: 0.521287202835083, Time: 25.99 sec\n",
      "Step 139300 - Training Loss: 0.919574499130249, Val Loss: 1.0465701818466187, Accuracy: 0.5906040072441101, Val Accuracy: 0.5212720632553101, Time: 25.44 sec\n",
      "Step 139400 - Training Loss: 0.9770918488502502, Val Loss: 1.0465370416641235, Accuracy: 0.5906717777252197, Val Accuracy: 0.5212568640708923, Time: 27.44 sec\n",
      "Step 139500 - Training Loss: 0.9276692271232605, Val Loss: 1.0465039014816284, Accuracy: 0.5907410979270935, Val Accuracy: 0.5212417244911194, Time: 25.77 sec\n",
      "Step 139600 - Training Loss: 0.9370458126068115, Val Loss: 1.0464707612991333, Accuracy: 0.5908100605010986, Val Accuracy: 0.5212268829345703, Time: 25.29 sec\n",
      "Step 139700 - Training Loss: 0.9675071239471436, Val Loss: 1.0464377403259277, Accuracy: 0.590877890586853, Val Accuracy: 0.5212118029594421, Time: 25.17 sec\n",
      "Step 139800 - Training Loss: 0.9465970993041992, Val Loss: 1.0464047193527222, Accuracy: 0.5909437537193298, Val Accuracy: 0.5211983919143677, Time: 25.36 sec\n",
      "Step 139900 - Training Loss: 0.8958503603935242, Val Loss: 1.0463718175888062, Accuracy: 0.5910115242004395, Val Accuracy: 0.5211833119392395, Time: 25.24 sec\n",
      "Step 140000 - Training Loss: 0.9456735849380493, Val Loss: 1.0463389158248901, Accuracy: 0.59107905626297, Val Accuracy: 0.5211682915687561, Time: 25.03 sec\n",
      "Step 140100 - Training Loss: 0.9132083058357239, Val Loss: 1.0463060140609741, Accuracy: 0.5911468267440796, Val Accuracy: 0.5211532711982727, Time: 25.74 sec\n",
      "Step 140200 - Training Loss: 0.9285086989402771, Val Loss: 1.0462732315063477, Accuracy: 0.5912147760391235, Val Accuracy: 0.5211383104324341, Time: 25.38 sec\n",
      "Step 140300 - Training Loss: 0.9370408654212952, Val Loss: 1.0462404489517212, Accuracy: 0.5912831425666809, Val Accuracy: 0.5211232900619507, Time: 25.14 sec\n",
      "Step 140400 - Training Loss: 0.9687743186950684, Val Loss: 1.0462076663970947, Accuracy: 0.5913514494895935, Val Accuracy: 0.5211083889007568, Time: 25.28 sec\n",
      "Step 140500 - Training Loss: 0.9833452701568604, Val Loss: 1.0461750030517578, Accuracy: 0.5914196372032166, Val Accuracy: 0.5210934281349182, Time: 25.16 sec\n",
      "Step 140600 - Training Loss: 0.9524723887443542, Val Loss: 1.0461424589157104, Accuracy: 0.5914860963821411, Val Accuracy: 0.5210785269737244, Time: 25.13 sec\n",
      "Step 140700 - Training Loss: 0.9295846819877625, Val Loss: 1.0461097955703735, Accuracy: 0.5915530920028687, Val Accuracy: 0.5210636854171753, Time: 25.48 sec\n",
      "Step 140800 - Training Loss: 0.9496890902519226, Val Loss: 1.0460772514343262, Accuracy: 0.591620147228241, Val Accuracy: 0.5210487842559814, Time: 25.09 sec\n",
      "Step 140900 - Training Loss: 0.9576793313026428, Val Loss: 1.0460448265075684, Accuracy: 0.5916858911514282, Val Accuracy: 0.5210339426994324, Time: 25.24 sec\n",
      "Step 141000 - Training Loss: 0.9793173670768738, Val Loss: 1.0460124015808105, Accuracy: 0.5917514562606812, Val Accuracy: 0.5210191607475281, Time: 25.25 sec\n",
      "Step 141100 - Training Loss: 0.9422582983970642, Val Loss: 1.0459799766540527, Accuracy: 0.5918158292770386, Val Accuracy: 0.521004319190979, Time: 25.34 sec\n",
      "Step 141200 - Training Loss: 0.9662815928459167, Val Loss: 1.0459476709365845, Accuracy: 0.5918830037117004, Val Accuracy: 0.5209895372390747, Time: 25.78 sec\n",
      "Step 141300 - Training Loss: 0.9708910584449768, Val Loss: 1.0459153652191162, Accuracy: 0.5919503569602966, Val Accuracy: 0.5209748148918152, Time: 25.14 sec\n",
      "Step 141400 - Training Loss: 0.9333330988883972, Val Loss: 1.045883059501648, Accuracy: 0.5920150876045227, Val Accuracy: 0.5209600925445557, Time: 25.21 sec\n",
      "Step 141500 - Training Loss: 0.9560335874557495, Val Loss: 1.0458508729934692, Accuracy: 0.5920827388763428, Val Accuracy: 0.5209453701972961, Time: 25.12 sec\n",
      "Step 141600 - Training Loss: 0.9306811094284058, Val Loss: 1.0458186864852905, Accuracy: 0.5921477675437927, Val Accuracy: 0.5209306478500366, Time: 25.11 sec\n",
      "Step 141700 - Training Loss: 0.9309011697769165, Val Loss: 1.0457866191864014, Accuracy: 0.5922136306762695, Val Accuracy: 0.5209159851074219, Time: 25.40 sec\n",
      "Step 141800 - Training Loss: 0.9756739139556885, Val Loss: 1.0457544326782227, Accuracy: 0.5922801494598389, Val Accuracy: 0.5209013223648071, Time: 25.14 sec\n",
      "Step 141900 - Training Loss: 0.9318041205406189, Val Loss: 1.045722484588623, Accuracy: 0.5923468470573425, Val Accuracy: 0.5208867192268372, Time: 25.61 sec\n",
      "Step 142000 - Training Loss: 0.9498569965362549, Val Loss: 1.0456904172897339, Accuracy: 0.592414379119873, Val Accuracy: 0.5208720564842224, Time: 25.35 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 142100 - Training Loss: 0.9477684497833252, Val Loss: 1.0456584692001343, Accuracy: 0.5924813747406006, Val Accuracy: 0.5208575129508972, Time: 25.34 sec\n",
      "Step 142200 - Training Loss: 0.9702295064926147, Val Loss: 1.0456266403198242, Accuracy: 0.5925482511520386, Val Accuracy: 0.5208429098129272, Time: 25.13 sec\n",
      "Step 142300 - Training Loss: 0.9530181884765625, Val Loss: 1.0455948114395142, Accuracy: 0.5926133394241333, Val Accuracy: 0.520828366279602, Time: 25.32 sec\n",
      "Step 142400 - Training Loss: 0.9562054872512817, Val Loss: 1.045562982559204, Accuracy: 0.5926792025566101, Val Accuracy: 0.5208138227462769, Time: 25.75 sec\n",
      "Step 142500 - Training Loss: 0.9318967461585999, Val Loss: 1.045531153678894, Accuracy: 0.5927433371543884, Val Accuracy: 0.5207993388175964, Time: 25.58 sec\n",
      "Step 142600 - Training Loss: 0.9383410215377808, Val Loss: 1.0454994440078735, Accuracy: 0.592806875705719, Val Accuracy: 0.520784854888916, Time: 25.23 sec\n",
      "Step 142700 - Training Loss: 0.952532947063446, Val Loss: 1.045467734336853, Accuracy: 0.5928708910942078, Val Accuracy: 0.5207703709602356, Time: 25.10 sec\n",
      "Step 142800 - Training Loss: 0.9413275718688965, Val Loss: 1.045436143875122, Accuracy: 0.5929364562034607, Val Accuracy: 0.5207558870315552, Time: 25.27 sec\n",
      "Step 142900 - Training Loss: 0.9603047370910645, Val Loss: 1.0454045534133911, Accuracy: 0.5930009484291077, Val Accuracy: 0.5207415223121643, Time: 25.63 sec\n",
      "Step 143000 - Training Loss: 0.9519676566123962, Val Loss: 1.0453729629516602, Accuracy: 0.5930661559104919, Val Accuracy: 0.5207270979881287, Time: 25.04 sec\n",
      "Step 143100 - Training Loss: 0.9251629710197449, Val Loss: 1.0453414916992188, Accuracy: 0.5931311249732971, Val Accuracy: 0.5207127332687378, Time: 25.75 sec\n",
      "Step 143200 - Training Loss: 0.9732181429862976, Val Loss: 1.0453100204467773, Accuracy: 0.5931951403617859, Val Accuracy: 0.5206983685493469, Time: 25.39 sec\n",
      "Step 143300 - Training Loss: 0.9491122364997864, Val Loss: 1.0452786684036255, Accuracy: 0.5932590365409851, Val Accuracy: 0.520684003829956, Time: 25.36 sec\n",
      "Step 143400 - Training Loss: 0.9145662188529968, Val Loss: 1.0452473163604736, Accuracy: 0.5933248400688171, Val Accuracy: 0.5206696391105652, Time: 25.15 sec\n",
      "Step 143500 - Training Loss: 0.9571075439453125, Val Loss: 1.0452159643173218, Accuracy: 0.5933898687362671, Val Accuracy: 0.5206553339958191, Time: 25.65 sec\n",
      "Step 143600 - Training Loss: 0.908879280090332, Val Loss: 1.04518461227417, Accuracy: 0.5934539437294006, Val Accuracy: 0.5206410884857178, Time: 25.65 sec\n",
      "Step 143700 - Training Loss: 0.9831801652908325, Val Loss: 1.0451533794403076, Accuracy: 0.5935185551643372, Val Accuracy: 0.5206267833709717, Time: 25.32 sec\n",
      "Step 143800 - Training Loss: 0.9590182304382324, Val Loss: 1.0451222658157349, Accuracy: 0.5935823917388916, Val Accuracy: 0.5206125378608704, Time: 26.02 sec\n",
      "Step 143900 - Training Loss: 1.0225495100021362, Val Loss: 1.0450910329818726, Accuracy: 0.5936470031738281, Val Accuracy: 0.520598292350769, Time: 25.01 sec\n",
      "Step 144000 - Training Loss: 0.9442628026008606, Val Loss: 1.0450599193572998, Accuracy: 0.5937108993530273, Val Accuracy: 0.5205841064453125, Time: 25.66 sec\n",
      "Step 144100 - Training Loss: 0.9331724643707275, Val Loss: 1.0450289249420166, Accuracy: 0.5937749743461609, Val Accuracy: 0.520569920539856, Time: 25.27 sec\n",
      "Step 144200 - Training Loss: 0.9491921067237854, Val Loss: 1.0449978113174438, Accuracy: 0.5938370823860168, Val Accuracy: 0.5205557346343994, Time: 25.63 sec\n",
      "Step 144300 - Training Loss: 0.9479223489761353, Val Loss: 1.0449669361114502, Accuracy: 0.5939010977745056, Val Accuracy: 0.5205416083335876, Time: 25.35 sec\n",
      "Step 144400 - Training Loss: 0.9566653966903687, Val Loss: 1.044935941696167, Accuracy: 0.5939663052558899, Val Accuracy: 0.5205274224281311, Time: 25.50 sec\n",
      "Step 144500 - Training Loss: 0.9784100651741028, Val Loss: 1.0449050664901733, Accuracy: 0.5940306186676025, Val Accuracy: 0.5205133557319641, Time: 25.27 sec\n",
      "Step 144600 - Training Loss: 0.9819434285163879, Val Loss: 1.0448741912841797, Accuracy: 0.594094455242157, Val Accuracy: 0.5204992294311523, Time: 25.71 sec\n",
      "Step 144700 - Training Loss: 0.9228023886680603, Val Loss: 1.044843316078186, Accuracy: 0.5941568613052368, Val Accuracy: 0.5204851627349854, Time: 26.09 sec\n",
      "Step 144800 - Training Loss: 0.960666298866272, Val Loss: 1.044812560081482, Accuracy: 0.5942202210426331, Val Accuracy: 0.5204710960388184, Time: 25.48 sec\n",
      "Step 144900 - Training Loss: 0.9291154146194458, Val Loss: 1.0447819232940674, Accuracy: 0.5942841172218323, Val Accuracy: 0.5204570889472961, Time: 25.37 sec\n",
      "Step 145000 - Training Loss: 0.9242722392082214, Val Loss: 1.0447511672973633, Accuracy: 0.594346821308136, Val Accuracy: 0.5204430222511292, Time: 25.72 sec\n",
      "Step 145100 - Training Loss: 0.9832319021224976, Val Loss: 1.0447205305099487, Accuracy: 0.5944111347198486, Val Accuracy: 0.5204290747642517, Time: 25.28 sec\n",
      "Step 145200 - Training Loss: 1.0085644721984863, Val Loss: 1.0446898937225342, Accuracy: 0.5944724678993225, Val Accuracy: 0.5204150676727295, Time: 25.72 sec\n",
      "Step 145300 - Training Loss: 0.9596471786499023, Val Loss: 1.0446593761444092, Accuracy: 0.5945366621017456, Val Accuracy: 0.520401120185852, Time: 25.34 sec\n",
      "Step 145400 - Training Loss: 0.9630682468414307, Val Loss: 1.0446288585662842, Accuracy: 0.5946040153503418, Val Accuracy: 0.5203871726989746, Time: 25.86 sec\n",
      "Step 145500 - Training Loss: 0.97136390209198, Val Loss: 1.0445983409881592, Accuracy: 0.594667375087738, Val Accuracy: 0.5203732252120972, Time: 25.77 sec\n",
      "Step 145600 - Training Loss: 0.9860014319419861, Val Loss: 1.0445679426193237, Accuracy: 0.5947301983833313, Val Accuracy: 0.5203593373298645, Time: 25.54 sec\n",
      "Step 145700 - Training Loss: 0.9583625793457031, Val Loss: 1.0445375442504883, Accuracy: 0.5947945713996887, Val Accuracy: 0.5203454494476318, Time: 25.44 sec\n",
      "Step 145800 - Training Loss: 0.945865273475647, Val Loss: 1.0445071458816528, Accuracy: 0.5948583483695984, Val Accuracy: 0.5203315615653992, Time: 25.46 sec\n",
      "Step 145900 - Training Loss: 0.9264490008354187, Val Loss: 1.044476866722107, Accuracy: 0.5949207544326782, Val Accuracy: 0.5203177332878113, Time: 25.70 sec\n",
      "Step 146000 - Training Loss: 0.9602451324462891, Val Loss: 1.044446587562561, Accuracy: 0.5949822068214417, Val Accuracy: 0.5203039050102234, Time: 25.70 sec\n",
      "Step 146100 - Training Loss: 0.9122917056083679, Val Loss: 1.0444164276123047, Accuracy: 0.5950455069541931, Val Accuracy: 0.5202901363372803, Time: 25.47 sec\n",
      "Step 146200 - Training Loss: 0.9305709004402161, Val Loss: 1.0443861484527588, Accuracy: 0.5951085686683655, Val Accuracy: 0.5202763080596924, Time: 25.63 sec\n",
      "Step 146300 - Training Loss: 0.9752026200294495, Val Loss: 1.044356107711792, Accuracy: 0.5951709151268005, Val Accuracy: 0.5202625393867493, Time: 25.94 sec\n",
      "Step 146400 - Training Loss: 0.9928466081619263, Val Loss: 1.0443259477615356, Accuracy: 0.5952322483062744, Val Accuracy: 0.5202487707138062, Time: 26.15 sec\n",
      "Step 146500 - Training Loss: 0.9167268872261047, Val Loss: 1.0442959070205688, Accuracy: 0.5952934622764587, Val Accuracy: 0.5202350616455078, Time: 25.58 sec\n",
      "Step 146600 - Training Loss: 0.9175701141357422, Val Loss: 1.044265866279602, Accuracy: 0.5953556895256042, Val Accuracy: 0.5202213525772095, Time: 25.61 sec\n",
      "Step 146700 - Training Loss: 0.9707802534103394, Val Loss: 1.0442358255386353, Accuracy: 0.595417320728302, Val Accuracy: 0.5202076435089111, Time: 26.25 sec\n",
      "Step 146800 - Training Loss: 0.9775465130805969, Val Loss: 1.044205904006958, Accuracy: 0.5954805016517639, Val Accuracy: 0.5201939940452576, Time: 25.71 sec\n",
      "Step 146900 - Training Loss: 0.9677484631538391, Val Loss: 1.0441759824752808, Accuracy: 0.5955427289009094, Val Accuracy: 0.5201802849769592, Time: 25.68 sec\n",
      "Step 147000 - Training Loss: 0.9293989539146423, Val Loss: 1.044146180152893, Accuracy: 0.595604658126831, Val Accuracy: 0.5201666951179504, Time: 25.70 sec\n",
      "Step 147100 - Training Loss: 0.946533203125, Val Loss: 1.0441163778305054, Accuracy: 0.5956668257713318, Val Accuracy: 0.5201530456542969, Time: 25.18 sec\n",
      "Step 147200 - Training Loss: 0.9344465136528015, Val Loss: 1.0440865755081177, Accuracy: 0.5957287549972534, Val Accuracy: 0.5201394557952881, Time: 26.01 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 147300 - Training Loss: 0.9606539607048035, Val Loss: 1.04405677318573, Accuracy: 0.595789909362793, Val Accuracy: 0.5201258659362793, Time: 25.29 sec\n",
      "Step 147400 - Training Loss: 0.9737986326217651, Val Loss: 1.0440270900726318, Accuracy: 0.595851480960846, Val Accuracy: 0.5201122760772705, Time: 25.34 sec\n",
      "Step 147500 - Training Loss: 0.9482858777046204, Val Loss: 1.0439974069595337, Accuracy: 0.5959125757217407, Val Accuracy: 0.5200987458229065, Time: 25.67 sec\n",
      "Step 147600 - Training Loss: 0.9574083685874939, Val Loss: 1.043967843055725, Accuracy: 0.5959736704826355, Val Accuracy: 0.5200852155685425, Time: 25.65 sec\n",
      "Step 147700 - Training Loss: 0.9668422341346741, Val Loss: 1.0439382791519165, Accuracy: 0.5960354208946228, Val Accuracy: 0.5200716853141785, Time: 25.62 sec\n",
      "Step 147800 - Training Loss: 0.935003936290741, Val Loss: 1.043908715248108, Accuracy: 0.5960971117019653, Val Accuracy: 0.5200582146644592, Time: 25.70 sec\n",
      "Step 147900 - Training Loss: 1.0016103982925415, Val Loss: 1.0438792705535889, Accuracy: 0.5961588025093079, Val Accuracy: 0.520045280456543, Time: 25.70 sec\n",
      "Step 148000 - Training Loss: 0.9437294602394104, Val Loss: 1.0438497066497803, Accuracy: 0.596220076084137, Val Accuracy: 0.5200318098068237, Time: 25.90 sec\n",
      "Step 148100 - Training Loss: 0.9345350861549377, Val Loss: 1.0438203811645508, Accuracy: 0.5962822437286377, Val Accuracy: 0.5200183987617493, Time: 25.70 sec\n",
      "Step 148200 - Training Loss: 0.9291517734527588, Val Loss: 1.0437909364700317, Accuracy: 0.5963422656059265, Val Accuracy: 0.52000492811203, Time: 25.42 sec\n",
      "Step 148300 - Training Loss: 0.9465010166168213, Val Loss: 1.0437616109848022, Accuracy: 0.5964025855064392, Val Accuracy: 0.5199915766716003, Time: 25.60 sec\n",
      "Step 148400 - Training Loss: 0.9593715071678162, Val Loss: 1.0437322854995728, Accuracy: 0.5964635610580444, Val Accuracy: 0.5199781656265259, Time: 25.96 sec\n",
      "Step 148500 - Training Loss: 0.963546872138977, Val Loss: 1.0437030792236328, Accuracy: 0.5965238809585571, Val Accuracy: 0.5199648141860962, Time: 25.85 sec\n",
      "Step 148600 - Training Loss: 0.9830682873725891, Val Loss: 1.0436737537384033, Accuracy: 0.5965843200683594, Val Accuracy: 0.5199514627456665, Time: 26.00 sec\n",
      "Step 148700 - Training Loss: 0.9267358183860779, Val Loss: 1.043644666671753, Accuracy: 0.5966469645500183, Val Accuracy: 0.5199381113052368, Time: 25.83 sec\n",
      "Step 148800 - Training Loss: 0.9260872602462769, Val Loss: 1.043615460395813, Accuracy: 0.5967088341712952, Val Accuracy: 0.5199248194694519, Time: 25.52 sec\n",
      "Step 148900 - Training Loss: 0.9266036748886108, Val Loss: 1.0435863733291626, Accuracy: 0.5967699885368347, Val Accuracy: 0.5199114680290222, Time: 26.38 sec\n",
      "Step 149000 - Training Loss: 0.963767409324646, Val Loss: 1.0435572862625122, Accuracy: 0.5968318581581116, Val Accuracy: 0.5198982357978821, Time: 25.83 sec\n",
      "Step 149100 - Training Loss: 0.9241208434104919, Val Loss: 1.0435281991958618, Accuracy: 0.5968939065933228, Val Accuracy: 0.5198849439620972, Time: 25.74 sec\n",
      "Step 149200 - Training Loss: 0.9265960454940796, Val Loss: 1.043499231338501, Accuracy: 0.5969541668891907, Val Accuracy: 0.519871711730957, Time: 25.74 sec\n",
      "Step 149300 - Training Loss: 0.9379814267158508, Val Loss: 1.0434702634811401, Accuracy: 0.5970147252082825, Val Accuracy: 0.5198584794998169, Time: 25.43 sec\n",
      "Step 149400 - Training Loss: 0.9692057967185974, Val Loss: 1.0434414148330688, Accuracy: 0.5970749258995056, Val Accuracy: 0.5198452472686768, Time: 25.84 sec\n",
      "Step 149500 - Training Loss: 0.9304021596908569, Val Loss: 1.0434125661849976, Accuracy: 0.5971372127532959, Val Accuracy: 0.5198320746421814, Time: 26.17 sec\n",
      "Step 149600 - Training Loss: 0.9267086386680603, Val Loss: 1.0433837175369263, Accuracy: 0.5971983075141907, Val Accuracy: 0.519818902015686, Time: 25.40 sec\n",
      "Step 149700 - Training Loss: 0.9480457305908203, Val Loss: 1.043354868888855, Accuracy: 0.5972575545310974, Val Accuracy: 0.5198057293891907, Time: 25.18 sec\n",
      "Step 149800 - Training Loss: 0.9255620837211609, Val Loss: 1.0433261394500732, Accuracy: 0.5973174571990967, Val Accuracy: 0.5197926163673401, Time: 25.69 sec\n",
      "Step 149900 - Training Loss: 0.9563249945640564, Val Loss: 1.0432974100112915, Accuracy: 0.59737628698349, Val Accuracy: 0.5197795033454895, Time: 25.68 sec\n",
      "Step 150000 - Training Loss: 0.9678695201873779, Val Loss: 1.0432686805725098, Accuracy: 0.5974348187446594, Val Accuracy: 0.5197663903236389, Time: 26.26 sec\n",
      "Step 150100 - Training Loss: 0.9547642469406128, Val Loss: 1.0432400703430176, Accuracy: 0.5974938869476318, Val Accuracy: 0.5197532773017883, Time: 26.23 sec\n",
      "Step 150200 - Training Loss: 0.9262200593948364, Val Loss: 1.0432114601135254, Accuracy: 0.5975523591041565, Val Accuracy: 0.5197402238845825, Time: 25.68 sec\n",
      "Step 150300 - Training Loss: 0.928473174571991, Val Loss: 1.0431828498840332, Accuracy: 0.5976120829582214, Val Accuracy: 0.5197271704673767, Time: 25.36 sec\n",
      "Step 150400 - Training Loss: 0.9816107153892517, Val Loss: 1.0431543588638306, Accuracy: 0.597672164440155, Val Accuracy: 0.5197141170501709, Time: 25.52 sec\n",
      "Step 150500 - Training Loss: 0.9451046586036682, Val Loss: 1.043125867843628, Accuracy: 0.5977321267127991, Val Accuracy: 0.5197011232376099, Time: 25.85 sec\n",
      "Step 150600 - Training Loss: 0.9506905674934387, Val Loss: 1.0430973768234253, Accuracy: 0.5977906584739685, Val Accuracy: 0.5196881294250488, Time: 26.58 sec\n",
      "Step 150700 - Training Loss: 0.9477939009666443, Val Loss: 1.0430690050125122, Accuracy: 0.5978493690490723, Val Accuracy: 0.5196751356124878, Time: 25.83 sec\n",
      "Step 150800 - Training Loss: 0.9118297100067139, Val Loss: 1.0430405139923096, Accuracy: 0.5979082584381104, Val Accuracy: 0.5196621417999268, Time: 26.48 sec\n",
      "Step 150900 - Training Loss: 0.9250979423522949, Val Loss: 1.043012261390686, Accuracy: 0.5979672074317932, Val Accuracy: 0.5196492075920105, Time: 26.35 sec\n",
      "Step 151000 - Training Loss: 0.9556331634521484, Val Loss: 1.042983889579773, Accuracy: 0.5980254411697388, Val Accuracy: 0.5196362733840942, Time: 25.35 sec\n",
      "Step 151100 - Training Loss: 0.965437114238739, Val Loss: 1.0429556369781494, Accuracy: 0.5980831980705261, Val Accuracy: 0.519623339176178, Time: 25.50 sec\n",
      "Step 151200 - Training Loss: 0.9390791654586792, Val Loss: 1.0429273843765259, Accuracy: 0.598142683506012, Val Accuracy: 0.5196104645729065, Time: 25.53 sec\n",
      "Step 151300 - Training Loss: 0.927489697933197, Val Loss: 1.042899250984192, Accuracy: 0.5982014536857605, Val Accuracy: 0.519597589969635, Time: 25.49 sec\n",
      "Step 151400 - Training Loss: 0.9769077897071838, Val Loss: 1.0428709983825684, Accuracy: 0.5982602834701538, Val Accuracy: 0.5195847153663635, Time: 25.20 sec\n",
      "Step 151500 - Training Loss: 0.9616067409515381, Val Loss: 1.0428428649902344, Accuracy: 0.5983201265335083, Val Accuracy: 0.519571840763092, Time: 25.65 sec\n",
      "Step 151600 - Training Loss: 0.9637346267700195, Val Loss: 1.04281485080719, Accuracy: 0.5983793139457703, Val Accuracy: 0.5195590257644653, Time: 25.90 sec\n",
      "Step 151700 - Training Loss: 0.9393341541290283, Val Loss: 1.0427868366241455, Accuracy: 0.5984376072883606, Val Accuracy: 0.5195462107658386, Time: 25.87 sec\n",
      "Step 151800 - Training Loss: 0.9140565395355225, Val Loss: 1.042758822441101, Accuracy: 0.5984976887702942, Val Accuracy: 0.5195334553718567, Time: 25.53 sec\n",
      "Step 151900 - Training Loss: 0.9477752447128296, Val Loss: 1.0427308082580566, Accuracy: 0.5985568761825562, Val Accuracy: 0.51952064037323, Time: 25.78 sec\n",
      "Step 152000 - Training Loss: 0.9717425107955933, Val Loss: 1.0427027940750122, Accuracy: 0.598618745803833, Val Accuracy: 0.519507884979248, Time: 25.87 sec\n",
      "Step 152100 - Training Loss: 0.9308956861495972, Val Loss: 1.0426748991012573, Accuracy: 0.5986776351928711, Val Accuracy: 0.5194951295852661, Time: 25.85 sec\n",
      "Step 152200 - Training Loss: 0.9684901833534241, Val Loss: 1.042647123336792, Accuracy: 0.5987365245819092, Val Accuracy: 0.5194823741912842, Time: 25.93 sec\n",
      "Step 152300 - Training Loss: 0.950759768486023, Val Loss: 1.042619228363037, Accuracy: 0.5987987518310547, Val Accuracy: 0.519469678401947, Time: 25.58 sec\n",
      "Step 152400 - Training Loss: 0.9292276501655579, Val Loss: 1.0425914525985718, Accuracy: 0.5988584160804749, Val Accuracy: 0.5194569826126099, Time: 25.81 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 152500 - Training Loss: 0.9470939040184021, Val Loss: 1.0425636768341064, Accuracy: 0.5989146828651428, Val Accuracy: 0.5194442868232727, Time: 26.07 sec\n",
      "Step 152600 - Training Loss: 0.9287171959877014, Val Loss: 1.0425360202789307, Accuracy: 0.5989734530448914, Val Accuracy: 0.5194316506385803, Time: 26.16 sec\n",
      "Step 152700 - Training Loss: 0.9346131682395935, Val Loss: 1.0425082445144653, Accuracy: 0.5990307331085205, Val Accuracy: 0.5194190144538879, Time: 25.50 sec\n",
      "Step 152800 - Training Loss: 0.9625248908996582, Val Loss: 1.0424805879592896, Accuracy: 0.5990914702415466, Val Accuracy: 0.5194063782691956, Time: 25.40 sec\n",
      "Step 152900 - Training Loss: 0.9859521985054016, Val Loss: 1.0424530506134033, Accuracy: 0.599149763584137, Val Accuracy: 0.5193937420845032, Time: 25.88 sec\n",
      "Step 153000 - Training Loss: 0.912903904914856, Val Loss: 1.0424253940582275, Accuracy: 0.599209725856781, Val Accuracy: 0.5193811655044556, Time: 26.84 sec\n",
      "Step 153100 - Training Loss: 0.9463821649551392, Val Loss: 1.0423978567123413, Accuracy: 0.599266767501831, Val Accuracy: 0.519368588924408, Time: 25.50 sec\n",
      "Step 153200 - Training Loss: 0.9228643774986267, Val Loss: 1.0423704385757446, Accuracy: 0.5993252992630005, Val Accuracy: 0.5193560123443604, Time: 25.58 sec\n",
      "Step 153300 - Training Loss: 0.9707030057907104, Val Loss: 1.0423429012298584, Accuracy: 0.5993847250938416, Val Accuracy: 0.5193434357643127, Time: 25.69 sec\n",
      "Step 153400 - Training Loss: 0.924561083316803, Val Loss: 1.0423154830932617, Accuracy: 0.5994426012039185, Val Accuracy: 0.5193309187889099, Time: 25.81 sec\n",
      "Step 153500 - Training Loss: 0.9241034984588623, Val Loss: 1.042288064956665, Accuracy: 0.5995003581047058, Val Accuracy: 0.5193184018135071, Time: 25.47 sec\n",
      "Step 153600 - Training Loss: 0.9458774328231812, Val Loss: 1.042260766029358, Accuracy: 0.5995580554008484, Val Accuracy: 0.5193058848381042, Time: 25.21 sec\n",
      "Step 153700 - Training Loss: 0.9826393723487854, Val Loss: 1.0422333478927612, Accuracy: 0.5996166467666626, Val Accuracy: 0.5192934274673462, Time: 25.86 sec\n",
      "Step 153800 - Training Loss: 0.9609189033508301, Val Loss: 1.042206048965454, Accuracy: 0.5996738076210022, Val Accuracy: 0.5192809700965881, Time: 25.55 sec\n",
      "Step 153900 - Training Loss: 0.9530779123306274, Val Loss: 1.0421788692474365, Accuracy: 0.599730908870697, Val Accuracy: 0.5192685127258301, Time: 25.10 sec\n",
      "Step 154000 - Training Loss: 0.9438520669937134, Val Loss: 1.0421515703201294, Accuracy: 0.5997875332832336, Val Accuracy: 0.519256055355072, Time: 25.69 sec\n",
      "Step 154100 - Training Loss: 0.9410836100578308, Val Loss: 1.0421243906021118, Accuracy: 0.5998455882072449, Val Accuracy: 0.5192436575889587, Time: 25.41 sec\n",
      "Step 154200 - Training Loss: 0.9238677620887756, Val Loss: 1.0420972108840942, Accuracy: 0.59990394115448, Val Accuracy: 0.5192312598228455, Time: 25.87 sec\n",
      "Step 154300 - Training Loss: 0.9781425595283508, Val Loss: 1.0420701503753662, Accuracy: 0.5999611616134644, Val Accuracy: 0.5192188620567322, Time: 25.54 sec\n",
      "Step 154400 - Training Loss: 0.9545142650604248, Val Loss: 1.0420430898666382, Accuracy: 0.6000198721885681, Val Accuracy: 0.5192064642906189, Time: 25.41 sec\n",
      "Step 154500 - Training Loss: 0.9468070864677429, Val Loss: 1.0420160293579102, Accuracy: 0.6000797748565674, Val Accuracy: 0.5191941261291504, Time: 25.41 sec\n",
      "Step 154600 - Training Loss: 0.9626356363296509, Val Loss: 1.0419889688491821, Accuracy: 0.6001360416412354, Val Accuracy: 0.5191817879676819, Time: 25.24 sec\n",
      "Step 154700 - Training Loss: 0.9485242962837219, Val Loss: 1.0419620275497437, Accuracy: 0.6001927256584167, Val Accuracy: 0.5191694498062134, Time: 25.36 sec\n",
      "Step 154800 - Training Loss: 0.9303487539291382, Val Loss: 1.0419350862503052, Accuracy: 0.6002500057220459, Val Accuracy: 0.5191571116447449, Time: 25.44 sec\n",
      "Step 154900 - Training Loss: 0.972291886806488, Val Loss: 1.0419081449508667, Accuracy: 0.6003067493438721, Val Accuracy: 0.5191448330879211, Time: 25.29 sec\n",
      "Step 155000 - Training Loss: 0.9306468367576599, Val Loss: 1.0418813228607178, Accuracy: 0.6003629565238953, Val Accuracy: 0.5191325545310974, Time: 25.83 sec\n",
      "Step 155100 - Training Loss: 0.9552903771400452, Val Loss: 1.0418545007705688, Accuracy: 0.6004196405410767, Val Accuracy: 0.5191203355789185, Time: 25.82 sec\n",
      "Step 155200 - Training Loss: 0.9305323958396912, Val Loss: 1.04182767868042, Accuracy: 0.6004782915115356, Val Accuracy: 0.5191080570220947, Time: 25.55 sec\n",
      "Step 155300 - Training Loss: 0.9539937376976013, Val Loss: 1.041800856590271, Accuracy: 0.6005342602729797, Val Accuracy: 0.5190958380699158, Time: 25.82 sec\n",
      "Step 155400 - Training Loss: 0.9542964696884155, Val Loss: 1.0417741537094116, Accuracy: 0.6005910038948059, Val Accuracy: 0.5190836191177368, Time: 25.88 sec\n",
      "Step 155500 - Training Loss: 1.0155218839645386, Val Loss: 1.0417474508285522, Accuracy: 0.6006464958190918, Val Accuracy: 0.5190714001655579, Time: 25.64 sec\n",
      "Step 155600 - Training Loss: 0.9344356060028076, Val Loss: 1.0417207479476929, Accuracy: 0.6007016897201538, Val Accuracy: 0.5190592408180237, Time: 27.35 sec\n",
      "Step 155700 - Training Loss: 0.9694434404373169, Val Loss: 1.041694164276123, Accuracy: 0.6007576584815979, Val Accuracy: 0.5190470814704895, Time: 26.24 sec\n",
      "Step 155800 - Training Loss: 0.9402233958244324, Val Loss: 1.0416674613952637, Accuracy: 0.6008137464523315, Val Accuracy: 0.5190349221229553, Time: 25.40 sec\n",
      "Step 155900 - Training Loss: 0.9720343351364136, Val Loss: 1.0416409969329834, Accuracy: 0.6008713245391846, Val Accuracy: 0.5190227627754211, Time: 25.71 sec\n",
      "Step 156000 - Training Loss: 0.9623928070068359, Val Loss: 1.0416144132614136, Accuracy: 0.600926399230957, Val Accuracy: 0.5190111398696899, Time: 25.94 sec\n",
      "Step 156100 - Training Loss: 0.928340494632721, Val Loss: 1.0415879487991333, Accuracy: 0.6009814739227295, Val Accuracy: 0.5189990401268005, Time: 26.02 sec\n",
      "Step 156200 - Training Loss: 0.9577785134315491, Val Loss: 1.041561484336853, Accuracy: 0.6010376214981079, Val Accuracy: 0.5189869403839111, Time: 26.49 sec\n",
      "Step 156300 - Training Loss: 0.9594436883926392, Val Loss: 1.0415350198745728, Accuracy: 0.6010947823524475, Val Accuracy: 0.5189749002456665, Time: 26.04 sec\n",
      "Step 156400 - Training Loss: 0.9361276626586914, Val Loss: 1.041508674621582, Accuracy: 0.6011514067649841, Val Accuracy: 0.5189628005027771, Time: 25.79 sec\n",
      "Step 156500 - Training Loss: 0.9478896260261536, Val Loss: 1.0414822101593018, Accuracy: 0.6012101769447327, Val Accuracy: 0.5189507603645325, Time: 26.68 sec\n",
      "Step 156600 - Training Loss: 0.9408012628555298, Val Loss: 1.041455864906311, Accuracy: 0.6012638807296753, Val Accuracy: 0.5189387202262878, Time: 26.83 sec\n",
      "Step 156700 - Training Loss: 0.947277307510376, Val Loss: 1.0414296388626099, Accuracy: 0.6013200879096985, Val Accuracy: 0.518926739692688, Time: 25.64 sec\n",
      "Step 156800 - Training Loss: 0.9703230857849121, Val Loss: 1.0414032936096191, Accuracy: 0.6013780236244202, Val Accuracy: 0.5189146995544434, Time: 25.68 sec\n",
      "Step 156900 - Training Loss: 0.9367597103118896, Val Loss: 1.041377067565918, Accuracy: 0.6014338135719299, Val Accuracy: 0.5189027190208435, Time: 25.61 sec\n",
      "Step 157000 - Training Loss: 1.0094996690750122, Val Loss: 1.0413509607315063, Accuracy: 0.601489245891571, Val Accuracy: 0.5188921689987183, Time: 25.51 sec\n",
      "Step 157100 - Training Loss: 0.9829599857330322, Val Loss: 1.0413247346878052, Accuracy: 0.6015451550483704, Val Accuracy: 0.5188801884651184, Time: 25.71 sec\n",
      "Step 157200 - Training Loss: 0.9730622172355652, Val Loss: 1.0412986278533936, Accuracy: 0.601600706577301, Val Accuracy: 0.5188682675361633, Time: 25.64 sec\n",
      "Step 157300 - Training Loss: 0.9521619081497192, Val Loss: 1.041272521018982, Accuracy: 0.6016576886177063, Val Accuracy: 0.5188563466072083, Time: 25.63 sec\n",
      "Step 157400 - Training Loss: 0.9472955465316772, Val Loss: 1.0412464141845703, Accuracy: 0.6017132997512817, Val Accuracy: 0.5188444256782532, Time: 25.12 sec\n",
      "Step 157500 - Training Loss: 0.9464892745018005, Val Loss: 1.0412204265594482, Accuracy: 0.6017700433731079, Val Accuracy: 0.5188325047492981, Time: 26.20 sec\n",
      "Step 157600 - Training Loss: 0.9554845094680786, Val Loss: 1.0411944389343262, Accuracy: 0.6018257141113281, Val Accuracy: 0.5188206434249878, Time: 25.85 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 157700 - Training Loss: 0.9279627203941345, Val Loss: 1.041168451309204, Accuracy: 0.6018807888031006, Val Accuracy: 0.5188087821006775, Time: 25.54 sec\n",
      "Step 157800 - Training Loss: 0.9858028292655945, Val Loss: 1.041142463684082, Accuracy: 0.6019365191459656, Val Accuracy: 0.5187969207763672, Time: 25.98 sec\n",
      "Step 157900 - Training Loss: 0.9498947858810425, Val Loss: 1.0411165952682495, Accuracy: 0.6019911766052246, Val Accuracy: 0.5187851190567017, Time: 25.94 sec\n",
      "Step 158000 - Training Loss: 0.9740491509437561, Val Loss: 1.041090726852417, Accuracy: 0.6020456552505493, Val Accuracy: 0.5187732577323914, Time: 25.85 sec\n",
      "Step 158100 - Training Loss: 0.9047881960868835, Val Loss: 1.0410648584365845, Accuracy: 0.6021007299423218, Val Accuracy: 0.5187614560127258, Time: 25.58 sec\n",
      "Step 158200 - Training Loss: 0.9302452802658081, Val Loss: 1.0410391092300415, Accuracy: 0.6021544337272644, Val Accuracy: 0.5187496542930603, Time: 25.27 sec\n",
      "Step 158300 - Training Loss: 0.9272121787071228, Val Loss: 1.0410133600234985, Accuracy: 0.6022090911865234, Val Accuracy: 0.5187379121780396, Time: 25.88 sec\n",
      "Step 158400 - Training Loss: 0.9293434619903564, Val Loss: 1.0409876108169556, Accuracy: 0.6022640466690063, Val Accuracy: 0.5187261700630188, Time: 25.44 sec\n",
      "Step 158500 - Training Loss: 0.958271861076355, Val Loss: 1.0409618616104126, Accuracy: 0.6023194193840027, Val Accuracy: 0.518714427947998, Time: 25.57 sec\n",
      "Step 158600 - Training Loss: 0.9389238953590393, Val Loss: 1.0409362316131592, Accuracy: 0.6023738980293274, Val Accuracy: 0.5187026858329773, Time: 25.32 sec\n",
      "Step 158700 - Training Loss: 0.9290713667869568, Val Loss: 1.0409106016159058, Accuracy: 0.6024293303489685, Val Accuracy: 0.5186909437179565, Time: 25.52 sec\n",
      "Step 158800 - Training Loss: 0.9479727745056152, Val Loss: 1.0408849716186523, Accuracy: 0.602484405040741, Val Accuracy: 0.5186792612075806, Time: 25.51 sec\n",
      "Step 158900 - Training Loss: 0.9281617403030396, Val Loss: 1.040859341621399, Accuracy: 0.6025394201278687, Val Accuracy: 0.5186675786972046, Time: 25.58 sec\n",
      "Step 159000 - Training Loss: 0.9719855785369873, Val Loss: 1.040833830833435, Accuracy: 0.6025940179824829, Val Accuracy: 0.5186558961868286, Time: 25.93 sec\n",
      "Step 159100 - Training Loss: 0.9467802047729492, Val Loss: 1.0408083200454712, Accuracy: 0.602648138999939, Val Accuracy: 0.5186442136764526, Time: 26.50 sec\n",
      "Step 159200 - Training Loss: 0.9551605582237244, Val Loss: 1.0407828092575073, Accuracy: 0.6027035713195801, Val Accuracy: 0.5186325907707214, Time: 25.97 sec\n",
      "Step 159300 - Training Loss: 0.9543488025665283, Val Loss: 1.040757417678833, Accuracy: 0.6027588844299316, Val Accuracy: 0.5186209678649902, Time: 25.87 sec\n",
      "Step 159400 - Training Loss: 0.9458855986595154, Val Loss: 1.0407319068908691, Accuracy: 0.6028124094009399, Val Accuracy: 0.518609344959259, Time: 25.27 sec\n",
      "Step 159500 - Training Loss: 0.9129059314727783, Val Loss: 1.0407065153121948, Accuracy: 0.6028664112091064, Val Accuracy: 0.5185977816581726, Time: 25.59 sec\n",
      "Step 159600 - Training Loss: 0.9795044660568237, Val Loss: 1.04068124294281, Accuracy: 0.6029219627380371, Val Accuracy: 0.5185861587524414, Time: 25.54 sec\n",
      "Step 159700 - Training Loss: 0.9689837694168091, Val Loss: 1.0406558513641357, Accuracy: 0.6029782295227051, Val Accuracy: 0.518574595451355, Time: 25.50 sec\n",
      "Step 159800 - Training Loss: 0.9606910943984985, Val Loss: 1.040630578994751, Accuracy: 0.6030338406562805, Val Accuracy: 0.5185630321502686, Time: 25.31 sec\n",
      "Step 159900 - Training Loss: 0.9171910881996155, Val Loss: 1.0406053066253662, Accuracy: 0.603087306022644, Val Accuracy: 0.5185515284538269, Time: 25.52 sec\n",
      "Step 160000 - Training Loss: 0.9417932033538818, Val Loss: 1.0405800342559814, Accuracy: 0.6031408309936523, Val Accuracy: 0.5185399651527405, Time: 25.42 sec\n",
      "Step 160100 - Training Loss: 0.9313451051712036, Val Loss: 1.0405548810958862, Accuracy: 0.6031947731971741, Val Accuracy: 0.5185284614562988, Time: 25.08 sec\n",
      "Step 160200 - Training Loss: 0.9649209380149841, Val Loss: 1.040529727935791, Accuracy: 0.6032505631446838, Val Accuracy: 0.5185169577598572, Time: 25.43 sec\n",
      "Step 160300 - Training Loss: 0.9273353815078735, Val Loss: 1.0405045747756958, Accuracy: 0.603304386138916, Val Accuracy: 0.5185054540634155, Time: 25.84 sec\n",
      "Step 160400 - Training Loss: 0.9382690787315369, Val Loss: 1.0404794216156006, Accuracy: 0.6033579707145691, Val Accuracy: 0.5184940099716187, Time: 25.84 sec\n",
      "Step 160500 - Training Loss: 0.9068887829780579, Val Loss: 1.040454387664795, Accuracy: 0.6034122705459595, Val Accuracy: 0.5184825658798218, Time: 25.58 sec\n",
      "Step 160600 - Training Loss: 0.9472597241401672, Val Loss: 1.0404293537139893, Accuracy: 0.6034663915634155, Val Accuracy: 0.5184711217880249, Time: 25.58 sec\n",
      "Step 160700 - Training Loss: 0.9282811284065247, Val Loss: 1.0404043197631836, Accuracy: 0.6035206913948059, Val Accuracy: 0.518459677696228, Time: 25.65 sec\n",
      "Step 160800 - Training Loss: 0.9851874113082886, Val Loss: 1.0403794050216675, Accuracy: 0.6035751700401306, Val Accuracy: 0.5184482932090759, Time: 25.28 sec\n",
      "Step 160900 - Training Loss: 0.9399471879005432, Val Loss: 1.0403543710708618, Accuracy: 0.6036301851272583, Val Accuracy: 0.518436849117279, Time: 25.29 sec\n",
      "Step 161000 - Training Loss: 0.9411616325378418, Val Loss: 1.0403294563293457, Accuracy: 0.6036853790283203, Val Accuracy: 0.518425464630127, Time: 25.98 sec\n",
      "Step 161100 - Training Loss: 0.950231671333313, Val Loss: 1.0403045415878296, Accuracy: 0.6037387251853943, Val Accuracy: 0.5184140801429749, Time: 25.72 sec\n",
      "Step 161200 - Training Loss: 0.9573459625244141, Val Loss: 1.040279746055603, Accuracy: 0.6037927269935608, Val Accuracy: 0.5184027552604675, Time: 26.08 sec\n",
      "Step 161300 - Training Loss: 0.9185514450073242, Val Loss: 1.0402549505233765, Accuracy: 0.6038456559181213, Val Accuracy: 0.5183914303779602, Time: 25.78 sec\n",
      "Step 161400 - Training Loss: 0.9246212244033813, Val Loss: 1.04023015499115, Accuracy: 0.6039016842842102, Val Accuracy: 0.5183801054954529, Time: 25.55 sec\n",
      "Step 161500 - Training Loss: 0.950793445110321, Val Loss: 1.0402053594589233, Accuracy: 0.6039556860923767, Val Accuracy: 0.5183687806129456, Time: 25.37 sec\n",
      "Step 161600 - Training Loss: 0.9768967032432556, Val Loss: 1.0401805639266968, Accuracy: 0.6040101051330566, Val Accuracy: 0.5183574557304382, Time: 25.20 sec\n",
      "Step 161700 - Training Loss: 0.9555021524429321, Val Loss: 1.0401558876037598, Accuracy: 0.6040657162666321, Val Accuracy: 0.5183461904525757, Time: 25.74 sec\n",
      "Step 161800 - Training Loss: 0.9544877409934998, Val Loss: 1.0401312112808228, Accuracy: 0.6041202545166016, Val Accuracy: 0.5183349251747131, Time: 25.42 sec\n",
      "Step 161900 - Training Loss: 0.9472041726112366, Val Loss: 1.0401065349578857, Accuracy: 0.6041706800460815, Val Accuracy: 0.5183236598968506, Time: 25.29 sec\n",
      "Step 162000 - Training Loss: 0.9500113129615784, Val Loss: 1.0400819778442383, Accuracy: 0.6042218804359436, Val Accuracy: 0.5183129906654358, Time: 25.35 sec\n",
      "Step 162100 - Training Loss: 0.9533717632293701, Val Loss: 1.0400574207305908, Accuracy: 0.6042740345001221, Val Accuracy: 0.518301784992218, Time: 25.03 sec\n",
      "Step 162200 - Training Loss: 0.9586402177810669, Val Loss: 1.0400328636169434, Accuracy: 0.6043274402618408, Val Accuracy: 0.5182905793190002, Time: 24.96 sec\n",
      "Step 162300 - Training Loss: 0.9367908239364624, Val Loss: 1.040008306503296, Accuracy: 0.604378879070282, Val Accuracy: 0.5182793736457825, Time: 25.28 sec\n",
      "Step 162400 - Training Loss: 0.9864200949668884, Val Loss: 1.0399837493896484, Accuracy: 0.6044318079948425, Val Accuracy: 0.5182681679725647, Time: 25.25 sec\n",
      "Step 162500 - Training Loss: 0.9475167393684387, Val Loss: 1.0399593114852905, Accuracy: 0.6044849753379822, Val Accuracy: 0.5182569622993469, Time: 25.32 sec\n",
      "Step 162600 - Training Loss: 0.9504912495613098, Val Loss: 1.0399348735809326, Accuracy: 0.6045371294021606, Val Accuracy: 0.5182458162307739, Time: 25.93 sec\n",
      "Step 162700 - Training Loss: 0.965553879737854, Val Loss: 1.0399105548858643, Accuracy: 0.6045900583267212, Val Accuracy: 0.5182346701622009, Time: 25.61 sec\n",
      "Step 162800 - Training Loss: 0.9393678903579712, Val Loss: 1.0398861169815063, Accuracy: 0.6046431064605713, Val Accuracy: 0.5182235240936279, Time: 26.37 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 162900 - Training Loss: 0.9474643468856812, Val Loss: 1.039861798286438, Accuracy: 0.6046963334083557, Val Accuracy: 0.5182123780250549, Time: 26.20 sec\n",
      "Step 163000 - Training Loss: 0.9653260707855225, Val Loss: 1.0398374795913696, Accuracy: 0.6047495603561401, Val Accuracy: 0.5182012915611267, Time: 25.70 sec\n",
      "Step 163100 - Training Loss: 0.98924320936203, Val Loss: 1.0398131608963013, Accuracy: 0.6048020124435425, Val Accuracy: 0.5181902050971985, Time: 26.06 sec\n",
      "Step 163200 - Training Loss: 0.9909473657608032, Val Loss: 1.0397889614105225, Accuracy: 0.6048527956008911, Val Accuracy: 0.5181791186332703, Time: 25.77 sec\n",
      "Step 163300 - Training Loss: 0.952709436416626, Val Loss: 1.039764642715454, Accuracy: 0.6049030423164368, Val Accuracy: 0.518168032169342, Time: 26.04 sec\n",
      "Step 163400 - Training Loss: 0.9460663795471191, Val Loss: 1.0397404432296753, Accuracy: 0.6049557328224182, Val Accuracy: 0.5181570053100586, Time: 25.75 sec\n",
      "Step 163500 - Training Loss: 0.946697473526001, Val Loss: 1.039716362953186, Accuracy: 0.6050064563751221, Val Accuracy: 0.5181459784507751, Time: 25.87 sec\n",
      "Step 163600 - Training Loss: 0.9503723978996277, Val Loss: 1.0396921634674072, Accuracy: 0.6050585508346558, Val Accuracy: 0.5181349515914917, Time: 25.89 sec\n",
      "Step 163700 - Training Loss: 0.9583759903907776, Val Loss: 1.039668083190918, Accuracy: 0.6051097512245178, Val Accuracy: 0.5181239247322083, Time: 25.41 sec\n",
      "Step 163800 - Training Loss: 0.9757562279701233, Val Loss: 1.0396440029144287, Accuracy: 0.6051616668701172, Val Accuracy: 0.5181128978729248, Time: 25.07 sec\n",
      "Step 163900 - Training Loss: 0.9826933741569519, Val Loss: 1.0396199226379395, Accuracy: 0.6052117943763733, Val Accuracy: 0.5181019306182861, Time: 25.77 sec\n",
      "Step 164000 - Training Loss: 0.9481090307235718, Val Loss: 1.0395959615707397, Accuracy: 0.6052622199058533, Val Accuracy: 0.5180909633636475, Time: 24.92 sec\n",
      "Step 164100 - Training Loss: 0.9424043893814087, Val Loss: 1.0395718812942505, Accuracy: 0.6053125262260437, Val Accuracy: 0.5180799961090088, Time: 25.33 sec\n",
      "Step 164200 - Training Loss: 0.9298294186592102, Val Loss: 1.0395479202270508, Accuracy: 0.6053646802902222, Val Accuracy: 0.5180690288543701, Time: 25.07 sec\n",
      "Step 164300 - Training Loss: 0.9562394618988037, Val Loss: 1.0395240783691406, Accuracy: 0.6054170727729797, Val Accuracy: 0.5180581212043762, Time: 25.27 sec\n",
      "Step 164400 - Training Loss: 0.9332990050315857, Val Loss: 1.039500117301941, Accuracy: 0.6054674386978149, Val Accuracy: 0.5180471539497375, Time: 25.34 sec\n",
      "Step 164500 - Training Loss: 0.9446697235107422, Val Loss: 1.0394762754440308, Accuracy: 0.6055200695991516, Val Accuracy: 0.5180362462997437, Time: 24.87 sec\n",
      "Step 164600 - Training Loss: 0.9471587538719177, Val Loss: 1.0394524335861206, Accuracy: 0.6055693030357361, Val Accuracy: 0.5180253386497498, Time: 25.23 sec\n",
      "Step 164700 - Training Loss: 0.9617601037025452, Val Loss: 1.0394285917282104, Accuracy: 0.6056177616119385, Val Accuracy: 0.5180144906044006, Time: 25.12 sec\n",
      "Step 164800 - Training Loss: 0.936159074306488, Val Loss: 1.0394047498703003, Accuracy: 0.6056704521179199, Val Accuracy: 0.5180036425590515, Time: 25.58 sec\n",
      "Step 164900 - Training Loss: 0.9593821167945862, Val Loss: 1.0393810272216797, Accuracy: 0.6057228446006775, Val Accuracy: 0.5179927349090576, Time: 25.02 sec\n",
      "Step 165000 - Training Loss: 0.9582352638244629, Val Loss: 1.039357304573059, Accuracy: 0.6057757139205933, Val Accuracy: 0.5179818868637085, Time: 25.04 sec\n",
      "Step 165100 - Training Loss: 0.9297307729721069, Val Loss: 1.0393335819244385, Accuracy: 0.6058274507522583, Val Accuracy: 0.5179727077484131, Time: 25.53 sec\n",
      "Step 165200 - Training Loss: 0.954113781452179, Val Loss: 1.0393099784851074, Accuracy: 0.6058780550956726, Val Accuracy: 0.5179619193077087, Time: 25.36 sec\n",
      "Step 165300 - Training Loss: 0.9618855118751526, Val Loss: 1.0392862558364868, Accuracy: 0.6059301495552063, Val Accuracy: 0.5179535150527954, Time: 25.40 sec\n",
      "Step 165400 - Training Loss: 0.950562059879303, Val Loss: 1.0392626523971558, Accuracy: 0.6059809327125549, Val Accuracy: 0.5179427266120911, Time: 25.27 sec\n",
      "Step 165500 - Training Loss: 0.9644994139671326, Val Loss: 1.0392390489578247, Accuracy: 0.6060330271720886, Val Accuracy: 0.5179319381713867, Time: 25.15 sec\n",
      "Step 165600 - Training Loss: 0.9291456937789917, Val Loss: 1.0392154455184937, Accuracy: 0.6060847043991089, Val Accuracy: 0.5179212093353271, Time: 25.65 sec\n",
      "Step 165700 - Training Loss: 0.9819692969322205, Val Loss: 1.0391919612884521, Accuracy: 0.6061348915100098, Val Accuracy: 0.5179104208946228, Time: 24.96 sec\n",
      "Step 165800 - Training Loss: 0.970632791519165, Val Loss: 1.0391684770584106, Accuracy: 0.606184184551239, Val Accuracy: 0.5178996920585632, Time: 25.45 sec\n",
      "Step 165900 - Training Loss: 0.9736965894699097, Val Loss: 1.0391449928283691, Accuracy: 0.6062353849411011, Val Accuracy: 0.5178889632225037, Time: 25.80 sec\n",
      "Step 166000 - Training Loss: 0.9684054851531982, Val Loss: 1.0391215085983276, Accuracy: 0.6062838435173035, Val Accuracy: 0.5178782343864441, Time: 25.59 sec\n",
      "Step 166100 - Training Loss: 0.9872837066650391, Val Loss: 1.0390981435775757, Accuracy: 0.6063345670700073, Val Accuracy: 0.5178675651550293, Time: 25.16 sec\n",
      "Step 166200 - Training Loss: 0.9124737977981567, Val Loss: 1.0390747785568237, Accuracy: 0.6063858270645142, Val Accuracy: 0.5178568363189697, Time: 25.29 sec\n",
      "Step 166300 - Training Loss: 0.9536312818527222, Val Loss: 1.0390514135360718, Accuracy: 0.6064358949661255, Val Accuracy: 0.5178461670875549, Time: 25.47 sec\n",
      "Step 166400 - Training Loss: 0.9367990493774414, Val Loss: 1.0390280485153198, Accuracy: 0.6064872741699219, Val Accuracy: 0.5178354978561401, Time: 25.25 sec\n",
      "Step 166500 - Training Loss: 1.0040162801742554, Val Loss: 1.0390046834945679, Accuracy: 0.6065366864204407, Val Accuracy: 0.5178248882293701, Time: 25.23 sec\n",
      "Step 166600 - Training Loss: 0.9593591094017029, Val Loss: 1.0389814376831055, Accuracy: 0.6065869331359863, Val Accuracy: 0.5178142189979553, Time: 25.15 sec\n",
      "Step 166700 - Training Loss: 0.9284458756446838, Val Loss: 1.038958191871643, Accuracy: 0.6066361665725708, Val Accuracy: 0.5178036093711853, Time: 25.27 sec\n",
      "Step 166800 - Training Loss: 0.9915153384208679, Val Loss: 1.0389349460601807, Accuracy: 0.6066873073577881, Val Accuracy: 0.5177929997444153, Time: 25.53 sec\n",
      "Step 166900 - Training Loss: 0.9744923114776611, Val Loss: 1.0389117002487183, Accuracy: 0.6067368984222412, Val Accuracy: 0.5177823901176453, Time: 25.56 sec\n",
      "Step 167000 - Training Loss: 0.9935542345046997, Val Loss: 1.0388885736465454, Accuracy: 0.6067883372306824, Val Accuracy: 0.5177717804908752, Time: 25.69 sec\n",
      "Step 167100 - Training Loss: 0.958502471446991, Val Loss: 1.0388654470443726, Accuracy: 0.6068382263183594, Val Accuracy: 0.51776123046875, Time: 25.22 sec\n",
      "Step 167200 - Training Loss: 0.9631755352020264, Val Loss: 1.0388423204421997, Accuracy: 0.6068882942199707, Val Accuracy: 0.5177506804466248, Time: 25.06 sec\n",
      "Step 167300 - Training Loss: 0.9614861607551575, Val Loss: 1.0388191938400269, Accuracy: 0.6069369316101074, Val Accuracy: 0.5177401304244995, Time: 25.35 sec\n",
      "Step 167400 - Training Loss: 0.9296500086784363, Val Loss: 1.0387961864471436, Accuracy: 0.6069850325584412, Val Accuracy: 0.5177295804023743, Time: 25.06 sec\n",
      "Step 167500 - Training Loss: 0.9422628879547119, Val Loss: 1.0387731790542603, Accuracy: 0.607033908367157, Val Accuracy: 0.517719030380249, Time: 25.54 sec\n",
      "Step 167600 - Training Loss: 0.9694285988807678, Val Loss: 1.038750171661377, Accuracy: 0.607084333896637, Val Accuracy: 0.5177085399627686, Time: 24.71 sec\n",
      "Step 167700 - Training Loss: 0.9712286591529846, Val Loss: 1.0387271642684937, Accuracy: 0.6071329712867737, Val Accuracy: 0.5176980495452881, Time: 25.35 sec\n",
      "Step 167800 - Training Loss: 0.916205883026123, Val Loss: 1.0387041568756104, Accuracy: 0.6071818470954895, Val Accuracy: 0.5176875591278076, Time: 25.02 sec\n",
      "Step 167900 - Training Loss: 0.9522227048873901, Val Loss: 1.0386812686920166, Accuracy: 0.6072298884391785, Val Accuracy: 0.5176770687103271, Time: 25.40 sec\n",
      "Step 168000 - Training Loss: 0.9124298691749573, Val Loss: 1.0386583805084229, Accuracy: 0.6072784662246704, Val Accuracy: 0.5176665782928467, Time: 25.51 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 168100 - Training Loss: 0.9732562899589539, Val Loss: 1.038635492324829, Accuracy: 0.6073263883590698, Val Accuracy: 0.517656147480011, Time: 25.56 sec\n",
      "Step 168200 - Training Loss: 0.9693083763122559, Val Loss: 1.0386126041412354, Accuracy: 0.6073755025863647, Val Accuracy: 0.5176457166671753, Time: 25.25 sec\n",
      "Step 168300 - Training Loss: 0.9294229745864868, Val Loss: 1.0385898351669312, Accuracy: 0.6074244379997253, Val Accuracy: 0.5176352858543396, Time: 25.64 sec\n",
      "Step 168400 - Training Loss: 0.9396086931228638, Val Loss: 1.038567066192627, Accuracy: 0.6074732542037964, Val Accuracy: 0.5176248550415039, Time: 25.93 sec\n",
      "Step 168500 - Training Loss: 0.9753803014755249, Val Loss: 1.0385442972183228, Accuracy: 0.6075211763381958, Val Accuracy: 0.517614483833313, Time: 25.30 sec\n",
      "Step 168600 - Training Loss: 0.9604955315589905, Val Loss: 1.0385215282440186, Accuracy: 0.607570469379425, Val Accuracy: 0.5176040530204773, Time: 25.62 sec\n",
      "Step 168700 - Training Loss: 1.0018513202667236, Val Loss: 1.038498878479004, Accuracy: 0.6076188087463379, Val Accuracy: 0.5175936818122864, Time: 25.72 sec\n",
      "Step 168800 - Training Loss: 1.0001678466796875, Val Loss: 1.0384761095046997, Accuracy: 0.607667863368988, Val Accuracy: 0.5175833106040955, Time: 25.87 sec\n",
      "Step 168900 - Training Loss: 0.928094744682312, Val Loss: 1.038453459739685, Accuracy: 0.6077163815498352, Val Accuracy: 0.5175729990005493, Time: 25.52 sec\n",
      "Step 169000 - Training Loss: 0.9478325843811035, Val Loss: 1.03843092918396, Accuracy: 0.607763946056366, Val Accuracy: 0.5175626277923584, Time: 25.44 sec\n",
      "Step 169100 - Training Loss: 0.9474653601646423, Val Loss: 1.0384082794189453, Accuracy: 0.6078125834465027, Val Accuracy: 0.5175523161888123, Time: 25.66 sec\n",
      "Step 169200 - Training Loss: 0.9256150126457214, Val Loss: 1.0383857488632202, Accuracy: 0.6078613996505737, Val Accuracy: 0.5175420045852661, Time: 25.75 sec\n",
      "Step 169300 - Training Loss: 0.9557936787605286, Val Loss: 1.0383630990982056, Accuracy: 0.6079095005989075, Val Accuracy: 0.51753169298172, Time: 25.78 sec\n",
      "Step 169400 - Training Loss: 0.9440277814865112, Val Loss: 1.03834068775177, Accuracy: 0.6079583764076233, Val Accuracy: 0.5175213813781738, Time: 25.37 sec\n",
      "Step 169500 - Training Loss: 0.9313181638717651, Val Loss: 1.038318157196045, Accuracy: 0.6080071926116943, Val Accuracy: 0.5175111293792725, Time: 25.70 sec\n",
      "Step 169600 - Training Loss: 0.9587088823318481, Val Loss: 1.0382956266403198, Accuracy: 0.6080555319786072, Val Accuracy: 0.5175008177757263, Time: 25.64 sec\n",
      "Step 169700 - Training Loss: 1.007226586341858, Val Loss: 1.0382732152938843, Accuracy: 0.6081030368804932, Val Accuracy: 0.517490565776825, Time: 26.01 sec\n",
      "Step 169800 - Training Loss: 1.0014557838439941, Val Loss: 1.0382508039474487, Accuracy: 0.6081516146659851, Val Accuracy: 0.5174803137779236, Time: 25.42 sec\n",
      "Step 169900 - Training Loss: 0.9573706984519958, Val Loss: 1.0382283926010132, Accuracy: 0.6081985235214233, Val Accuracy: 0.517470121383667, Time: 25.58 sec\n",
      "Step 170000 - Training Loss: 0.9593248963356018, Val Loss: 1.0382061004638672, Accuracy: 0.6082484722137451, Val Accuracy: 0.5174598693847656, Time: 25.57 sec\n",
      "Step 170100 - Training Loss: 0.9756264686584473, Val Loss: 1.0381836891174316, Accuracy: 0.6082970499992371, Val Accuracy: 0.517449676990509, Time: 25.80 sec\n",
      "Step 170200 - Training Loss: 0.9697883725166321, Val Loss: 1.0381613969802856, Accuracy: 0.6083440780639648, Val Accuracy: 0.5174397826194763, Time: 25.24 sec\n",
      "Step 170300 - Training Loss: 0.9592968225479126, Val Loss: 1.0381391048431396, Accuracy: 0.6083928942680359, Val Accuracy: 0.5174295902252197, Time: 25.71 sec\n",
      "Step 170400 - Training Loss: 0.9440469145774841, Val Loss: 1.0381168127059937, Accuracy: 0.6084411144256592, Val Accuracy: 0.5174193978309631, Time: 25.82 sec\n",
      "Step 170500 - Training Loss: 0.9506485462188721, Val Loss: 1.0380946397781372, Accuracy: 0.6084887385368347, Val Accuracy: 0.5174092650413513, Time: 25.71 sec\n",
      "Step 170600 - Training Loss: 0.9046912789344788, Val Loss: 1.0380724668502808, Accuracy: 0.6085363626480103, Val Accuracy: 0.5173991322517395, Time: 25.77 sec\n",
      "Step 170700 - Training Loss: 0.979195237159729, Val Loss: 1.0380501747131348, Accuracy: 0.6085838079452515, Val Accuracy: 0.5173889994621277, Time: 25.66 sec\n",
      "Step 170800 - Training Loss: 0.9667720198631287, Val Loss: 1.0380281209945679, Accuracy: 0.6086317300796509, Val Accuracy: 0.517379641532898, Time: 25.05 sec\n",
      "Step 170900 - Training Loss: 0.9530191421508789, Val Loss: 1.0380059480667114, Accuracy: 0.6086798906326294, Val Accuracy: 0.5173695087432861, Time: 25.63 sec\n",
      "Step 171000 - Training Loss: 0.9562332630157471, Val Loss: 1.0379838943481445, Accuracy: 0.6087272763252258, Val Accuracy: 0.5173593759536743, Time: 25.46 sec\n",
      "Step 171100 - Training Loss: 0.9143570065498352, Val Loss: 1.037961721420288, Accuracy: 0.6087743639945984, Val Accuracy: 0.5173493027687073, Time: 25.69 sec\n",
      "Step 171200 - Training Loss: 0.9156893491744995, Val Loss: 1.0379396677017212, Accuracy: 0.6088207960128784, Val Accuracy: 0.5173392295837402, Time: 25.31 sec\n",
      "Step 171300 - Training Loss: 0.9738909006118774, Val Loss: 1.0379177331924438, Accuracy: 0.6088684797286987, Val Accuracy: 0.5173291563987732, Time: 25.84 sec\n",
      "Step 171400 - Training Loss: 0.9114817976951599, Val Loss: 1.037895679473877, Accuracy: 0.6089153289794922, Val Accuracy: 0.5173190832138062, Time: 25.35 sec\n",
      "Step 171500 - Training Loss: 0.9700135588645935, Val Loss: 1.0378737449645996, Accuracy: 0.6089642643928528, Val Accuracy: 0.5173090696334839, Time: 25.04 sec\n",
      "Step 171600 - Training Loss: 0.9702832698822021, Val Loss: 1.0378516912460327, Accuracy: 0.6090129017829895, Val Accuracy: 0.5172990560531616, Time: 25.21 sec\n",
      "Step 171700 - Training Loss: 0.9657437205314636, Val Loss: 1.037829875946045, Accuracy: 0.6090594530105591, Val Accuracy: 0.5172890424728394, Time: 25.41 sec\n",
      "Step 171800 - Training Loss: 0.9550859332084656, Val Loss: 1.0378079414367676, Accuracy: 0.6091046333312988, Val Accuracy: 0.5172790288925171, Time: 25.70 sec\n",
      "Step 171900 - Training Loss: 0.9284121990203857, Val Loss: 1.0377860069274902, Accuracy: 0.609153151512146, Val Accuracy: 0.5172690153121948, Time: 25.24 sec\n",
      "Step 172000 - Training Loss: 0.940334141254425, Val Loss: 1.0377641916275024, Accuracy: 0.609200119972229, Val Accuracy: 0.5172590017318726, Time: 25.35 sec\n",
      "Step 172100 - Training Loss: 0.9708435535430908, Val Loss: 1.0377423763275146, Accuracy: 0.6092478632926941, Val Accuracy: 0.5172490477561951, Time: 25.22 sec\n",
      "Step 172200 - Training Loss: 0.9706264138221741, Val Loss: 1.0377205610275269, Accuracy: 0.6092933416366577, Val Accuracy: 0.5172390937805176, Time: 25.16 sec\n",
      "Step 172300 - Training Loss: 0.9813444018363953, Val Loss: 1.037698745727539, Accuracy: 0.6093412637710571, Val Accuracy: 0.5172291398048401, Time: 25.18 sec\n",
      "Step 172400 - Training Loss: 0.9541442394256592, Val Loss: 1.0376770496368408, Accuracy: 0.6093878149986267, Val Accuracy: 0.5172191858291626, Time: 25.24 sec\n",
      "Step 172500 - Training Loss: 0.9687798023223877, Val Loss: 1.0376553535461426, Accuracy: 0.6094349026679993, Val Accuracy: 0.5172092914581299, Time: 25.65 sec\n",
      "Step 172600 - Training Loss: 0.9327539801597595, Val Loss: 1.0376336574554443, Accuracy: 0.6094816327095032, Val Accuracy: 0.5171993374824524, Time: 24.96 sec\n",
      "Step 172700 - Training Loss: 1.0192220211029053, Val Loss: 1.037611961364746, Accuracy: 0.6095291376113892, Val Accuracy: 0.5171894431114197, Time: 24.87 sec\n",
      "Step 172800 - Training Loss: 0.9320419430732727, Val Loss: 1.0375902652740479, Accuracy: 0.6095744967460632, Val Accuracy: 0.517179548740387, Time: 25.03 sec\n",
      "Step 172900 - Training Loss: 0.9677770733833313, Val Loss: 1.0375686883926392, Accuracy: 0.6096219420433044, Val Accuracy: 0.5171696543693542, Time: 25.03 sec\n",
      "Step 173000 - Training Loss: 0.9287596940994263, Val Loss: 1.0375471115112305, Accuracy: 0.6096694469451904, Val Accuracy: 0.5171598196029663, Time: 25.06 sec\n",
      "Step 173100 - Training Loss: 0.9285209774971008, Val Loss: 1.0375255346298218, Accuracy: 0.6097142100334167, Val Accuracy: 0.5171501040458679, Time: 25.35 sec\n",
      "Step 173200 - Training Loss: 0.939569354057312, Val Loss: 1.037503957748413, Accuracy: 0.6097632646560669, Val Accuracy: 0.51714026927948, Time: 25.20 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 173300 - Training Loss: 0.9726141095161438, Val Loss: 1.0374823808670044, Accuracy: 0.609809935092926, Val Accuracy: 0.517130434513092, Time: 24.97 sec\n",
      "Step 173400 - Training Loss: 0.9880385994911194, Val Loss: 1.0374609231948853, Accuracy: 0.6098570823669434, Val Accuracy: 0.5171205997467041, Time: 25.39 sec\n",
      "Step 173500 - Training Loss: 0.9310052990913391, Val Loss: 1.0374394655227661, Accuracy: 0.6099037528038025, Val Accuracy: 0.5171108245849609, Time: 25.17 sec\n",
      "Step 173600 - Training Loss: 0.9922203421592712, Val Loss: 1.037418007850647, Accuracy: 0.6099491715431213, Val Accuracy: 0.517100989818573, Time: 25.18 sec\n",
      "Step 173700 - Training Loss: 0.9284979104995728, Val Loss: 1.0373965501785278, Accuracy: 0.6099959015846252, Val Accuracy: 0.5170912146568298, Time: 24.96 sec\n",
      "Step 173800 - Training Loss: 0.9470043182373047, Val Loss: 1.0373752117156982, Accuracy: 0.6100481748580933, Val Accuracy: 0.5170814394950867, Time: 25.23 sec\n",
      "Step 173900 - Training Loss: 0.9679648280143738, Val Loss: 1.037353754043579, Accuracy: 0.6100975275039673, Val Accuracy: 0.5170716643333435, Time: 25.18 sec\n",
      "Step 174000 - Training Loss: 0.9591628313064575, Val Loss: 1.0373324155807495, Accuracy: 0.610144853591919, Val Accuracy: 0.5170618891716003, Time: 25.78 sec\n",
      "Step 174100 - Training Loss: 0.9589089155197144, Val Loss: 1.03731107711792, Accuracy: 0.6101951003074646, Val Accuracy: 0.5170521140098572, Time: 25.42 sec\n",
      "Step 174200 - Training Loss: 0.9297806620597839, Val Loss: 1.0372898578643799, Accuracy: 0.6102415323257446, Val Accuracy: 0.5170423984527588, Time: 25.47 sec\n",
      "Step 174300 - Training Loss: 0.9331538677215576, Val Loss: 1.0372685194015503, Accuracy: 0.61028653383255, Val Accuracy: 0.5170326828956604, Time: 25.48 sec\n",
      "Step 174400 - Training Loss: 0.9594287872314453, Val Loss: 1.0372473001480103, Accuracy: 0.6103334426879883, Val Accuracy: 0.517022967338562, Time: 25.05 sec\n",
      "Step 174500 - Training Loss: 0.9384256601333618, Val Loss: 1.0372260808944702, Accuracy: 0.610382080078125, Val Accuracy: 0.5170132517814636, Time: 25.13 sec\n",
      "Step 174600 - Training Loss: 0.9115455746650696, Val Loss: 1.0372048616409302, Accuracy: 0.6104291081428528, Val Accuracy: 0.51700359582901, Time: 24.96 sec\n",
      "Step 174700 - Training Loss: 0.923997163772583, Val Loss: 1.0371836423873901, Accuracy: 0.6104766726493835, Val Accuracy: 0.5169938802719116, Time: 24.93 sec\n",
      "Step 174800 - Training Loss: 0.9492616057395935, Val Loss: 1.0371625423431396, Accuracy: 0.6105219721794128, Val Accuracy: 0.5169857740402222, Time: 25.35 sec\n",
      "Step 174900 - Training Loss: 0.9503874182701111, Val Loss: 1.0371413230895996, Accuracy: 0.6105673313140869, Val Accuracy: 0.5169761180877686, Time: 27.00 sec\n",
      "Step 175000 - Training Loss: 0.9629125595092773, Val Loss: 1.0371202230453491, Accuracy: 0.6106122732162476, Val Accuracy: 0.5169664621353149, Time: 25.54 sec\n",
      "Step 175100 - Training Loss: 0.9494321942329407, Val Loss: 1.0370991230010986, Accuracy: 0.6106582880020142, Val Accuracy: 0.5169568657875061, Time: 25.73 sec\n",
      "Step 175200 - Training Loss: 0.9479004144668579, Val Loss: 1.0370781421661377, Accuracy: 0.6107054948806763, Val Accuracy: 0.5169472098350525, Time: 25.14 sec\n",
      "Step 175300 - Training Loss: 0.9702447652816772, Val Loss: 1.0370570421218872, Accuracy: 0.6107508540153503, Val Accuracy: 0.5169376134872437, Time: 25.01 sec\n",
      "Step 175400 - Training Loss: 0.9281927943229675, Val Loss: 1.0370360612869263, Accuracy: 0.610797643661499, Val Accuracy: 0.5169280171394348, Time: 25.26 sec\n",
      "Step 175500 - Training Loss: 0.9539989829063416, Val Loss: 1.0370150804519653, Accuracy: 0.6108444333076477, Val Accuracy: 0.516918420791626, Time: 26.90 sec\n",
      "Step 175600 - Training Loss: 0.9357746839523315, Val Loss: 1.0369940996170044, Accuracy: 0.6108918190002441, Val Accuracy: 0.5169088244438171, Time: 27.64 sec\n",
      "Step 175700 - Training Loss: 0.9571855664253235, Val Loss: 1.0369731187820435, Accuracy: 0.6109364032745361, Val Accuracy: 0.5168992280960083, Time: 31.85 sec\n",
      "Step 175800 - Training Loss: 0.9411399960517883, Val Loss: 1.036952257156372, Accuracy: 0.6109827756881714, Val Accuracy: 0.5168896913528442, Time: 30.33 sec\n",
      "Step 175900 - Training Loss: 0.9277777671813965, Val Loss: 1.0369312763214111, Accuracy: 0.6110286712646484, Val Accuracy: 0.5168801546096802, Time: 31.22 sec\n",
      "Step 176000 - Training Loss: 0.9434483051300049, Val Loss: 1.0369104146957397, Accuracy: 0.6110737919807434, Val Accuracy: 0.5168706178665161, Time: 29.22 sec\n",
      "Step 176100 - Training Loss: 0.966405987739563, Val Loss: 1.0368895530700684, Accuracy: 0.61111980676651, Val Accuracy: 0.516861081123352, Time: 28.12 sec\n",
      "Step 176200 - Training Loss: 0.9918761253356934, Val Loss: 1.0368688106536865, Accuracy: 0.6111653447151184, Val Accuracy: 0.516851544380188, Time: 27.11 sec\n",
      "Step 176300 - Training Loss: 0.9742246866226196, Val Loss: 1.0368479490280151, Accuracy: 0.6112112402915955, Val Accuracy: 0.5168420672416687, Time: 27.82 sec\n",
      "Step 176400 - Training Loss: 0.9602873921394348, Val Loss: 1.0368272066116333, Accuracy: 0.6112555861473083, Val Accuracy: 0.5168325304985046, Time: 27.12 sec\n",
      "Step 176500 - Training Loss: 0.940321683883667, Val Loss: 1.0368064641952515, Accuracy: 0.6113007068634033, Val Accuracy: 0.5168230533599854, Time: 26.80 sec\n",
      "Step 176600 - Training Loss: 0.9332281351089478, Val Loss: 1.0367857217788696, Accuracy: 0.6113458871841431, Val Accuracy: 0.5168135762214661, Time: 26.30 sec\n",
      "Step 176700 - Training Loss: 0.9756521582603455, Val Loss: 1.0367649793624878, Accuracy: 0.6113945245742798, Val Accuracy: 0.5168040990829468, Time: 26.62 sec\n",
      "Step 176800 - Training Loss: 0.9667966365814209, Val Loss: 1.0367443561553955, Accuracy: 0.6114394068717957, Val Accuracy: 0.5167946815490723, Time: 26.29 sec\n",
      "Step 176900 - Training Loss: 0.9520179033279419, Val Loss: 1.0367236137390137, Accuracy: 0.6114827394485474, Val Accuracy: 0.5167852640151978, Time: 26.55 sec\n",
      "Step 177000 - Training Loss: 0.956032931804657, Val Loss: 1.0367029905319214, Accuracy: 0.611527144908905, Val Accuracy: 0.5167757868766785, Time: 26.53 sec\n",
      "Step 177100 - Training Loss: 0.9481993317604065, Val Loss: 1.036682367324829, Accuracy: 0.6115713715553284, Val Accuracy: 0.516766369342804, Time: 26.77 sec\n",
      "Step 177200 - Training Loss: 0.9317837953567505, Val Loss: 1.0366617441177368, Accuracy: 0.6116170287132263, Val Accuracy: 0.5167569518089294, Time: 26.98 sec\n",
      "Step 177300 - Training Loss: 0.9710973501205444, Val Loss: 1.036641240119934, Accuracy: 0.6116622686386108, Val Accuracy: 0.5167475938796997, Time: 27.02 sec\n",
      "Step 177400 - Training Loss: 0.9127049446105957, Val Loss: 1.0366207361221313, Accuracy: 0.6117079257965088, Val Accuracy: 0.5167381763458252, Time: 26.70 sec\n",
      "Step 177500 - Training Loss: 0.9491214156150818, Val Loss: 1.036600112915039, Accuracy: 0.6117531657218933, Val Accuracy: 0.5167288184165955, Time: 26.24 sec\n",
      "Step 177600 - Training Loss: 0.9788877367973328, Val Loss: 1.0365796089172363, Accuracy: 0.6117983460426331, Val Accuracy: 0.5167194604873657, Time: 26.50 sec\n",
      "Step 177700 - Training Loss: 0.9731485247612, Val Loss: 1.0365592241287231, Accuracy: 0.6118449568748474, Val Accuracy: 0.516710102558136, Time: 26.50 sec\n",
      "Step 177800 - Training Loss: 0.9482421278953552, Val Loss: 1.0365387201309204, Accuracy: 0.611890435218811, Val Accuracy: 0.5167007446289062, Time: 40.52 sec\n",
      "Step 177900 - Training Loss: 0.9509132504463196, Val Loss: 1.0365183353424072, Accuracy: 0.6119356155395508, Val Accuracy: 0.5166913866996765, Time: 31.30 sec\n",
      "Step 178000 - Training Loss: 0.950870156288147, Val Loss: 1.0364978313446045, Accuracy: 0.6119805574417114, Val Accuracy: 0.5166820883750916, Time: 31.04 sec\n",
      "Step 178100 - Training Loss: 0.8906686902046204, Val Loss: 1.0364774465560913, Accuracy: 0.6120243668556213, Val Accuracy: 0.5166727304458618, Time: 29.03 sec\n",
      "Step 178200 - Training Loss: 0.9702532887458801, Val Loss: 1.0364571809768677, Accuracy: 0.6120673418045044, Val Accuracy: 0.5166634321212769, Time: 32.75 sec\n",
      "Step 178300 - Training Loss: 0.9684901833534241, Val Loss: 1.0364367961883545, Accuracy: 0.6121106743812561, Val Accuracy: 0.5166541337966919, Time: 27.96 sec\n",
      "Step 178400 - Training Loss: 0.9453682899475098, Val Loss: 1.0364165306091309, Accuracy: 0.6121554374694824, Val Accuracy: 0.5166448354721069, Time: 27.20 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 178500 - Training Loss: 0.9547499418258667, Val Loss: 1.0363961458206177, Accuracy: 0.6121986508369446, Val Accuracy: 0.5166355967521667, Time: 27.47 sec\n",
      "Step 178600 - Training Loss: 0.9643194079399109, Val Loss: 1.036375880241394, Accuracy: 0.6122443079948425, Val Accuracy: 0.5166262984275818, Time: 28.49 sec\n",
      "Step 178700 - Training Loss: 0.9487423300743103, Val Loss: 1.0363556146621704, Accuracy: 0.6122901439666748, Val Accuracy: 0.5166170597076416, Time: 31.15 sec\n",
      "Step 178800 - Training Loss: 0.9198620915412903, Val Loss: 1.0363354682922363, Accuracy: 0.6123363971710205, Val Accuracy: 0.5166078209877014, Time: 27.61 sec\n",
      "Step 178900 - Training Loss: 0.9604179859161377, Val Loss: 1.0363152027130127, Accuracy: 0.6123793721199036, Val Accuracy: 0.5165985822677612, Time: 28.43 sec\n",
      "Step 179000 - Training Loss: 0.9359643459320068, Val Loss: 1.0363880395889282, Accuracy: 0.6124259233474731, Val Accuracy: 0.516589343547821, Time: 26.36 sec\n",
      "Step 179100 - Training Loss: 0.9163793921470642, Val Loss: 1.0365530252456665, Accuracy: 0.612470805644989, Val Accuracy: 0.5165801048278809, Time: 28.18 sec\n",
      "Step 179200 - Training Loss: 0.9694153666496277, Val Loss: 1.0367177724838257, Accuracy: 0.6125161647796631, Val Accuracy: 0.5165709257125854, Time: 27.68 sec\n",
      "Step 179300 - Training Loss: 0.9338862895965576, Val Loss: 1.0368824005126953, Accuracy: 0.612561047077179, Val Accuracy: 0.51656174659729, Time: 26.76 sec\n",
      "Step 179400 - Training Loss: 0.9402594566345215, Val Loss: 1.0370467901229858, Accuracy: 0.612605631351471, Val Accuracy: 0.5165525674819946, Time: 25.80 sec\n",
      "Step 179500 - Training Loss: 0.9270579814910889, Val Loss: 1.0372109413146973, Accuracy: 0.6126493215560913, Val Accuracy: 0.5165433883666992, Time: 26.89 sec\n",
      "Step 179600 - Training Loss: 0.9494748115539551, Val Loss: 1.0373749732971191, Accuracy: 0.6126946210861206, Val Accuracy: 0.5166168212890625, Time: 27.64 sec\n",
      "Step 179700 - Training Loss: 0.9243862628936768, Val Loss: 1.0375388860702515, Accuracy: 0.6127380728721619, Val Accuracy: 0.5166999101638794, Time: 28.26 sec\n",
      "Step 179800 - Training Loss: 0.9964531064033508, Val Loss: 1.0377025604248047, Accuracy: 0.6127822995185852, Val Accuracy: 0.5167828798294067, Time: 28.51 sec\n",
      "Step 179900 - Training Loss: 0.9590653777122498, Val Loss: 1.0378659963607788, Accuracy: 0.6128262877464294, Val Accuracy: 0.5168657898902893, Time: 26.14 sec\n",
      "Step 180000 - Training Loss: 0.961104154586792, Val Loss: 1.0380293130874634, Accuracy: 0.6128708720207214, Val Accuracy: 0.5169470906257629, Time: 26.66 sec\n",
      "Step 180100 - Training Loss: 0.9564281702041626, Val Loss: 1.0381923913955688, Accuracy: 0.6129159331321716, Val Accuracy: 0.5170298218727112, Time: 26.68 sec\n",
      "Step 180200 - Training Loss: 0.9473198056221008, Val Loss: 1.0383553504943848, Accuracy: 0.6129592657089233, Val Accuracy: 0.5171123743057251, Time: 25.55 sec\n",
      "Step 180300 - Training Loss: 0.9240282773971558, Val Loss: 1.0385180711746216, Accuracy: 0.6130032539367676, Val Accuracy: 0.517194926738739, Time: 26.15 sec\n",
      "Step 180400 - Training Loss: 0.9219548106193542, Val Loss: 1.0386806726455688, Accuracy: 0.6130473017692566, Val Accuracy: 0.5172773599624634, Time: 26.36 sec\n",
      "Step 180500 - Training Loss: 0.9498468637466431, Val Loss: 1.0388431549072266, Accuracy: 0.6130903363227844, Val Accuracy: 0.5173522233963013, Time: 26.51 sec\n",
      "Step 180600 - Training Loss: 0.9476762413978577, Val Loss: 1.0390052795410156, Accuracy: 0.6131357550621033, Val Accuracy: 0.5174344778060913, Time: 26.40 sec\n",
      "Step 180700 - Training Loss: 0.9337091445922852, Val Loss: 1.0391674041748047, Accuracy: 0.6131787300109863, Val Accuracy: 0.5175058841705322, Time: 31.60 sec\n",
      "Step 180800 - Training Loss: 0.973774790763855, Val Loss: 1.0393292903900146, Accuracy: 0.6132214665412903, Val Accuracy: 0.5175821781158447, Time: 28.71 sec\n",
      "Step 180900 - Training Loss: 0.9080163836479187, Val Loss: 1.0394909381866455, Accuracy: 0.6132655143737793, Val Accuracy: 0.5176641941070557, Time: 27.13 sec\n",
      "Step 181000 - Training Loss: 0.955101728439331, Val Loss: 1.0396524667739868, Accuracy: 0.6133098006248474, Val Accuracy: 0.5177389979362488, Time: 30.83 sec\n",
      "Step 181100 - Training Loss: 0.9359890818595886, Val Loss: 1.039813756942749, Accuracy: 0.6133539080619812, Val Accuracy: 0.5178202986717224, Time: 27.92 sec\n",
      "Step 181200 - Training Loss: 0.9309377074241638, Val Loss: 1.0399749279022217, Accuracy: 0.6133993268013, Val Accuracy: 0.5179020762443542, Time: 29.37 sec\n",
      "Step 181300 - Training Loss: 0.9386988282203674, Val Loss: 1.0401358604431152, Accuracy: 0.6134423017501831, Val Accuracy: 0.5179836750030518, Time: 29.85 sec\n",
      "Step 181400 - Training Loss: 0.9726899862289429, Val Loss: 1.0402966737747192, Accuracy: 0.6134849786758423, Val Accuracy: 0.5180652141571045, Time: 29.21 sec\n",
      "Step 181500 - Training Loss: 0.9572644829750061, Val Loss: 1.0404573678970337, Accuracy: 0.6135291457176208, Val Accuracy: 0.5181466937065125, Time: 26.52 sec\n",
      "Step 181600 - Training Loss: 0.9890877604484558, Val Loss: 1.040617823600769, Accuracy: 0.6135743260383606, Val Accuracy: 0.5182264447212219, Time: 26.68 sec\n",
      "Step 181700 - Training Loss: 0.9420240521430969, Val Loss: 1.0407780408859253, Accuracy: 0.6136175990104675, Val Accuracy: 0.5183077454566956, Time: 25.60 sec\n",
      "Step 181800 - Training Loss: 0.9110917448997498, Val Loss: 1.040938138961792, Accuracy: 0.6136595606803894, Val Accuracy: 0.5183889269828796, Time: 28.71 sec\n",
      "Step 181900 - Training Loss: 1.0023441314697266, Val Loss: 1.0410981178283691, Accuracy: 0.6137022376060486, Val Accuracy: 0.518470048904419, Time: 29.32 sec\n",
      "Step 182000 - Training Loss: 0.978322446346283, Val Loss: 1.0412578582763672, Accuracy: 0.6137452721595764, Val Accuracy: 0.5185494422912598, Time: 28.86 sec\n",
      "Step 182100 - Training Loss: 0.94297194480896, Val Loss: 1.0414173603057861, Accuracy: 0.6137874722480774, Val Accuracy: 0.5186302661895752, Time: 27.15 sec\n",
      "Step 182200 - Training Loss: 0.9485878348350525, Val Loss: 1.041576862335205, Accuracy: 0.6138319969177246, Val Accuracy: 0.5187006592750549, Time: 27.05 sec\n",
      "Step 182300 - Training Loss: 0.9214937686920166, Val Loss: 1.0417360067367554, Accuracy: 0.6138734817504883, Val Accuracy: 0.5187814235687256, Time: 26.94 sec\n",
      "Step 182400 - Training Loss: 0.9784792065620422, Val Loss: 1.0418950319290161, Accuracy: 0.6139158010482788, Val Accuracy: 0.5188620686531067, Time: 26.92 sec\n",
      "Step 182500 - Training Loss: 0.9242081046104431, Val Loss: 1.0420539379119873, Accuracy: 0.6139593124389648, Val Accuracy: 0.518942654132843, Time: 27.04 sec\n",
      "Step 182600 - Training Loss: 0.9401784539222717, Val Loss: 1.042212724685669, Accuracy: 0.6140021681785583, Val Accuracy: 0.5190231800079346, Time: 26.86 sec\n",
      "Step 182700 - Training Loss: 0.9398486614227295, Val Loss: 1.042371153831482, Accuracy: 0.6140453815460205, Val Accuracy: 0.5191035270690918, Time: 26.44 sec\n",
      "Step 182800 - Training Loss: 0.9409292340278625, Val Loss: 1.042529582977295, Accuracy: 0.6140866875648499, Val Accuracy: 0.519183874130249, Time: 25.48 sec\n",
      "Step 182900 - Training Loss: 0.9806751608848572, Val Loss: 1.0426877737045288, Accuracy: 0.6141281723976135, Val Accuracy: 0.5192641019821167, Time: 26.15 sec\n",
      "Step 183000 - Training Loss: 0.9462721943855286, Val Loss: 1.0428457260131836, Accuracy: 0.6141709685325623, Val Accuracy: 0.5193442106246948, Time: 26.29 sec\n",
      "Step 183100 - Training Loss: 0.9524825215339661, Val Loss: 1.0430036783218384, Accuracy: 0.6142149567604065, Val Accuracy: 0.5194242596626282, Time: 27.12 sec\n",
      "Step 183200 - Training Loss: 0.9275234937667847, Val Loss: 1.0431612730026245, Accuracy: 0.6142584085464478, Val Accuracy: 0.51948481798172, Time: 27.66 sec\n",
      "Step 183300 - Training Loss: 0.9671041369438171, Val Loss: 1.043318748474121, Accuracy: 0.6143020391464233, Val Accuracy: 0.5195562839508057, Time: 26.02 sec\n",
      "Step 183400 - Training Loss: 0.9881884455680847, Val Loss: 1.0434761047363281, Accuracy: 0.6143432259559631, Val Accuracy: 0.5196360945701599, Time: 29.15 sec\n",
      "Step 183500 - Training Loss: 0.9693670272827148, Val Loss: 1.0436333417892456, Accuracy: 0.6143844723701477, Val Accuracy: 0.5197157859802246, Time: 29.47 sec\n",
      "Step 183600 - Training Loss: 0.9548898339271545, Val Loss: 1.043790340423584, Accuracy: 0.6144275069236755, Val Accuracy: 0.5197933912277222, Time: 29.63 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 183700 - Training Loss: 0.9863622188568115, Val Loss: 1.0439471006393433, Accuracy: 0.6144706010818481, Val Accuracy: 0.5198714733123779, Time: 29.54 sec\n",
      "Step 183800 - Training Loss: 0.941615104675293, Val Loss: 1.044103741645813, Accuracy: 0.6145122647285461, Val Accuracy: 0.5199509263038635, Time: 27.55 sec\n",
      "Step 183900 - Training Loss: 0.9658772349357605, Val Loss: 1.0442602634429932, Accuracy: 0.6145552396774292, Val Accuracy: 0.5200294852256775, Time: 29.13 sec\n",
      "Step 184000 - Training Loss: 0.9283196926116943, Val Loss: 1.0444165468215942, Accuracy: 0.6145968437194824, Val Accuracy: 0.5201087594032288, Time: 28.96 sec\n",
      "Step 184100 - Training Loss: 0.9100024104118347, Val Loss: 1.0445727109909058, Accuracy: 0.6146389245986938, Val Accuracy: 0.5201879739761353, Time: 28.66 sec\n",
      "Step 184200 - Training Loss: 0.9302545785903931, Val Loss: 1.0447286367416382, Accuracy: 0.6146810054779053, Val Accuracy: 0.5202658772468567, Time: 28.58 sec\n",
      "Step 184300 - Training Loss: 0.9884350895881653, Val Loss: 1.044884443283081, Accuracy: 0.6147233247756958, Val Accuracy: 0.5203434824943542, Time: 29.23 sec\n",
      "Step 184400 - Training Loss: 0.9428202509880066, Val Loss: 1.0450401306152344, Accuracy: 0.6147664189338684, Val Accuracy: 0.5204204320907593, Time: 29.19 sec\n",
      "Step 184500 - Training Loss: 0.9481858015060425, Val Loss: 1.0451955795288086, Accuracy: 0.6148084998130798, Val Accuracy: 0.5204992890357971, Time: 28.98 sec\n",
      "Step 184600 - Training Loss: 0.9698250889778137, Val Loss: 1.0453509092330933, Accuracy: 0.6148500442504883, Val Accuracy: 0.5205696821212769, Time: 29.08 sec\n",
      "Step 184700 - Training Loss: 0.9490423202514648, Val Loss: 1.0455060005187988, Accuracy: 0.6148921847343445, Val Accuracy: 0.5206466913223267, Time: 29.08 sec\n",
      "Step 184800 - Training Loss: 0.9154929518699646, Val Loss: 1.0456609725952148, Accuracy: 0.6149340867996216, Val Accuracy: 0.520707368850708, Time: 28.71 sec\n",
      "Step 184900 - Training Loss: 0.9112005233764648, Val Loss: 1.0458158254623413, Accuracy: 0.6149759292602539, Val Accuracy: 0.520785927772522, Time: 28.64 sec\n",
      "Step 185000 - Training Loss: 0.9274874329566956, Val Loss: 1.0459704399108887, Accuracy: 0.615018367767334, Val Accuracy: 0.5208643674850464, Time: 31.78 sec\n",
      "Step 185100 - Training Loss: 0.9767369031906128, Val Loss: 1.0461249351501465, Accuracy: 0.6150596737861633, Val Accuracy: 0.520942747592926, Time: 27.66 sec\n",
      "Step 185200 - Training Loss: 0.929803729057312, Val Loss: 1.0462791919708252, Accuracy: 0.6151009202003479, Val Accuracy: 0.5210201144218445, Time: 25.88 sec\n",
      "Step 185300 - Training Loss: 0.9134771227836609, Val Loss: 1.0464333295822144, Accuracy: 0.6151422262191772, Val Accuracy: 0.5210983157157898, Time: 26.12 sec\n",
      "Step 185400 - Training Loss: 0.963830828666687, Val Loss: 1.046587347984314, Accuracy: 0.6151854991912842, Val Accuracy: 0.5211758017539978, Time: 26.11 sec\n",
      "Step 185500 - Training Loss: 0.938947856426239, Val Loss: 1.0467045307159424, Accuracy: 0.6152274012565613, Val Accuracy: 0.5212356448173523, Time: 26.05 sec\n",
      "Step 185600 - Training Loss: 0.938497006893158, Val Loss: 1.0466711521148682, Accuracy: 0.615269660949707, Val Accuracy: 0.5212178826332092, Time: 24.88 sec\n",
      "Step 185700 - Training Loss: 0.9369251132011414, Val Loss: 1.0466378927230835, Accuracy: 0.6153114438056946, Val Accuracy: 0.5212026834487915, Time: 27.18 sec\n",
      "Step 185800 - Training Loss: 0.9095253944396973, Val Loss: 1.0466045141220093, Accuracy: 0.6153534054756165, Val Accuracy: 0.5211873650550842, Time: 25.36 sec\n",
      "Step 185900 - Training Loss: 0.9237940311431885, Val Loss: 1.0465713739395142, Accuracy: 0.6153951287269592, Val Accuracy: 0.5211722254753113, Time: 25.16 sec\n",
      "Step 186000 - Training Loss: 0.9321585297584534, Val Loss: 1.0465381145477295, Accuracy: 0.6154377460479736, Val Accuracy: 0.5211566686630249, Time: 25.36 sec\n",
      "Step 186100 - Training Loss: 0.9747835397720337, Val Loss: 1.0465049743652344, Accuracy: 0.6154782772064209, Val Accuracy: 0.5211412310600281, Time: 25.12 sec\n",
      "Step 186200 - Training Loss: 1.0070196390151978, Val Loss: 1.0464719533920288, Accuracy: 0.6155188083648682, Val Accuracy: 0.5211259722709656, Time: 25.41 sec\n",
      "Step 186300 - Training Loss: 1.0038774013519287, Val Loss: 1.0464388132095337, Accuracy: 0.6155611872673035, Val Accuracy: 0.5211109519004822, Time: 25.11 sec\n",
      "Step 186400 - Training Loss: 0.9253612756729126, Val Loss: 1.0464059114456177, Accuracy: 0.6156033873558044, Val Accuracy: 0.5210946202278137, Time: 26.87 sec\n",
      "Step 186500 - Training Loss: 0.9378191232681274, Val Loss: 1.046372890472412, Accuracy: 0.6156432032585144, Val Accuracy: 0.5210795402526855, Time: 25.01 sec\n",
      "Step 186600 - Training Loss: 0.9613483548164368, Val Loss: 1.046339988708496, Accuracy: 0.6156845092773438, Val Accuracy: 0.5210645794868469, Time: 25.37 sec\n",
      "Step 186700 - Training Loss: 0.917815089225769, Val Loss: 1.0463072061538696, Accuracy: 0.6157244443893433, Val Accuracy: 0.5210496187210083, Time: 24.93 sec\n",
      "Step 186800 - Training Loss: 0.9631855487823486, Val Loss: 1.0462743043899536, Accuracy: 0.615764319896698, Val Accuracy: 0.5210345983505249, Time: 25.14 sec\n",
      "Step 186900 - Training Loss: 0.9789168834686279, Val Loss: 1.0462415218353271, Accuracy: 0.6158046722412109, Val Accuracy: 0.521019697189331, Time: 24.92 sec\n",
      "Step 187000 - Training Loss: 0.9464738965034485, Val Loss: 1.0462088584899902, Accuracy: 0.6158455610275269, Val Accuracy: 0.521004855632782, Time: 24.87 sec\n",
      "Step 187100 - Training Loss: 0.9980272650718689, Val Loss: 1.0461761951446533, Accuracy: 0.6158857345581055, Val Accuracy: 0.5209900140762329, Time: 28.17 sec\n",
      "Step 187200 - Training Loss: 0.9534019827842712, Val Loss: 1.0461435317993164, Accuracy: 0.6159259080886841, Val Accuracy: 0.5209751725196838, Time: 29.29 sec\n",
      "Step 187300 - Training Loss: 0.9465571045875549, Val Loss: 1.046110987663269, Accuracy: 0.6159654855728149, Val Accuracy: 0.5209603309631348, Time: 26.85 sec\n",
      "Step 187400 - Training Loss: 0.9612932801246643, Val Loss: 1.0460784435272217, Accuracy: 0.6160078048706055, Val Accuracy: 0.5209448337554932, Time: 25.22 sec\n",
      "Step 187500 - Training Loss: 0.9314007759094238, Val Loss: 1.0460458993911743, Accuracy: 0.6160489320755005, Val Accuracy: 0.5209295153617859, Time: 25.20 sec\n",
      "Step 187600 - Training Loss: 0.9380030632019043, Val Loss: 1.0460134744644165, Accuracy: 0.6160903573036194, Val Accuracy: 0.5209147334098816, Time: 25.86 sec\n",
      "Step 187700 - Training Loss: 0.9985097050666809, Val Loss: 1.0459811687469482, Accuracy: 0.6161313652992249, Val Accuracy: 0.520899772644043, Time: 25.29 sec\n",
      "Step 187800 - Training Loss: 0.9879244565963745, Val Loss: 1.0459487438201904, Accuracy: 0.6161720156669617, Val Accuracy: 0.5208851099014282, Time: 25.45 sec\n",
      "Step 187900 - Training Loss: 0.9246432185173035, Val Loss: 1.0459164381027222, Accuracy: 0.6162109971046448, Val Accuracy: 0.5208703875541687, Time: 25.78 sec\n",
      "Step 188000 - Training Loss: 0.9475796222686768, Val Loss: 1.0458842515945435, Accuracy: 0.6162523627281189, Val Accuracy: 0.5208556056022644, Time: 25.20 sec\n",
      "Step 188100 - Training Loss: 0.9296419024467468, Val Loss: 1.0458519458770752, Accuracy: 0.6162949204444885, Val Accuracy: 0.5208384394645691, Time: 27.00 sec\n",
      "Step 188200 - Training Loss: 0.9594809412956238, Val Loss: 1.0458197593688965, Accuracy: 0.6163361072540283, Val Accuracy: 0.5208236575126648, Time: 25.75 sec\n",
      "Step 188300 - Training Loss: 0.9461931586265564, Val Loss: 1.0457876920700073, Accuracy: 0.6163777709007263, Val Accuracy: 0.5208090543746948, Time: 25.10 sec\n",
      "Step 188400 - Training Loss: 0.9088561534881592, Val Loss: 1.0457556247711182, Accuracy: 0.6164194345474243, Val Accuracy: 0.5207945108413696, Time: 27.51 sec\n",
      "Step 188500 - Training Loss: 1.0009586811065674, Val Loss: 1.045723557472229, Accuracy: 0.6164599061012268, Val Accuracy: 0.5207768082618713, Time: 26.62 sec\n",
      "Step 188600 - Training Loss: 0.9712792634963989, Val Loss: 1.0456916093826294, Accuracy: 0.6165010929107666, Val Accuracy: 0.5207622647285461, Time: 26.27 sec\n",
      "Step 188700 - Training Loss: 0.941802978515625, Val Loss: 1.0456596612930298, Accuracy: 0.6165416836738586, Val Accuracy: 0.5207473635673523, Time: 26.45 sec\n",
      "Step 188800 - Training Loss: 0.9507240056991577, Val Loss: 1.0456277132034302, Accuracy: 0.6165828108787537, Val Accuracy: 0.5207289457321167, Time: 25.79 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 188900 - Training Loss: 0.9127156734466553, Val Loss: 1.0455958843231201, Accuracy: 0.6166222095489502, Val Accuracy: 0.5207118988037109, Time: 25.57 sec\n",
      "Restoring model weights from the end of the best epoch: 178950.\n",
      "Step 188949 - Training Loss: 0.9713545441627502, Val Loss: 1.045580267906189\n",
      "Epoch 188950: early stopping\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 1\n",
    "HIDDEN_UNITS = 512\n",
    "\n",
    "conv_layer = tf.keras.layers.Conv1D(\n",
    "            filters=HIDDEN_UNITS,\n",
    "            kernel_size=(2,),\n",
    "            kernel_initializer='he_uniform',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
    "            activation='relu')\n",
    "\n",
    "# Prepare our layer, loss, and optimizer.\n",
    "mlmodel = tf.keras.Sequential(\n",
    "    [\n",
    "        # Shape: (time, features) => (time*features)\n",
    "        conv_layer,\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.8),\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(HIDDEN_UNITS, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(NUM_LABELS),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = train(mlmodel, TOTAL_EPOCHS, callbacks)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "histories[\"64x4+DO+Reg:Lam.5\"] = history\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 15]\n",
    "\n",
    "# PLOT histories\n",
    "plt.subplot(211)\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'loss', smoothing_std=10).plot(histories)\n",
    "a = plt.xscale('log')\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "#plt.ylim([0.75, 1.1])\n",
    "plt.xlabel(\"Epochs\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'accuracy', smoothing_std=10).plot(histories)\n",
    "#plotter.plot(histories)\n",
    "a = plt.xscale('log')\n",
    "plt.xlim([5, max(plt.xlim())])\n",
    "plt.ylim([0.4, 0.7])\n",
    "plt.xlabel(\"Epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.53>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Accuracy()(y_pred=roundTan(tf.nn.tanh(mlmodel(val_df_x))), y_true=val_df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 682.0\n",
      "Lost : 518.0\n",
      "Total : 1200.0\n",
      "Diff : 164.0\n",
      "Edge : 13.666666666666666%\n",
      "Information Coefficient : 0.1366666555404663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5683333"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.evaluate(ppl.onehot(toSigmoid(tf.nn.tanh(mlmodel(train_df_x))).numpy()), ppl.onehot(toSigmoid(train_df_y).numpy()), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 54.0\n",
      "Lost : 46.0\n",
      "Total : 100.0\n",
      "Diff : 8.0\n",
      "Edge : 8.0%\n",
      "Information Coefficient : 0.08000004291534424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.evaluate(ppl.onehot(toSigmoid(tf.nn.tanh(mlmodel(val_df_x))).numpy()), ppl.onehot(toSigmoid(val_df_y).numpy()), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won : 44.0\n",
      "Lost : 43.0\n",
      "Total : 87.0\n",
      "Diff : 1.0\n",
      "Edge : 1.1494252873563218%\n",
      "Information Coefficient : 0.011494278907775879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.50574714"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlutils.evaluate(ppl.onehot(toSigmoid(tf.nn.tanh(mlmodel(test_df_x))).numpy()), ppl.onehot(toSigmoid(test_df_y).numpy()), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.69271004>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.BinaryCrossentropy(from_logits=True)(y_pred=mlmodel(val_x), y_true=toSigmoid(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.6941605066964598>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.BinaryCrossentropy(from_logits=False)(y_pred=baseline, y_true=toSigmoid(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [np.sum(toSigmoid(train_y)==1)/len(train_y)]*len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.43678162>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.BinaryAccuracy()(y_pred=baseline, y_true=toSigmoid(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: PossiblyAwesome_CNNx4+BN+DO+Batch40-ELU_model-IV/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: PossiblyAwesome_CNNx4+BN+DO+Batch40-ELU_model-IV/assets\n"
     ]
    }
   ],
   "source": [
    "mlmodel.save(\"PossiblyAwesome_CNNx4+BN+DO+Batch40-ELU_model-IV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "modelName = \"PossiblyAwesome_CNNx4+BN+DO+Batch40_model-I\"\n",
    "mlmodel = tf.keras.models.load_model(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data ratio: 48.44% Positive, 51.56% Negative\n",
      "Prediction data ratio: 19.97% Positive, 80.03% Negative\n",
      "\n",
      "=================================================\n",
      "Classification Metrics\n",
      "=================================================\n",
      "\n",
      "Won : 684\n",
      "Lost : 658\n",
      "Total : 1342\n",
      "Diff : 26\n",
      "\n",
      "Accuracy : 50.97%\n",
      "Information Coefficient (Edge): 1.94%\n",
      "Expected Value (Annualised): -7645.77%\n",
      "\n",
      "Precision: Of all the predicted Buys/Sells, how many were correct?\n",
      "Precision (Buy) : 48.51%\n",
      "Precision (Sell): 51.58%\n",
      "\n",
      "Recall: Of all the actual Buys/Sells, how many were correct?\n",
      "Recall (Buy): 20.00%\n",
      "Recall (Sell): 80.06%\n",
      "\n",
      "F1 Score: Harmonic mean of Precision and Recall for the Buys/Sells\n",
      "F1 Score (Buy): 28.32%\n",
      "F1 Score (Sell): 62.74%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tradeframework.api.insights import InsightManager\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pred = pd.DataFrame(roundTan(tf.nn.tanh(mlmodel(all_x))).numpy().flatten(), index=dataset.index[1200:])\n",
    "true = pd.DataFrame(all_y.numpy().flatten(), index=dataset.index[1200:])\n",
    "\n",
    "print(f\"Actual data ratio: {len(true.values[true>0])/len(true):.2%} Positive, {len(true.values[true<0])/len(true):.2%} Negative\")\n",
    "print(f\"Prediction data ratio: {len(pred.values[pred>0])/len(pred):.2%} Positive, {len(pred.values[pred<0])/len(pred):.2%} Negative\")\n",
    "\n",
    "im = InsightManager(None)\n",
    "im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"actual\":true[0], \"predictions\":pred[0], \"noHold\":True, \"returnsData\":False}))\n",
    "#im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"baseline\":p.assets[0], \"noHold\":True}))\n",
    "\n",
    "results = im.generateInsights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_pickle(f\"{modelName}-1.7(nonneg)-all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data ratio: 52.25% Positive, 47.75% Negative\n",
      "Prediction data ratio: 73.25% Positive, 26.75% Negative\n",
      "\n",
      "=================================================\n",
      "Classification Metrics\n",
      "=================================================\n",
      "\n",
      "Won : 808\n",
      "Lost : 392\n",
      "Total : 1200\n",
      "Diff : 416\n",
      "\n",
      "Accuracy : 67.33%\n",
      "Information Coefficient (Edge): 34.67%\n",
      "Expected Value (Annualised): 16630.38%\n",
      "\n",
      "Precision: Of all the predicted Buys/Sells, how many were correct?\n",
      "Precision (Buy) : 63.37%\n",
      "Precision (Sell): 78.19%\n",
      "\n",
      "Recall: Of all the actual Buys/Sells, how many were correct?\n",
      "Recall (Buy): 88.84%\n",
      "Recall (Sell): 43.80%\n",
      "\n",
      "F1 Score: Harmonic mean of Precision and Recall for the Buys/Sells\n",
      "F1 Score (Buy): 73.97%\n",
      "F1 Score (Sell): 56.15%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tradeframework.api.insights import InsightManager\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pred = pd.DataFrame(roundTan(tf.nn.tanh(mlmodel(train_df_x))).numpy().flatten(), index=dataset.index[:1200])\n",
    "true = pd.DataFrame(train_df_y.numpy().flatten(), index=dataset.index[:1200])\n",
    "\n",
    "print(f\"Actual data ratio: {len(true.values[true>0])/len(true):.2%} Positive, {len(true.values[true<0])/len(true):.2%} Negative\")\n",
    "print(f\"Prediction data ratio: {len(pred.values[pred>0])/len(pred):.2%} Positive, {len(pred.values[pred<0])/len(pred):.2%} Negative\")\n",
    "\n",
    "im = InsightManager(None)\n",
    "im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"actual\":true[0], \"predictions\":pred[0], \"noHold\":True, \"returnsData\":False}))\n",
    "#im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"baseline\":p.assets[0], \"noHold\":True}))\n",
    "\n",
    "results = im.generateInsights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data ratio: 50.00% Positive, 50.00% Negative\n",
      "Prediction data ratio: 67.00% Positive, 33.00% Negative\n",
      "\n",
      "=================================================\n",
      "Classification Metrics\n",
      "=================================================\n",
      "\n",
      "Won : 53\n",
      "Lost : 47\n",
      "Total : 100\n",
      "Diff : 6\n",
      "\n",
      "Accuracy : 53.00%\n",
      "Information Coefficient (Edge): 6.00%\n",
      "Expected Value (Annualised): 6430.02%\n",
      "\n",
      "Precision: Of all the predicted Buys/Sells, how many were correct?\n",
      "Precision (Buy) : 52.24%\n",
      "Precision (Sell): 54.55%\n",
      "\n",
      "Recall: Of all the actual Buys/Sells, how many were correct?\n",
      "Recall (Buy): 70.00%\n",
      "Recall (Sell): 36.00%\n",
      "\n",
      "F1 Score: Harmonic mean of Precision and Recall for the Buys/Sells\n",
      "F1 Score (Buy): 59.83%\n",
      "F1 Score (Sell): 43.37%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tradeframework.api.insights import InsightManager\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pred = pd.DataFrame(roundTan(tf.nn.tanh(mlmodel(val_df_x))).numpy().flatten(), index=dataset.index[1200:1300])\n",
    "true = pd.DataFrame(val_df_y.numpy().flatten(), index=dataset.index[1200:1300])\n",
    "\n",
    "print(f\"Actual data ratio: {len(true.values[true>0])/len(true):.2%} Positive, {len(true.values[true<0])/len(true):.2%} Negative\")\n",
    "print(f\"Prediction data ratio: {len(pred.values[pred>0])/len(pred):.2%} Positive, {len(pred.values[pred<0])/len(pred):.2%} Negative\")\n",
    "\n",
    "im = InsightManager(None)\n",
    "im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"actual\":true[0], \"predictions\":pred[0], \"noHold\":True, \"returnsData\":False}))\n",
    "#im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"baseline\":p.assets[0], \"noHold\":True}))\n",
    "\n",
    "results = im.generateInsights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data ratio: 43.68% Positive, 56.32% Negative\n",
      "Prediction data ratio: 60.92% Positive, 39.08% Negative\n",
      "\n",
      "=================================================\n",
      "Classification Metrics\n",
      "=================================================\n",
      "\n",
      "Won : 46\n",
      "Lost : 41\n",
      "Total : 87\n",
      "Diff : 5\n",
      "\n",
      "Accuracy : 52.87%\n",
      "Information Coefficient (Edge): 5.75%\n",
      "Expected Value (Annualised): 4690.83%\n",
      "\n",
      "Precision: Of all the predicted Buys/Sells, how many were correct?\n",
      "Precision (Buy) : 47.17%\n",
      "Precision (Sell): 61.76%\n",
      "\n",
      "Recall: Of all the actual Buys/Sells, how many were correct?\n",
      "Recall (Buy): 65.79%\n",
      "Recall (Sell): 42.86%\n",
      "\n",
      "F1 Score: Harmonic mean of Precision and Recall for the Buys/Sells\n",
      "F1 Score (Buy): 54.95%\n",
      "F1 Score (Sell): 50.60%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tradeframework.api.insights import InsightManager\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pred = pd.DataFrame(roundTan(tf.nn.tanh(mlmodel(test_df_x))).numpy().flatten(), index=dataset.index[1300:])\n",
    "true = pd.DataFrame(test_df_y.numpy().flatten(), index=dataset.index[1300:])\n",
    "\n",
    "print(f\"Actual data ratio: {len(true.values[true>0])/len(true):.2%} Positive, {len(true.values[true<0])/len(true):.2%} Negative\")\n",
    "print(f\"Prediction data ratio: {len(pred.values[pred>0])/len(pred):.2%} Positive, {len(pred.values[pred<0])/len(pred):.2%} Negative\")\n",
    "\n",
    "im = InsightManager(None)\n",
    "im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"actual\":true[0], \"predictions\":pred[0], \"noHold\":True, \"returnsData\":False}))\n",
    "#im.addInsightGenerator(im.createInsightGenerator(\"ConfusionMatrix\", opts={\"baseline\":p.assets[0], \"noHold\":True}))\n",
    "\n",
    "results = im.generateInsights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "true.to_pickle(\"results-all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev3.9",
   "language": "python",
   "name": "dev3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
